# Code Context Analysis

Generated: 2026-02-10T21:35:04+05:30
Files Scanned: 22
Analysis Tools: regex, gosec, eslint, flawfinder

## Security Summary

**Total Issues: 23**

- ðŸ”´ CRITICAL: 2
- ðŸŸ  HIGH: 0
- ðŸŸ¡ MEDIUM: 0
- ðŸŸ¢ LOW: 21

**Issues by Tool:**
- regex: 23

---

## File: context_engine/main.go
Language: go | Tokens: 6785 | Size: 27142 bytes

**âš ï¸ Security Issues:**

ðŸ”´ **[CRITICAL]** Line 168 - AWS Credentials
   *AWS credentials exposed*
   Tool: regex
   ```
   Pattern:     regexp.MustCompile(`(?i)(aws_access_key|aws_secret|AKIA[0-9A-Z]{16})`),
   ```

ðŸ”´ **[CRITICAL]** Line 176 - SQL Injection
   *Potential SQL injection vulnerability*
   Tool: regex
   ```
   Pattern:     regexp.MustCompile(`(execute|query|exec)\s*\([^)]*\+|fmt\.Sprintf.*SELECT|SELECT.*%s|"SELECT.*"\s*\+`),
   ```

ðŸŸ¢ **[LOW]** Line 261 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   // Debug/Development code
   ```

ðŸŸ¢ **[LOW]** Line 263 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   Pattern:     regexp.MustCompile(`(?i)(console\.log|print\(|var_dump|debug|TODO.*security|FIXME.*security)`),
   ```

ðŸŸ¢ **[LOW]** Line 264 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   Type:        "Debug Code",
   ```

ðŸŸ¢ **[LOW]** Line 266 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   Description: "Debug code or security TODO in production",
   ```

```go
package main

import (
	"crypto/md5"
	"encoding/json"
	"fmt"
	"io/fs"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"time"
)

// Config holds engine configuration
type Config struct {
	MaxFileSize       int64    `json:"max_file_size"`
	MaxTotalTokens    int      `json:"max_total_tokens"`
	ExcludePatterns   []string `json:"exclude_patterns"`
	IncludeExtensions []string `json:"include_extensions"`
	EnableSecurity    bool     `json:"enable_security"`
	UseGosec          bool     `json:"use_gosec"`
	UseBandit         bool     `json:"use_bandit"`     // Python
	UseESLint         bool     `json:"use_eslint"`     // JavaScript/TypeScript
	UseFlawfinder     bool     `json:"use_flawfinder"` // C/C++
	UsePhpStan        bool     `json:"use_phpstan"`    // PHP
	UseRubocop        bool     `json:"use_rubocop"`    // Ruby
	CacheEnabled      bool     `json:"cache_enabled"`
	CacheDir          string   `json:"cache_dir"`
}

// FileContext represents a processed file
type FileContext struct {
	Path         string          `json:"path"`
	Content      string          `json:"content"`
	Hash         string          `json:"hash"`
	Size         int64           `json:"size"`
	Tokens       int             `json:"tokens"`
	ModifiedTime time.Time       `json:"modified_time"`
	Language     string          `json:"language"`
	Imports      []string        `json:"imports"`
	Functions    []string        `json:"functions"`
	Security     []SecurityIssue `json:"security,omitempty"`
}

// SecurityIssue represents a potential security threat
type SecurityIssue struct {
	Severity    string `json:"severity"`
	Type        string `json:"type"`
	Description string `json:"description"`
	Line        int    `json:"line"`
	Column      int    `json:"column"`
	Code        string `json:"code"`
	Tool        string `json:"tool"`
	CWE         string `json:"cwe,omitempty"`
	Confidence  string `json:"confidence,omitempty"`
}

// Tool output structures

// GosecIssue represents gosec JSON output
type GosecIssue struct {
	Severity   string `json:"severity"`
	Confidence string `json:"confidence"`
	RuleID     string `json:"rule_id"`
	Details    string `json:"details"`
	File       string `json:"file"`
	Code       string `json:"code"`
	Line       string `json:"line"`
	Column     string `json:"column"`
	CWE        struct {
		ID string `json:"id"`
	} `json:"cwe"`
}

type GosecOutput struct {
	Issues []GosecIssue `json:"Issues"`
}

// BanditResult represents bandit JSON output
type BanditResult struct {
	Results []struct {
		TestID          string `json:"test_id"`
		IssueConfidence string `json:"issue_confidence"`
		IssueSeverity   string `json:"issue_severity"`
		IssueText       string `json:"issue_text"`
		LineNumber      int    `json:"line_number"`
		Code            string `json:"code"`
		Filename        string `json:"filename"`
		CWE             struct {
			ID int `json:"id"`
		} `json:"cwe"`
	} `json:"results"`
}

// ESLintResult represents eslint JSON output
type ESLintResult []struct {
	FilePath string `json:"filePath"`
	Messages []struct {
		RuleID   string `json:"ruleId"`
		Severity int    `json:"severity"`
		Message  string `json:"message"`
		Line     int    `json:"line"`
		Column   int    `json:"column"`
	} `json:"messages"`
}

// FlawfinderResult represents flawfinder output
type FlawfinderHit struct {
	File        string
	Line        int
	Column      int
	Level       int
	Category    string
	Name        string
	Description string
	Code        string
}

// SecurityPattern defines regex-based security patterns
type SecurityPattern struct {
	Pattern     *regexp.Regexp
	Type        string
	Severity    string
	Description string
	Languages   []string
}

// ContextEngine manages code context generation
type ContextEngine struct {
	Config      Config
	Files       []FileContext
	Cache       map[string]FileContext
	SecurityDB  []SecurityPattern
	ProjectPath string
}

// NewContextEngine initializes the engine
func NewContextEngine(cfg Config) *ContextEngine {
	engine := &ContextEngine{
		Config:     cfg,
		Files:      make([]FileContext, 0),
		Cache:      make(map[string]FileContext),
		SecurityDB: initSecurityPatterns(),
	}

	if cfg.CacheEnabled {
		engine.loadCache()
	}

	return engine
}

// initSecurityPatterns defines comprehensive multi-language patterns
func initSecurityPatterns() []SecurityPattern {
	patterns := []SecurityPattern{
		// Credentials - All languages
		{
			Pattern:     regexp.MustCompile(`(?i)(password|passwd|pwd|secret|api_key|apikey|token|private_key)\s*=\s*["'][^"']{8,}["']`),
			Type:        "Hardcoded Credentials",
			Severity:    "CRITICAL",
			Description: "Hardcoded credentials detected",
			Languages:   []string{"*"},
		},
		{
			Pattern:     regexp.MustCompile(`(?i)(aws_access_key|aws_secret|AKIA[0-9A-Z]{16})`),
			Type:        "AWS Credentials",
			Severity:    "CRITICAL",
			Description: "AWS credentials exposed",
			Languages:   []string{"*"},
		},
		// SQL Injection - Multiple languages
		{
			Pattern:     regexp.MustCompile(`(execute|query|exec)\s*\([^)]*\+|fmt\.Sprintf.*SELECT|SELECT.*%s|"SELECT.*"\s*\+`),
			Type:        "SQL Injection",
			Severity:    "CRITICAL",
			Description: "Potential SQL injection vulnerability",
			Languages:   []string{"go", "python", "javascript", "typescript", "php", "java"},
		},
		// Command Injection
		{
			Pattern:     regexp.MustCompile(`(exec\.Command|os\.system|subprocess\.call|eval|shell_exec|system)\s*\([^)]*\+`),
			Type:        "Command Injection",
			Severity:    "HIGH",
			Description: "Dynamic command construction - potential command injection",
			Languages:   []string{"go", "python", "javascript", "php", "ruby"},
		},
		// XSS vulnerabilities
		{
			Pattern:     regexp.MustCompile(`innerHTML\s*=|document\.write\(|\.html\([^)]*\+`),
			Type:        "XSS Vulnerability",
			Severity:    "HIGH",
			Description: "Potential XSS - dynamic HTML content",
			Languages:   []string{"javascript", "typescript"},
		},
		// Path Traversal
		{
			Pattern:     regexp.MustCompile(`(os\.Open|ioutil\.ReadFile|open\(|file_get_contents|readFile)\s*\([^)]*\+`),
			Type:        "Path Traversal",
			Severity:    "HIGH",
			Description: "Dynamic file path - potential path traversal",
			Languages:   []string{"go", "python", "javascript", "php", "ruby"},
		},
		// Weak Crypto
		{
			Pattern:     regexp.MustCompile(`(MD5|SHA1|DES|RC4|md5|sha1)\s*\(`),
			Type:        "Weak Cryptography",
			Severity:    "MEDIUM",
			Description: "Use of weak cryptographic algorithm",
			Languages:   []string{"*"},
		},
		{
			Pattern:     regexp.MustCompile(`Math\.random|rand\(\)|mt_rand\(\)`),
			Type:        "Weak Random",
			Severity:    "MEDIUM",
			Description: "Weak random number generator for security",
			Languages:   []string{"javascript", "php", "c", "cpp"},
		},
		// Deserialization
		{
			Pattern:     regexp.MustCompile(`(pickle\.loads|yaml\.load|unserialize|eval\(|json\.loads.*JSONDecoder)`),
			Type:        "Unsafe Deserialization",
			Severity:    "HIGH",
			Description: "Unsafe deserialization of untrusted data",
			Languages:   []string{"python", "php", "javascript", "ruby"},
		},
		// SSRF
		{
			Pattern:     regexp.MustCompile(`(http\.Get|requests\.get|fetch|curl_exec|Net::HTTP)\s*\([^)]*\+`),
			Type:        "SSRF",
			Severity:    "HIGH",
			Description: "Server-Side Request Forgery risk",
			Languages:   []string{"go", "python", "javascript", "php", "ruby"},
		},
		// Code Injection
		{
			Pattern:     regexp.MustCompile(`\beval\s*\(|exec\s*\(|Function\s*\(`),
			Type:        "Code Injection",
			Severity:    "CRITICAL",
			Description: "Dynamic code execution",
			Languages:   []string{"javascript", "python", "php"},
		},
		// Buffer Overflow - C/C++
		{
			Pattern:     regexp.MustCompile(`\b(gets|strcpy|strcat|sprintf|vsprintf)\s*\(`),
			Type:        "Buffer Overflow",
			Severity:    "CRITICAL",
			Description: "Unsafe buffer function",
			Languages:   []string{"c", "cpp"},
		},
		// XXE - XML External Entity
		{
			Pattern:     regexp.MustCompile(`XMLParser|parseXML|DocumentBuilder.*parse|simplexml_load`),
			Type:        "XXE Risk",
			Severity:    "HIGH",
			Description: "XML parser may be vulnerable to XXE",
			Languages:   []string{"java", "php", "python", "javascript"},
		},
		// Debug/Development code
		{
			Pattern:     regexp.MustCompile(`(?i)(console\.log|print\(|var_dump|debug|TODO.*security|FIXME.*security)`),
			Type:        "Debug Code",
			Severity:    "LOW",
			Description: "Debug code or security TODO in production",
			Languages:   []string{"*"},
		},
	}

	return patterns
}

// CheckToolsAvailable verifies required tools are installed
func (e *ContextEngine) CheckToolsAvailable() {
	tools := map[string]*bool{
		"gosec":      &e.Config.UseGosec,
		"bandit":     &e.Config.UseBandit,
		"eslint":     &e.Config.UseESLint,
		"flawfinder": &e.Config.UseFlawfinder,
		"phpstan":    &e.Config.UsePhpStan,
		"rubocop":    &e.Config.UseRubocop,
	}

	fmt.Println("Checking available security tools:")
	for tool, enabled := range tools {
		if *enabled {
			if _, err := exec.LookPath(tool); err != nil {
				fmt.Printf("âš ï¸  %s not found (disabled)\n", tool)
				*enabled = false
			} else {
				fmt.Printf("âœ“ %s found\n", tool)
			}
		}
	}
	fmt.Println()
}

// RunGosec executes gosec on Go files
func (e *ContextEngine) RunGosec() ([]SecurityIssue, error) {
	if !e.Config.UseGosec {
		return nil, nil
	}

	fmt.Println("Running gosec analysis...")
	cmd := exec.Command("gosec", "-fmt=json", "-quiet", "./...")
	cmd.Dir = e.ProjectPath

	output, _ := cmd.CombinedOutput()
	if len(output) == 0 {
		return nil, nil
	}

	var result GosecOutput
	if err := json.Unmarshal(output, &result); err != nil {
		return nil, fmt.Errorf("failed to parse gosec output: %v", err)
	}

	issues := make([]SecurityIssue, 0)
	for _, issue := range result.Issues {
		var line int
		fmt.Sscanf(issue.Line, "%d", &line)

		filepath.Rel(e.ProjectPath, issue.File)

		issues = append(issues, SecurityIssue{
			Severity:    strings.ToUpper(issue.Severity),
			Type:        issue.RuleID,
			Description: issue.Details,
			Line:        line,
			Code:        issue.Code,
			Tool:        "gosec",
			CWE:         issue.CWE.ID,
			Confidence:  issue.Confidence,
		})
	}

	fmt.Printf("  Found %d issues with gosec\n", len(issues))
	return issues, nil
}

// RunBandit executes bandit on Python files
func (e *ContextEngine) RunBandit() ([]SecurityIssue, error) {
	if !e.Config.UseBandit {
		return nil, nil
	}

	fmt.Println("Running bandit analysis...")
	cmd := exec.Command("bandit", "-r", ".", "-f", "json", "-q")
	cmd.Dir = e.ProjectPath

	output, _ := cmd.CombinedOutput()
	if len(output) == 0 {
		return nil, nil
	}

	var result BanditResult
	if err := json.Unmarshal(output, &result); err != nil {
		return nil, fmt.Errorf("failed to parse bandit output: %v", err)
	}

	issues := make([]SecurityIssue, 0)
	for _, finding := range result.Results {
		filepath.Rel(e.ProjectPath, finding.Filename)

		severity := strings.ToUpper(finding.IssueSeverity)
		if severity == "UNDEFINED" {
			severity = "MEDIUM"
		}

		cwe := ""
		if finding.CWE.ID > 0 {
			cwe = fmt.Sprintf("CWE-%d", finding.CWE.ID)
		}

		issues = append(issues, SecurityIssue{
			Severity:    severity,
			Type:        finding.TestID,
			Description: finding.IssueText,
			Line:        finding.LineNumber,
			Code:        finding.Code,
			Tool:        "bandit",
			CWE:         cwe,
			Confidence:  finding.IssueConfidence,
		})
	}

	fmt.Printf("  Found %d issues with bandit\n", len(issues))
	return issues, nil
}

// RunESLint executes eslint with security plugin
func (e *ContextEngine) RunESLint() ([]SecurityIssue, error) {
	if !e.Config.UseESLint {
		return nil, nil
	}

	fmt.Println("Running eslint analysis...")
	cmd := exec.Command("eslint", ".", "--ext", ".js,.jsx,.ts,.tsx", "-f", "json")
	cmd.Dir = e.ProjectPath

	output, _ := cmd.CombinedOutput()
	if len(output) == 0 {
		return nil, nil
	}

	var result ESLintResult
	if err := json.Unmarshal(output, &result); err != nil {
		return nil, fmt.Errorf("failed to parse eslint output: %v", err)
	}

	issues := make([]SecurityIssue, 0)
	for _, file := range result {
		filepath.Rel(e.ProjectPath, file.FilePath)

		for _, msg := range file.Messages {
			if msg.RuleID == "" || msg.Severity < 1 {
				continue
			}

			// Only include security-related rules
			if !strings.Contains(msg.RuleID, "security") &&
				!strings.Contains(msg.RuleID, "no-eval") &&
				!strings.Contains(msg.RuleID, "no-implied-eval") {
				continue
			}

			severity := "MEDIUM"
			if msg.Severity == 2 {
				severity = "HIGH"
			}

			issues = append(issues, SecurityIssue{
				Severity:    severity,
				Type:        msg.RuleID,
				Description: msg.Message,
				Line:        msg.Line,
				Column:      msg.Column,
				Tool:        "eslint",
			})
		}
	}

	fmt.Printf("  Found %d issues with eslint\n", len(issues))
	return issues, nil
}

// RunFlawfinder executes flawfinder on C/C++ files
func (e *ContextEngine) RunFlawfinder() ([]SecurityIssue, error) {
	if !e.Config.UseFlawfinder {
		return nil, nil
	}

	fmt.Println("Running flawfinder analysis...")
	cmd := exec.Command("flawfinder", "--quiet", "--dataonly", ".")
	cmd.Dir = e.ProjectPath

	output, _ := cmd.CombinedOutput()
	if len(output) == 0 {
		return nil, nil
	}

	issues := make([]SecurityIssue, 0)
	lines := strings.Split(string(output), "\n")

	for _, line := range lines {
		if line == "" {
			continue
		}

		// Parse flawfinder output: file:line:column: [level] category: description
		re := regexp.MustCompile(`([^:]+):(\d+):(\d+):\s*\[(\d+)\]\s*\(([^)]+)\)\s*(.+)`)
		matches := re.FindStringSubmatch(line)

		if len(matches) == 7 {
			var lineNum, level int
			fmt.Sscanf(matches[2], "%d", &lineNum)
			fmt.Sscanf(matches[4], "%d", &level)

			severity := "LOW"
			if level >= 4 {
				severity = "HIGH"
			} else if level >= 2 {
				severity = "MEDIUM"
			}

			filepath.Rel(e.ProjectPath, matches[1])

			issues = append(issues, SecurityIssue{
				Severity:    severity,
				Type:        matches[5],
				Description: matches[6],
				Line:        lineNum,
				Tool:        "flawfinder",
			})
		}
	}

	fmt.Printf("  Found %d issues with flawfinder\n", len(issues))
	return issues, nil
}

// ScanDirectory walks the directory and processes files
func (e *ContextEngine) ScanDirectory(root string) error {
	e.ProjectPath = root

	// Run security tools on entire project
	var allSecurityIssues []SecurityIssue

	if e.Config.EnableSecurity {
		tools := []func() ([]SecurityIssue, error){
			e.RunGosec,
			e.RunBandit,
			e.RunESLint,
			e.RunFlawfinder,
		}

		for _, tool := range tools {
			if issues, err := tool(); err != nil {
				fmt.Printf("Warning: %v\n", err)
			} else {
				allSecurityIssues = append(allSecurityIssues, issues...)
			}
		}
	}

	// Create map for quick lookup of security issues by file
	securityByFile := make(map[string][]SecurityIssue)
	for _, issue := range allSecurityIssues {
		securityByFile[issue.Type] = append(securityByFile[issue.Type], issue)
	}

	// Walk directory and process files
	return filepath.WalkDir(root, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}

		if d.IsDir() {
			if e.shouldExclude(path) {
				return filepath.SkipDir
			}
			return nil
		}

		if !e.shouldInclude(path) {
			return nil
		}

		info, err := d.Info()
		if err != nil {
			return nil
		}

		if info.Size() > e.Config.MaxFileSize {
			return nil
		}

		relPath, _ := filepath.Rel(root, path)
		return e.processFile(path, relPath, info, allSecurityIssues)
	})
}

func (e *ContextEngine) shouldExclude(path string) bool {
	for _, pattern := range e.Config.ExcludePatterns {
		if strings.Contains(path, pattern) {
			return true
		}
	}
	return false
}

func (e *ContextEngine) shouldInclude(path string) bool {
	ext := filepath.Ext(path)
	for _, validExt := range e.Config.IncludeExtensions {
		if ext == validExt {
			return true
		}
	}
	return false
}

func (e *ContextEngine) processFile(path, relPath string, info fs.FileInfo, allIssues []SecurityIssue) error {
	hash := e.getFileHash(path)

	if e.Config.CacheEnabled {
		if cached, exists := e.Cache[hash]; exists {
			if cached.ModifiedTime.Equal(info.ModTime()) {
				e.Files = append(e.Files, cached)
				return nil
			}
		}
	}

	content, err := os.ReadFile(path)
	if err != nil {
		return nil
	}

	ctx := FileContext{
		Path:         relPath,
		Content:      string(content),
		Hash:         hash,
		Size:         info.Size(),
		Tokens:       estimateTokens(string(content)),
		ModifiedTime: info.ModTime(),
		Language:     detectLanguage(path),
		Security:     make([]SecurityIssue, 0),
	}

	ctx.Imports = extractImports(ctx.Content, ctx.Language)
	ctx.Functions = extractFunctions(ctx.Content, ctx.Language)

	// Match security issues to this file
	for _, issue := range allIssues {
		if strings.Contains(issue.Code, relPath) || strings.HasSuffix(issue.Code, filepath.Base(path)) {
			ctx.Security = append(ctx.Security, issue)
		}
	}

	// Add regex-based analysis
	if e.Config.EnableSecurity {
		regexIssues := e.analyzeSecurityThreatsRegex(ctx.Content, ctx.Language)
		ctx.Security = append(ctx.Security, regexIssues...)
	}

	e.Files = append(e.Files, ctx)

	if e.Config.CacheEnabled {
		e.Cache[hash] = ctx
	}

	return nil
}

func (e *ContextEngine) analyzeSecurityThreatsRegex(content, lang string) []SecurityIssue {
	issues := make([]SecurityIssue, 0)
	lines := strings.Split(content, "\n")

	for i, line := range lines {
		for _, pattern := range e.SecurityDB {
			// Check if pattern applies to this language
			if !e.patternApplies(pattern, lang) {
				continue
			}

			if pattern.Pattern.MatchString(line) {
				issues = append(issues, SecurityIssue{
					Severity:    pattern.Severity,
					Type:        pattern.Type,
					Description: pattern.Description,
					Line:        i + 1,
					Code:        strings.TrimSpace(line),
					Tool:        "regex",
				})
			}
		}
	}

	return issues
}

func (e *ContextEngine) patternApplies(pattern SecurityPattern, lang string) bool {
	for _, l := range pattern.Languages {
		if l == "*" || l == lang {
			return true
		}
	}
	return false
}

func (e *ContextEngine) GenerateContext() string {
	var sb strings.Builder
	totalTokens := 0

	sort.Slice(e.Files, func(i, j int) bool {
		if len(e.Files[i].Security) != len(e.Files[j].Security) {
			return len(e.Files[i].Security) > len(e.Files[j].Security)
		}
		return e.Files[i].Tokens > e.Files[j].Tokens
	})

	sb.WriteString("# Code Context Analysis\n\n")
	sb.WriteString(fmt.Sprintf("Generated: %s\n", time.Now().Format(time.RFC3339)))
	sb.WriteString(fmt.Sprintf("Files Scanned: %d\n", len(e.Files)))

	tools := []string{"regex"}
	if e.Config.UseGosec {
		tools = append(tools, "gosec")
	}
	if e.Config.UseBandit {
		tools = append(tools, "bandit")
	}
	if e.Config.UseESLint {
		tools = append(tools, "eslint")
	}
	if e.Config.UseFlawfinder {
		tools = append(tools, "flawfinder")
	}
	sb.WriteString(fmt.Sprintf("Analysis Tools: %s\n\n", strings.Join(tools, ", ")))

	if e.Config.EnableSecurity {
		sb.WriteString("## Security Summary\n\n")
		critical, high, medium, low := e.countSecurityIssues()
		total := critical + high + medium + low

		sb.WriteString(fmt.Sprintf("**Total Issues: %d**\n\n", total))
		sb.WriteString(fmt.Sprintf("- ðŸ”´ CRITICAL: %d\n", critical))
		sb.WriteString(fmt.Sprintf("- ðŸŸ  HIGH: %d\n", high))
		sb.WriteString(fmt.Sprintf("- ðŸŸ¡ MEDIUM: %d\n", medium))
		sb.WriteString(fmt.Sprintf("- ðŸŸ¢ LOW: %d\n\n", low))

		toolCounts := e.countIssuesByTool()
		sb.WriteString("**Issues by Tool:**\n")
		for tool, count := range toolCounts {
			if count > 0 {
				sb.WriteString(fmt.Sprintf("- %s: %d\n", tool, count))
			}
		}
		sb.WriteString("\n")
	}

	sb.WriteString("---\n\n")

	includedCount := 0
	for _, file := range e.Files {
		if totalTokens+file.Tokens > e.Config.MaxTotalTokens {
			break
		}

		sb.WriteString(fmt.Sprintf("## File: %s\n", file.Path))
		sb.WriteString(fmt.Sprintf("Language: %s | Tokens: %d | Size: %d bytes\n\n", file.Language, file.Tokens, file.Size))

		if len(file.Imports) > 0 {
			sb.WriteString("**Imports:** " + strings.Join(file.Imports, ", ") + "\n\n")
		}

		if len(file.Security) > 0 {
			sb.WriteString("**âš ï¸ Security Issues:**\n\n")
			for _, issue := range file.Security {
				emoji := getSeverityEmoji(issue.Severity)
				sb.WriteString(fmt.Sprintf("%s **[%s]** Line %d - %s\n", emoji, issue.Severity, issue.Line, issue.Type))
				sb.WriteString(fmt.Sprintf("   *%s*\n", issue.Description))
				sb.WriteString(fmt.Sprintf("   Tool: %s", issue.Tool))
				if issue.Confidence != "" {
					sb.WriteString(fmt.Sprintf(" | Confidence: %s", issue.Confidence))
				}
				if issue.CWE != "" {
					sb.WriteString(fmt.Sprintf(" | CWE: %s", issue.CWE))
				}
				sb.WriteString("\n")
				if issue.Code != "" {
					sb.WriteString(fmt.Sprintf("   ```\n   %s\n   ```\n", issue.Code))
				}
				sb.WriteString("\n")
			}
		}

		sb.WriteString("```" + file.Language + "\n")
		sb.WriteString(file.Content)
		sb.WriteString("\n```\n\n")

		totalTokens += file.Tokens
		includedCount++
	}

	sb.WriteString("\n---\n\n")
	sb.WriteString(fmt.Sprintf("**Summary:**\n"))
	sb.WriteString(fmt.Sprintf("- Files Included: %d / %d\n", includedCount, len(e.Files)))
	sb.WriteString(fmt.Sprintf("- Total Tokens: %d / %d\n", totalTokens, e.Config.MaxTotalTokens))

	return sb.String()
}

func getSeverityEmoji(severity string) string {
	switch severity {
	case "CRITICAL":
		return "ðŸ”´"
	case "HIGH":
		return "ðŸŸ "
	case "MEDIUM":
		return "ðŸŸ¡"
	case "LOW":
		return "ðŸŸ¢"
	default:
		return "âšª"
	}
}

func (e *ContextEngine) countSecurityIssues() (critical, high, medium, low int) {
	for _, file := range e.Files {
		for _, issue := range file.Security {
			switch issue.Severity {
			case "CRITICAL":
				critical++
			case "HIGH":
				high++
			case "MEDIUM":
				medium++
			case "LOW":
				low++
			}
		}
	}
	return
}

func (e *ContextEngine) countIssuesByTool() map[string]int {
	counts := make(map[string]int)
	for _, file := range e.Files {
		for _, issue := range file.Security {
			counts[issue.Tool]++
		}
	}
	return counts
}

func (e *ContextEngine) getFileHash(path string) string {
	data := []byte(path)
	return fmt.Sprintf("%x", md5.Sum(data))
}

func estimateTokens(content string) int {
	return len(content) / 4
}

func detectLanguage(path string) string {
	ext := filepath.Ext(path)
	langMap := map[string]string{
		".go": "go", ".js": "javascript", ".ts": "typescript",
		".py": "python", ".java": "java", ".rs": "rust",
		".c": "c", ".cpp": "cpp", ".h": "c", ".hpp": "cpp",
		".html": "html", ".css": "css", ".rb": "ruby", ".php": "php",
		".dart": "dart", ".mjs": "javascript",
	}
	if lang, ok := langMap[ext]; ok {
		return lang
	}
	return "text"
}

func extractImports(content, lang string) []string {
	imports := make([]string, 0)
	switch lang {
	case "go":
		re := regexp.MustCompile(`import\s+(?:"([^"]+)"|([a-zA-Z0-9_/]+))`)
		matches := re.FindAllStringSubmatch(content, -1)
		for _, m := range matches {
			if m[1] != "" {
				imports = append(imports, m[1])
			}
		}
	case "python":
		re := regexp.MustCompile(`(?:from\s+(\S+)|import\s+(\S+))`)
		matches := re.FindAllStringSubmatch(content, -1)
		for _, m := range matches {
			if m[1] != "" {
				imports = append(imports, m[1])
			} else if m[2] != "" {
				imports = append(imports, m[2])
			}
		}
	case "javascript", "typescript":
		re := regexp.MustCompile(`import\s+.*?from\s+['"]([^'"]+)['"]`)
		matches := re.FindAllStringSubmatch(content, -1)
		for _, m := range matches {
			imports = append(imports, m[1])
		}
	}
	return imports
}

func extractFunctions(content, lang string) []string {
	functions := make([]string, 0)
	switch lang {
	case "go":
		re := regexp.MustCompile(`func\s+(\w+)\s*\(`)
		matches := re.FindAllStringSubmatch(content, -1)
		for _, m := range matches {
			functions = append(functions, m[1])
		}
	case "python":
		re := regexp.MustCompile(`def\s+(\w+)\s*\(`)
		matches := re.FindAllStringSubmatch(content, -1)
		for _, m := range matches {
			functions = append(functions, m[1])
		}
	case "javascript", "typescript":
		re := regexp.MustCompile(`function\s+(\w+)\s*\(|const\s+(\w+)\s*=\s*\([^)]*\)\s*=>`)
		matches := re.FindAllStringSubmatch(content, -1)
		for _, m := range matches {
			if m[1] != "" {
				functions = append(functions, m[1])
			} else if m[2] != "" {
				functions = append(functions, m[2])
			}
		}
	}
	return functions
}

func (e *ContextEngine) loadCache() {
	if e.Config.CacheDir == "" {
		return
	}
	cachePath := filepath.Join(e.Config.CacheDir, "context_cache.json")
	data, err := os.ReadFile(cachePath)
	if err != nil {
		return
	}
	json.Unmarshal(data, &e.Cache)
}

func (e *ContextEngine) saveCache() error {
	if !e.Config.CacheEnabled || e.Config.CacheDir == "" {
		return nil
	}
	os.MkdirAll(e.Config.CacheDir, 0755)
	cachePath := filepath.Join(e.Config.CacheDir, "context_cache.json")
	data, err := json.MarshalIndent(e.Cache, "", "  ")
	if err != nil {
		return err
	}
	return os.WriteFile(cachePath, data, 0644)
}

func main() {
	config := Config{
		MaxFileSize:    100 * 1024,
		MaxTotalTokens: 100000,
		ExcludePatterns: []string{
			"node_modules", "vendor", ".git", "dist", "build",
			"__pycache__", ".pytest_cache", "target", ".next",
			"venv",
		},
		IncludeExtensions: []string{
			".go", ".js", ".ts", ".py", ".java", ".rs",
			".c", ".cpp", ".h", ".css", ".html", ".rb", ".php", ".dart", ".mjs",
		},
		EnableSecurity: true,
		UseGosec:       true,
		UseBandit:      true,
		UseESLint:      true,
		UseFlawfinder:  true,
		UsePhpStan:     false,
		UseRubocop:     false,
		CacheEnabled:   true,
		CacheDir:       ".context_cache",
	}

	engine := NewContextEngine(config)
	engine.CheckToolsAvailable()

	scanPath := "."
	if len(os.Args) > 1 {
		scanPath = os.Args[1]
	}

	absPath, _ := filepath.Abs(scanPath)
	fmt.Printf("\nðŸ” Scanning directory: %s\n\n", absPath)

	if err := engine.ScanDirectory(absPath); err != nil {
		fmt.Fprintf(os.Stderr, "Error scanning: %v\n", err)
		os.Exit(1)
	}

	fmt.Printf("\nâœ“ Processed %d files\n\n", len(engine.Files))

	context := engine.GenerateContext()

	outputFile := "code_context.txt"
	if err := os.WriteFile(outputFile, []byte(context), 0644); err != nil {
		fmt.Fprintf(os.Stderr, "Error writing output: %v\n", err)
		os.Exit(1)
	}

	if err := engine.saveCache(); err != nil {
		fmt.Fprintf(os.Stderr, "Warning: could not save cache: %v\n", err)
	}

	fmt.Printf("ðŸ“„ Context written to %s\n\n", outputFile)

	if config.EnableSecurity {
		critical, high, medium, low := engine.countSecurityIssues()
		total := critical + high + medium + low
		if total > 0 {
			fmt.Printf("âš ï¸  Security Issues Found: %d\n", total)
			fmt.Printf("   ðŸ”´ CRITICAL: %d | ðŸŸ  HIGH: %d | ðŸŸ¡ MEDIUM: %d | ðŸŸ¢ LOW: %d\n\n", critical, high, medium, low)

			toolCounts := engine.countIssuesByTool()
			fmt.Printf("ðŸ“Š Detection Tool Breakdown:\n")
			for tool, count := range toolCounts {
				if count > 0 {
					fmt.Printf("   - %s: %d issues\n", tool, count)
				}
			}
		} else {
			fmt.Println("âœ… No security issues detected!")
		}
	}
}

```

## File: internal/service/analysis/analysis.go
Language: go | Tokens: 10398 | Size: 41594 bytes

**âš ï¸ Security Issues:**

ðŸŸ¢ **[LOW]** Line 962 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   - Adds line numbers to each line for precise reference and debugging
   ```

ðŸŸ¢ **[LOW]** Line 1225 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   ðŸ” SYSTEM MONITORING & DEBUGGING:
   ```

ðŸŸ¢ **[LOW]** Line 1307 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   - Network debugging: tcpdump, wireshark-cli
   ```

ðŸŸ¢ **[LOW]** Line 1351 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   Description: "Optional context message for logging, debugging, or providing additional information about the command execution.",
   ```

```go
package analysis

import (
	"bufio"
	"bytes"
	"context"
	"dost/internal/repository"
	"dost/internal/service"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"strings"
	"time"

	gitignore "github.com/sabhiram/go-gitignore"
	"github.com/spf13/viper"
)

var defaultIgnore = map[string]bool{
	".git":         true,
	"node_modules": true,
	"vendor":       true,
	".venv":        true,
	".env":         true,
	".idea":        true,
	".vscode":      true,
	"__pycache__":  true,
	".dost":        true,
}
var ignoreMatcher *gitignore.GitIgnore
var AnalysisMap = make(map[string]Analysis, 0)
var AnalysistoolsFunc map[string]repository.Function = make(map[string]repository.Function)
var InputData = make(map[string]any, 0)
var FilesRead = make(map[string]any, 0)

var ChatHistory = make([]map[string]any, 0)

type Analysis struct {
	ID              string         `json:"id"`
	DetailSummary   string         `json:"detail_summary"`
	Summary         string         `json:"summary"`
	Domain          string         `json:"domain"`
	Constraints     Constraints    `json:"constraints"`
	InputsDetected  Inputs         `json:"inputs_detected"`
	Risks           []string       `json:"risks"`
	ExpectedOutput  OutputFormat   `json:"expected_output"`
	OperatingSystem string         `json:"operating_system"`
	QueryInputs     map[string]any `json:"query_input"`
	FilesRead       map[string]any `json:"files_read"`
}

type Constraints struct {
	Hard []string `json:"hard"`
	Soft []string `json:"soft"`
}

type Inputs struct {
	Files       []string `json:"files,omitempty"`
	Environment string   `json:"environment,omitempty"`
	Language    string   `json:"language,omitempty"`
}

type OutputFormat struct {
	Format     string                 `json:"format"`
	Example    map[string]interface{} `json:"example"`
	OutputType string                 `json:"output_type"`
}

type AgentAnalysis repository.Agent

type InitialContext struct {
	OS              string
	Arch            string
	User            string
	Shell           string
	CWD             string
	GoVersion       string
	FolderStructure map[string]any
	InstalledTools  []string
	EnvVars         map[string]string
	ProjectFiles    []string
	ProjectType     string
	GitBranch       string
	InternetAccess  bool
	AgentRole       string
	Capabilities    []string
	Timezone        string
	SessionID       string
}

func GetInitialContext() InitialContext {
	ctx := InitialContext{
		OS:              runtime.GOOS,
		Arch:            runtime.GOARCH,
		User:            os.Getenv("USERNAME"),
		Shell:           detectDefaultShell(),
		CWD:             mustGetWorkingDir(),
		FolderStructure: GetProjectStructure(map[string]any{"path": "./"}),
		GoVersion:       runtime.Version(),
		InstalledTools:  detectTools(),
		EnvVars:         getImportantEnvVars(),
		ProjectFiles:    scanProjectFiles(),
		ProjectType:     detectProjectType(),
		GitBranch:       getGitBranch(),
		InternetAccess:  checkInternet(),
		Timezone:        getLocalTimezone(),
		SessionID:       generateSessionID(),
	}
	return ctx
}

func detectDefaultShell() string {
	if runtime.GOOS == "windows" {
		// prefer PowerShell if present
		if _, err := exec.LookPath("powershell"); err == nil {
			return "powershell"
		}
		return "cmd"
	}
	return os.Getenv("SHELL")
}

func mustGetWorkingDir() string {
	dir, err := os.Getwd()
	if err != nil {
		return "."
	}
	return dir
}

func detectTools() []string {
	var found []string
	val := os.Getenv("PATH")
	found = strings.Split(val, ";")
	return found
}

func getImportantEnvVars() map[string]string {
	keys := []string{"PATH", "GOROOT", "GOPATH", "JAVA_HOME"}
	env := make(map[string]string)
	for _, k := range keys {
		if v := os.Getenv(k); v != "" {
			env[k] = v
		}
	}
	return env
}

func scanProjectFiles() []string {
	files := []string{}
	filepath.Walk(".", func(path string, info os.FileInfo, err error) error {
		if err == nil && !info.IsDir() {
			if strings.HasSuffix(path, ".go") ||
				path == "go.mod" || path == "package.json" || path == "requirements.txt" ||
				path == "Dockerfile" || path == "README.md" {
				files = append(files, path)
			}
		}
		return nil
	})
	return files
}

func detectProjectType() string {
	if _, err := os.Stat("go.mod"); err == nil {
		return "Go project"
	}
	if _, err := os.Stat("package.json"); err == nil {
		return "Node.js project"
	}
	if _, err := os.Stat("requirements.txt"); err == nil {
		return "Python project"
	}
	return "Unknown"
}

func getGitBranch() string {
	cmd := exec.Command("git", "rev-parse", "--abbrev-ref", "HEAD")
	out, err := cmd.Output()
	if err != nil {
		return ""
	}
	return strings.TrimSpace(string(out))
}

func checkInternet() bool {
	cmd := exec.Command("ping", "-c", "1", "8.8.8.8")
	if runtime.GOOS == "windows" {
		cmd = exec.Command("ping", "-n", "1", "8.8.8.8")
	}
	if err := cmd.Run(); err != nil {
		return false
	}
	return true
}

func getLocalTimezone() string {
	_, tz := time.Now().Zone()
	return fmt.Sprintf("%d min offset", tz/60)
}

func generateSessionID() string {
	return fmt.Sprintf("%d", time.Now().UnixNano())
}

// args must and only contains "query"
// Helper function to format files for Gemini
func formatFilesForGemini(filesRead map[string]any) string {
	if len(filesRead) == 0 {
		return ""
	}

	var result strings.Builder
	result.WriteString("=== FILES CONTENT ===\n\n")

	for fileName, fileData := range filesRead {
		result.WriteString(fmt.Sprintf("FILE: %s\n", fileName))
		result.WriteString("=" + strings.Repeat("=", len(fileName)+6) + "\n")

		if chunks, ok := fileData.([]map[string]any); ok {
			for _, chunk := range chunks {
				if content, exists := chunk["content"].(string); exists {
					result.WriteString(content)
					result.WriteString("\n")
				}
			}
		}
		result.WriteString("\n" + strings.Repeat("-", 50) + "\n\n")
	}

	return result.String()
}

func (p *AgentAnalysis) Interaction(args map[string]any) map[string]any {
	InitialContext := GetInitialContext()
	InitialContextBytes, err := json.Marshal(InitialContext)
	if err != nil {
		return map[string]any{"error": "Unable to get initial context"}
	}

	// Build consolidated user message with proper formatting
	var userMessage strings.Builder

	// Add files content if any
	filesContent := formatFilesForGemini(FilesRead)
	if filesContent != "" {
		userMessage.WriteString(filesContent)
		userMessage.WriteString("\n")
	}

	// Add initial context
	userMessage.WriteString("=== INITIAL CONTEXT ===\n")
	userMessage.WriteString(string(InitialContextBytes))
	userMessage.WriteString("\n\n")

	// Add the actual query
	userMessage.WriteString("=== QUERY ===\n")
	if query, ok := args["query"].(string); ok {
		userMessage.WriteString(query)
	}
	log.Println("TEST: ANALYSIS: ", userMessage.String()[0:20])
	// Add as a single consolidated user message
	ChatHistory = append(ChatHistory, map[string]any{
		"role": "user",
		"parts": []map[string]any{
			{
				"text": userMessage.String(),
			},
		},
	})

	for {
		// Check if last message was from model and add exit instruction if needed
		if len(ChatHistory) > 0 && ChatHistory[len(ChatHistory)-1]["role"] == "model" {
			ChatHistory = append(ChatHistory, map[string]any{
				"role": "user",
				"parts": []map[string]any{
					{
						"text": "If you feel there is no task left and you have created the Analysis by calling the put-analysis-agent-output function call then and then only call exit-process. Because only that can stop you and finish the program. Don't respond with text, no text output should be there, call the exit-process. Mark It the put-analysis-agent-output should be called before exit. PERIOD",
					},
				},
			})
		}

		output := p.RequestAgent(ChatHistory)

		if output["error"] != nil {
			fmt.Println("Error:", output["error"])
			os.Exit(1)
		}

		outputData, ok := output["output"].([]map[string]any)
		if !ok {
			fmt.Println("ERROR CONVERTING OUTPUT")
			return nil
		}

		if len(outputData) == 0 {
			fmt.Println("No output received")
			continue
		}

		// Process each output part
		for _, part := range outputData {
			partType, hasType := part["type"].(string)
			if !hasType {
				continue
			}

			if partType == "text" {
				// Handle text response
				if text, ok := part["data"].(string); ok {
					fmt.Println("Agent:", text)
				}
			} else if partType == "functionCall" {
				// Handle function call
				name, nameOK := part["name"].(string)
				argsData, argsOK := part["args"].(map[string]any)

				if !nameOK || !argsOK {
					fmt.Println("Error: invalid function call data")
					continue
				}

				fmt.Println("Calling function:", name)

				// Execute the function
				if function, exists := AnalysistoolsFunc[name]; exists {
					result := function.Run(argsData)

					// Check for exit condition
					if _, ok := result["exit"].(bool); ok {
						analysisID, ok := result["output"].(string)
						if ok {
							analysis := AnalysisMap[analysisID]
							analysis.QueryInputs = InputData
							AnalysisMap[analysisID] = analysis
							return map[string]any{"analysis-id": result["output"]}
						} else {
							return map[string]any{"analysis-id": result}
						}
					}

					// Add function response to chat history with proper structure
					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{
								"functionResponse": map[string]any{
									"name":     name,
									"response": result,
								},
							},
						},
					})

					// Display result if it's a string
					if outputStr, ok := result["output"].(string); ok {
						fmt.Println("Result:", outputStr)
					}
				} else {
					fmt.Printf("Function %s not found\n", name)

					// Add error response to chat history
					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{
								"text": fmt.Sprintf("Error: Function '%s' not found", name),
							},
						},
					})
				}
			}
		}

		// Continue the conversation loop
		fmt.Println("---")
	}
}

func (p *AgentAnalysis) NewAgent() {
	model := viper.GetString("ANALYSIS.MODEL")
	if model == "" {
		model = "gemini-1.5-pro"
	}
	endPoints := fmt.Sprintf("https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse", model)

	analysisAgentMeta := repository.AgentMetadata{
		ID:             "analysis-agent-v1",
		Name:           "Analysis Agent",
		Version:        "1.0.0",
		Type:           repository.AgentType(repository.AgentAnalysis),
		Instructions:   repository.AnalysisInstructions,
		LastActive:     time.Now(),
		MaxConcurrency: 5,
		Timeout:        30 * time.Second,
		Status:         "active",
		Tags:           []string{"analysis", "constraints", "inputs", "outputs", "validation"},
		Endpoints: map[string]string{
			"http": endPoints,
		},
	}
	p.Metadata = analysisAgentMeta
	p.Capabilities = AnalysisCapabilities
}

func (p *AgentAnalysis) RequestAgent(contents []map[string]any) map[string]any {
	fmt.Printf("Processing request with Analysis Agent: %s\n", p.Metadata.Name)

	// Build request payload for the AI model
	request := map[string]any{
		"systemInstruction": map[string]any{
			"parts": []map[string]any{
				{"text": p.Metadata.Instructions},
			},
		},
		"toolConfig": map[string]any{
			"functionCallingConfig": map[string]any{
				"mode": "ANY",
			},
		},
		"contents": contents,
		"tools": []map[string]any{
			{"functionDeclarations": GetAnalysisToolsMap()},
		},
	}

	// Marshal request body
	jsonBody, err := json.Marshal(request)
	if err != nil {
		return map[string]any{"error": err.Error(), "output": nil}
	}

	// Retry configuration
	const maxRetries = 5
	const maxWaitTime = 10 * time.Minute

	for attempt := 0; attempt <= maxRetries; attempt++ {
		// Create HTTP request
		req, err := http.NewRequestWithContext(
			context.Background(),
			"POST",
			p.Metadata.Endpoints["http"],
			bytes.NewBuffer(jsonBody),
		)
		if err != nil {
			return map[string]any{"error": err.Error(), "output": nil}
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("X-goog-api-key", viper.GetString("ANALYSIS.API_KEY"))

		// Execute request with timeout
		client := repository.NewStreamingHTTPClient()
		resp, err := client.Do(req)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			// Wait before retrying network errors
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}
		defer resp.Body.Close()

		// Success case - parse streaming response
		if resp.StatusCode == http.StatusOK {
			// Parse SSE stream with real-time display
			streamResp, err := repository.ParseSSEStream(resp.Body, true)
			if err != nil {
				if attempt == maxRetries {
					return map[string]any{"error": err.Error(), "output": nil}
				}
				time.Sleep(repository.ExponentialBackoff(attempt))
				continue
			}

			// Convert to standard output format
			output := repository.ConvertStreamResponseToOutput(streamResp)

			// Save chat history
			historyEntry := repository.BuildChatHistoryFromStream(streamResp, "analysis")
			if historyEntry != nil {
				ChatHistory = append(ChatHistory, historyEntry)
			}

			p.Metadata.LastActive = time.Now()
			return map[string]any{"error": nil, "output": output}
		}

		// Read body for error cases
		bodyBytes, err := io.ReadAll(resp.Body)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Handle rate limit errors (429)
		if resp.StatusCode == http.StatusTooManyRequests {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Rate limit exceeded after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}

			// Parse retry delay from response
			retryDelay := repository.ParseRetryDelay(string(bodyBytes))

			// Use provided delay or fallback to exponential backoff
			var waitTime time.Duration
			if retryDelay > 0 {
				waitTime = retryDelay
			} else {
				waitTime = repository.ExponentialBackoff(attempt)
			}

			// Cap wait time to reasonable maximum
			if waitTime > maxWaitTime {
				waitTime = maxWaitTime
			}

			fmt.Printf("Rate limit hit (attempt %d/%d). Waiting %v before retry...\n",
				attempt+1, maxRetries+1, waitTime)

			time.Sleep(waitTime)
			continue
		}

		// Handle other HTTP errors
		if resp.StatusCode >= 500 && resp.StatusCode < 600 {
			// Server errors - retry with backoff
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Server error after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}

			fmt.Printf("Server error (attempt %d/%d). Waiting %v before retry...\n",
				attempt+1, maxRetries+1, repository.ExponentialBackoff(attempt))

			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Client errors (400-499) except 429 - don't retry
		return map[string]any{
			"error":  fmt.Sprintf("HTTP %d: %s", resp.StatusCode, string(bodyBytes)),
			"output": nil,
		}
	}

	return map[string]any{
		"error":  fmt.Sprintf("Max retries (%d) exceeded", maxRetries),
		"output": nil,
	}
}

// GetProjectStructure returns the project structure as a string, ignoring files and directories specified in .gitignore.
// If a .gitignore file is not found, it uses a default ignore list.
// It takes the project path as input.
func GetProjectStructure(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		fmt.Println(text)
	}

	loadGitIgnore()
	path := args["path"].(string)
	var builder strings.Builder
	builder.WriteString(path + "\n")
	err := getProjectStructureRecursive(path, "", &builder)
	if err != nil {
		return map[string]any{"error": err, "output": nil}
	}

	if builder.String() == "." || builder.String() == "" {
		return map[string]any{"error": nil, "output": "<empty directory>"}
	}
	return map[string]any{"error": nil, "output": builder.String()}
}

// PutAgentOutput converts a generic map into AnalysisAgentOutput and prints/stores the JSON.
func PutAgentOutput(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		fmt.Println(text)
	}

	data, err := json.Marshal(args)
	if err != nil {
		fmt.Println("Error marshaling args:", err)
		return map[string]any{"error": err}
	}
	var output Analysis
	if err := json.Unmarshal(data, &output); err != nil {
		fmt.Println(" Error unmarshaling into AnalysisAgentOutput:", err)
		return map[string]any{"error": err}
	}
	output.OperatingSystem = runtime.GOOS
	output.FilesRead = FilesRead
	AnalysisMap[output.ID] = output

	fmt.Printf("â€¦ Stored analysis for task %s\n", output.ID)

	return map[string]any{"error": nil, "output": output.ID}
}

func TakeInputFromTerminal(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if !ok {
		return map[string]any{"error": "No Text Provided"}
	}
	fmt.Println(text)

	requirements, ok := args["requirements"].([]any)
	if !ok || len(requirements) == 0 {
		return map[string]any{
			"error":  nil,
			"output": map[string]string{"message": "No requirements provided"},
		}
	}

	results := make(map[string]string)
	reader := bufio.NewReader(os.Stdin)

	for _, req := range requirements {
		question, ok := req.(string)
		if !ok {
			continue
		}

		fmt.Printf("dost> %s: ", question)
		input, err := reader.ReadString('\n')
		if err != nil {
			return map[string]any{
				"error":  fmt.Sprintf("Error reading input: %v", err),
				"output": nil,
			}
		}

		input = strings.TrimSpace(input)
		if input == "" {
			results[question] = "<no input provided>"
		} else {
			results[question] = input
		}
		InputData[question] = results[question]
	}

	return map[string]any{"error": nil, "output": results}
}

func ExitProcess(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		fmt.Println(text)
	}

	fmt.Println("--- Task completed successfully! Exiting...")
	return map[string]any{"error": nil, "output": args["analysis-id"], "exit": true}

}
func ReadFiles(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Printf("ANALYSIS: %s", text)
	}

	fileNames, ok := args["file_names"].([]interface{})
	if !ok {
		return map[string]any{
			"error":  "Invalid arguments: 'file_names' must be a slice of strings",
			"output": nil,
		}
	}

	var stringFileNames []string
	for _, v := range fileNames {
		s, ok := v.(string)
		if !ok {
			return map[string]any{
				"error":  "Invalid argument: 'file_names' contains non-string values",
				"output": nil,
			}
		}
		stringFileNames = append(stringFileNames, s)
	}

	readFiles := make(map[string]any)
	var notFoundFiles []string

	for _, fileName := range stringFileNames {
		file, err := os.Open(fileName)
		if err != nil {
			notFoundFiles = append(notFoundFiles, fileName)
			continue
		}
		defer file.Close()

		// Read all lines, skipping empty ones
		scanner := bufio.NewScanner(file)
		var lines []string
		lineNumber := 1
		for scanner.Scan() {
			line := scanner.Text()
			// Skip empty lines but track line numbers
			if strings.TrimSpace(line) != "" {
				// Add line number prefix to non-empty lines
				numberedLine := fmt.Sprintf("%d: %s", lineNumber, line)
				lines = append(lines, numberedLine)
			}
			lineNumber++
		}

		if err := scanner.Err(); err != nil {
			readFiles[fileName] = fmt.Sprintf("Error reading file: %v", err)
			continue
		}

		// Create proper chunks (non-overlapping)
		chunks := []map[string]any{}
		chunkSize := 40
		if len(lines) < 100 {
			chunks = []map[string]any{{
				"start":   1,
				"end":     len(lines),
				"content": strings.Join(lines, "\n"),
			}}
		} else {
			for i := 0; i < len(lines); i += chunkSize {
				end := i + chunkSize
				if end > len(lines) {
					end = len(lines)
				}

				// Build chunk content
				var chunkContent strings.Builder
				for j := i; j < end; j++ {
					chunkContent.WriteString(lines[j])
					if j < end-1 { // Don't add newline after last line in chunk
						chunkContent.WriteString("\n")
					}
				}

				chunks = append(chunks, map[string]any{
					"start":   i + 1,
					"end":     end,
					"content": chunkContent.String(),
				})
			}

			// Handle empty file edge case (all lines were empty)
			if len(lines) == 0 {
				chunks = append(chunks, map[string]any{
					"start":   1,
					"end":     0,
					"content": "",
				})
			}
		}

		readFiles[fileName] = chunks
		// Also append to the global FilesRead map
		FilesRead[fileName] = chunks
		fmt.Printf("Read file: %s (%d non-empty lines, %d chunks)\n", fileName, len(lines), len(chunks))
	}

	if len(notFoundFiles) > 0 {
		fmt.Printf("Files not found: %v\n", notFoundFiles)
	}

	return map[string]any{"error": nil, "output": readFiles}
}

func ExecuteCommands(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Println(text)
	}

	// Get current working directory
	wd, err := os.Getwd()
	if err != nil {
		return map[string]any{"error": err.Error()}
	}

	// Extract command
	cmdStr, ok := args["command"].(string)
	if !ok || cmdStr == "" {
		return map[string]any{"error": "Invalid command"}
	}

	// Extract arguments (as array instead of a single string)
	var argList []string
	if rawArgs, ok := args["arguments"]; ok {
		switch v := rawArgs.(type) {
		case string:
			// split on spaces if user passed a string
			if v != "" {
				argList = strings.Fields(v)
			}
		case []any:
			for _, a := range v {
				if s, ok := a.(string); ok {
					argList = append(argList, s)
				}
			}
		}
	}
	fmt.Println(">DOST\\")
	fmt.Printf("%s %v", cmdStr, argList)
	if !service.TakePermission {
		fmt.Printf("\nAbout to run command in %s:\n> %s\nPress ENTER to continue or Ctrl+C to cancel...", wd, argList)
		bufio.NewReader(os.Stdin).ReadBytes('\n') // wait for Enter
	}

	// Handle `cd` separately
	if cmdStr == "cd" {
		if len(argList) == 0 {
			return map[string]any{"error": "cd requires a path"}
		}
		newDir := argList[0]
		if !filepath.IsAbs(newDir) {
			newDir = filepath.Join(wd, newDir)
		}
		if err := os.Chdir(newDir); err != nil {
			return map[string]any{"error": fmt.Sprintf("failed to change directory: %v", err)}
		}
		return map[string]any{"message": fmt.Sprintf("Changed directory to %s", newDir)}
	}

	// Build command properly
	cmd := exec.Command(cmdStr, argList...)
	cmd.Dir = wd
	var stdoutBuf, stderrBuf bytes.Buffer
	cmd.Stdin = os.Stdin
	cmd.Stdout = io.MultiWriter(os.Stdout, &stdoutBuf)
	cmd.Stderr = io.MultiWriter(os.Stderr, &stderrBuf)

	log.Default().Printf("Running command in %s: %s %v\n", wd, cmdStr, argList)

	err = cmd.Run()
	if err != nil {
		return map[string]any{
			"error": fmt.Sprintf("command failed: [%s %v] %v || CONSOLE/TERMINAL:%v",
				cmdStr, argList, err, stderrBuf.String()),
		}
	}

	return map[string]any{
		"message": "Command executed successfully",
		"output":  stdoutBuf.String(),
	}
}

func getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {
	entries, err := os.ReadDir(path)
	if err != nil {
		return err
	}

	for i, entry := range entries {
		entryPath := filepath.Join(path, entry.Name())

		// skip ignored entries
		if ignoreMatcher != nil {
			relPath, _ := filepath.Rel(".", entryPath)
			if ignoreMatcher.MatchesPath(relPath) {
				continue
			}
		}
		if defaultIgnore[entry.Name()] {
			// âœ… Skip this directory and its contents completely
			if entry.IsDir() {
				continue
			}
		}

		// draw branch
		connector := "â”œâ”€â”€"
		if i == len(entries)-1 {
			connector = "â””â”€â”€"
		}
		builder.WriteString(prefix + connector + " " + entry.Name() + "\n")

		// recursively descend
		if entry.IsDir() {
			subPrefix := prefix
			if i == len(entries)-1 {
				subPrefix += "    "
			} else {
				subPrefix += "â”‚   "
			}
			// ðŸš« Don't go inside ignored directories
			if !defaultIgnore[entry.Name()] {
				err := getProjectStructureRecursive(entryPath, subPrefix, builder)
				if err != nil {
					return err
				}
			}
		}
	}

	return nil
}

func loadGitIgnore() {
	if _, err := os.Stat(".gitignore"); err == nil {
		ignoreMatcher, _ = gitignore.CompileIgnoreFile(".gitignore")
	}
}

var AnalysisCapabilities = []repository.Function{
	{
		Name: "get-project-strucuture",
		Description: `Returns the full directory structure of the project at the given path.
		Call this before working on unfamiliar projects to understand where files are located.
		Respects .gitignore to skip irrelevant files.`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"path": {
					Type:        repository.TypeString,
					Description: "Path to the project directory (usually '.')",
				},
				"text": {
					Type:        repository.TypeString,
					Description: "A text which you want to say to user, instead of returning text output give it in this parameter",
				},
			},
			Required: []string{"path"},
		},
		Service: GetProjectStructure,
		Return: repository.Return{
			"error":  "string",
			"output": "string",
		},
	},
	{
		Name: "read-files",
		Description: `Read and analyze multiple files efficiently in a single operation. 
	
	IMPORTANT: This function can read MULTIPLE files simultaneously - pass ALL file paths you need in the file_names array rather than calling this function multiple times for individual files.
	
	Key features:
	- Reads multiple files in one call (more efficient than multiple separate calls)
	- Automatically skips empty lines to save tokens and improve clarity
	- Adds line numbers to each line for precise reference and debugging
	- Chunks large files automatically for better processing
	- Stores read files globally for reuse across the session
	
	Best practices:
	- Pass ALL required file paths in a single call: ["file1.go", "file2.md", "file3.txt"]
	- Use when you need to analyze code structure, configuration files, documentation, or any text-based content
	- Ideal for cross-file analysis, dependency checking, or comprehensive codebase review
	
	Example usage scenarios:
	- Code analysis: ["main.go", "utils.go", "config.yaml"]
	- Documentation review: ["README.md", "CHANGELOG.md", "API.md"]
	- Configuration audit: ["docker-compose.yml", ".env", "nginx.conf"]
	
	The function returns structured data with line numbers, making it easy to reference specific parts of files in subsequent analysis.`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Optional message to display to the user explaining what files you're reading and why, instead of just returning output silently",
				},
				"file_names": {
					Type:        repository.TypeArray,
					Description: "Array of file paths to read simultaneously. IMPORTANT: Include ALL files you need in this single array rather than making multiple function calls. Examples: ['main.go', 'config.yaml'], ['src/app.js', 'package.json', 'README.md']",
					Items: &repository.Properties{
						Type: "string",
					},
				},
			},
			Required: []string{"file_names"},
		},
		Service: ReadFiles,
		Return: repository.Return{
			"error":  "string - null if successful, error message if failed",
			"output": "object - map of filename to chunks with line numbers and content",
		},
	},
	{
		Name: "put-analysis-agent-output",
		Description: `Stores the output of the analysis agent in the in-memory map.
Use this after completing an analysis to persist the structured result (constraints, inputs, risks, expected output).`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"id": {
					Type:        repository.TypeString,
					Description: "Unique identifier for the analysis task",
				},
				"detail_summary": {
					Type:        repository.TypeString,
					Description: "Detailed summary of the analysis",
				},
				"summary": {
					Type:        repository.TypeString,
					Description: "Concise summary of the analysis",
				},
				"domain": {
					Type:        repository.TypeString,
					Description: "Domain or area of the task (e.g., software, AI, data)",
				},
				"constraints": {
					Type: repository.TypeObject,
					Properties: map[string]*repository.Properties{
						"hard": {
							Type:        repository.TypeArray,
							Items:       &repository.Properties{Type: repository.TypeString},
							Description: "Hard constraints (must follow)",
						},
						"soft": {
							Type:        repository.TypeArray,
							Items:       &repository.Properties{Type: repository.TypeString},
							Description: "Soft constraints (nice to follow)",
						},
					},
				},
				"inputs_detected": {
					Type: repository.TypeObject,
					Properties: map[string]*repository.Properties{
						"files": {
							Type:        repository.TypeArray,
							Items:       &repository.Properties{Type: repository.TypeString},
							Description: "Files detected in the project",
						},
						"environment": {
							Type:        repository.TypeString,
							Description: "Execution environment (Go, Python, Docker, etc.)",
						},
						"language": {
							Type:        repository.TypeString,
							Description: "Programming language(s) involved",
						},
					},
				},
				"risks": {
					Type:        repository.TypeArray,
					Items:       &repository.Properties{Type: repository.TypeString},
					Description: "List of identified risks or blockers",
				},
				"expected_output": {
					Type: repository.TypeObject,
					Properties: map[string]*repository.Properties{
						"format": {
							Type:        repository.TypeString,
							Description: "Format of the output (JSON, text, etc.)",
						},
						"example": {
							Type:        repository.TypeObject,
							Description: "Example of expected output structure",
						},
						"output_type": {
							Type:        repository.TypeString,
							Description: "Type of output (code, report, data, etc.)",
						},
					},
				},
				"text": {
					Type:        repository.TypeString,
					Description: "A text which you want to say to user, instead of returning text output give it in this parameter",
				},
			},
			Required: []string{
				"id",
				"detail_summary",
				"summary",
				"domain",
				"constraints",
				"inputs_detected",
				"risks",
				"expected_output",
				"text",
			},
		},
		Service: PutAgentOutput,
		Return: repository.Return{
			"error":  "string",
			"output": "string",
		},
	},
	{
		Name: "take-input-from-terminal",
		Description: `Prompts the user in the terminal for multiple required inputs.
Use this whenever you are missing essential details, such as:
- File names
- Function parameters
- Configuration values
- User choices`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"requirements": {
					Type:        repository.TypeArray,
					Description: "A list of questions or keys to ask the user for input",
					Items: &repository.Properties{
						Type: "string",
					},
				},
				"text": {
					Type:        repository.TypeString,
					Description: "A text which you want to say to user, instead of returning text output give it in this parameter",
				},
			},
			Required: []string{"requirements", "text"},
		},
		Service: TakeInputFromTerminal,
		Return:  repository.Return{"error": "string", "output": "object"},
	},

	{
		Name: "exit-process",
		Description: `When you feel that the task is fully completed, always call this function to exit the process.
âš ï¸ Important:
- Before calling, make sure all steps are done.
- Put that final compiled text inside the "text" parameter. This is what the user will see as the final answer.`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "The final compiled text output for the user (summary, results, explanations, etc.)",
				},
			},
			Required: []string{"text"},
		},
		Service: ExitProcess,
		Return: repository.Return{
			"error":  "string",
			"output": "string",
		},
	},

	{
		Name: "execute-command-in-terminal",
		Description: `Execute ANY valid shell/terminal command with full system access in the current working directory.
This tool provides COMPLETE command-line interface capabilities, enabling:

ðŸš€ PROJECT MANAGEMENT & SETUP:
- Initialize projects: npm init, cargo new, go mod init, django-admin startproject
- Setup frameworks: create-react-app, vue create, ng new, rails new
- Generate scaffolding: rails generate, ng generate, vue add
- Project templates: cookiecutter, yeoman generators, custom templates

ðŸ“ FILE & DIRECTORY OPERATIONS:
- Navigation: cd, ls, pwd, find, locate, which, whereis
- File management: cp, mv, rm, mkdir, rmdir, touch, ln
- Permissions: chmod, chown, chgrp, umask, getfacl, setfacl
- Content operations: cat, head, tail, grep, sed, awk, sort, uniq
- Archives: tar, zip, unzip, gzip, gunzip, 7z
- File comparison: diff, cmp, comm

ðŸ”§ DEVELOPMENT TOOLS & BUILD SYSTEMS:
- Compilers: gcc, g++, clang, rustc, javac, tsc, babel
- Interpreters: python, node, ruby, php, lua, perl
- Build tools: make, cmake, ninja, gradle, maven, ant, bazel
- Task runners: npm run, yarn, pnpm, gulp, grunt, webpack
- Linters: eslint, pylint, rubocop, clippy, checkstyle
- Formatters: prettier, black, gofmt, rustfmt, clang-format

ðŸ“¦ PACKAGE MANAGEMENT:
- Node.js: npm, yarn, pnpm (install, update, audit, publish)
- Python: pip, pip3, pipenv, poetry, conda
- Rust: cargo (build, test, publish, update)
- Go: go get, go mod (download, tidy, vendor)
- Ruby: gem, bundle
- PHP: composer
- Java: mvn, gradle
- System packages: apt, yum, brew, choco, pacman

ðŸ”„ VERSION CONTROL (GIT & OTHERS):
- Git operations: init, clone, add, commit, push, pull, merge, rebase
- Branch management: checkout, branch, switch, merge, rebase
- History: log, show, diff, blame, reflog
- Stashing: stash, stash pop, stash apply
- Remote management: remote add, fetch, pull, push
- Tags: tag, tag -a, tag -d
- Other VCS: svn, hg, bzr

ðŸ—„ï¸ DATABASE OPERATIONS:
- SQL databases: mysql, psql, sqlite3, sqlcmd
- NoSQL: mongo, redis-cli, couchdb
- Migrations: migrate, flyway, liquibase
- Dumps & restores: mysqldump, pg_dump, mongodump

ðŸŒ NETWORK & API OPERATIONS:
- HTTP requests: curl, wget, httpie
- Network tools: ping, telnet, netstat, ss, lsof
- DNS: nslookup, dig, host
- Certificates: openssl, certbot
- API testing: postman-cli, newman

ðŸ³ CONTAINERIZATION & ORCHESTRATION:
- Docker: build, run, exec, ps, images, compose
- Kubernetes: kubectl (apply, get, describe, logs, exec)
- Container registries: docker push, docker pull
- Orchestration: docker-compose, docker swarm

â˜ï¸ CLOUD & INFRASTRUCTURE:
- AWS CLI: aws s3, ec2, lambda, cloudformation
- Azure CLI: az vm, az storage, az webapp
- Google Cloud: gcloud compute, gsutil
- Terraform: plan, apply, destroy
- Ansible: ansible-playbook, ansible-vault

ðŸ” SYSTEM MONITORING & DEBUGGING:
- Process management: ps, top, htop, kill, killall, jobs
- System info: uname, whoami, id, groups, env
- Disk usage: df, du, fdisk, lsblk
- Memory: free, vmstat
- Performance: iostat, sar, strace, ltrace
- Logs: journalctl, tail -f, grep logs

ðŸ§ª TESTING & QUALITY ASSURANCE:
- Unit tests: pytest, jest, go test, cargo test, rspec
- Integration tests: newman, postman, cypress
- Load testing: ab, siege, wrk, jmeter
- Security scans: nmap, nikto, owasp-zap
- Code coverage: coverage.py, nyc, gocov
- Benchmarking: hyperfine, bench, criterion

ðŸ” SECURITY & ENCRYPTION:
- SSH operations: ssh, scp, ssh-keygen, ssh-add
- Encryption: gpg, openssl, age
- Certificates: certbot, openssl req, keytool
- Password management: pass, 1password-cli
- Security scanning: bandit, safety, audit

ðŸ“Š DATA PROCESSING & ANALYSIS:
- Text processing: sed, awk, grep, sort, cut, tr
- JSON/XML: jq, xmlstarlet, yq
- CSV processing: csvkit, miller
- Data conversion: pandoc, iconv
- Statistical tools: R, octave

ðŸŽ¯ AUTOMATION & SCRIPTING:
- Shell scripting: bash, zsh, fish, powershell
- Task scheduling: cron, at, systemd timers
- Process automation: expect, tmux, screen
- Workflow tools: github-cli, gitlab-ci

ðŸ–¥ï¸ SYSTEM ADMINISTRATION:
- Service management: systemctl, service, launchctl
- User management: useradd, usermod, passwd, su, sudo
- Network configuration: ifconfig, ip, route
- Firewall: iptables, ufw, firewall-cmd
- Package repositories: add-apt-repository, yum-config-manager

ðŸ”§ LANGUAGE-SPECIFIC TOOLS:
- Node.js: node, npm, yarn, npx, nvm
- Python: python, pip, virtualenv, conda, jupyter
- Go: go build, go test, go mod, go generate
- Rust: cargo build, cargo test, cargo publish
- Java: java, javac, maven, gradle
- C/C++: gcc, g++, make, cmake, gdb
- .NET: dotnet build, dotnet run, dotnet test
- Ruby: ruby, gem, bundle, rails
- PHP: php, composer, artisan

âš¡ PERFORMANCE & OPTIMIZATION:
- Profiling: perf, gprof, valgrind, pprof
- Benchmarking: time, hyperfine, ab
- Memory analysis: valgrind, AddressSanitizer
- Code optimization: compiler flags, link-time optimization

ðŸ”„ CI/CD & DEPLOYMENT:
- GitHub Actions: gh workflow, gh run
- Jenkins: jenkins-cli
- Docker deployment: docker deploy, docker service
- Serverless: serverless deploy, sam deploy
- Static sites: netlify, vercel

SYNTAX CHECKING & VALIDATION:
- C/C++: g++ -fsyntax-only, clang -fsyntax-only
- Python: python -m py_compile, python -m flake8
- JavaScript: node --check, eslint
- Go: go vet, go fmt -n
- Rust: cargo check
- JSON: jq empty, python -m json.tool
- YAML: yamllint, python -c "import yaml"
- XML: xmllint --noout

ADVANCED OPERATIONS:
- Parallel processing: parallel, xargs -P
- Process monitoring: watch, timeout
- Binary analysis: objdump, nm, readelf, strings
- System calls: strace, dtrace
- Network debugging: tcpdump, wireshark-cli

IMPORTANT USAGE NOTES:
- This tool has FULL system access - use responsibly
- Can modify files, install software, change system settings
- Can access network resources and external APIs
- Can start/stop services and processes
- Always verify commands before execution in production
- Use appropriate error handling and validation

EXAMPLES:

Project Setup:
{ "command": "npx", "arguments": ["create-react-app", "my-app", "--template", "typescript"] }
{ "command": "cargo", "arguments": ["new", "my-rust-project"] }
{ "command": "django-admin", "arguments": ["startproject", "mysite"] }

Development:
{ "command": "npm", "arguments": ["install", "express", "cors", "dotenv"] }
{ "command": "go", "arguments": ["mod", "init", "github.com/user/project"] }
{ "command": "pip", "arguments": ["install", "-r", "requirements.txt"] }

Git Operations:
{ "command": "git", "arguments": ["clone", "https://github.com/user/repo.git"] }
{ "command": "git", "arguments": ["add", ".", "&&", "git", "commit", "-m", "Initial commit"] }
{ "command": "git", "arguments": ["push", "origin", "main"] }

Testing & Quality:
{ "command": "pytest", "arguments": ["tests/", "-v", "--coverage"] }
{ "command": "eslint", "arguments": ["src/", "--fix"] }
{ "command": "cargo", "arguments": ["test", "--release"] }

System Operations:
{ "command": "docker", "arguments": ["build", "-t", "myapp", "."] }
{ "command": "systemctl", "arguments": ["start", "nginx"] }
{ "command": "curl", "arguments": ["-X", "POST", "https://api.example.com/data"] }

This tool is your gateway to the ENTIRE command-line ecosystem. Use it to automate, build, deploy, test, monitor, and manage any aspect of software development and system administration.`,

		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Optional context message for logging, debugging, or providing additional information about the command execution.",
				},
				"command": {
					Type:        repository.TypeString,
					Description: "The base command to execute. Can be any valid system command, tool, or executable available in the PATH or specified with full path.",
				},
				"arguments": {
					Type: repository.TypeArray,
					Items: &repository.Properties{
						Type:        repository.TypeString,
						Description: "Individual command arguments, flags, options, and parameters.",
					},
					Description: "Array of command arguments. Each element should be a separate argument (proper shell escaping handled automatically).",
				},
			},
			Required: []string{"command"},
			Optional: []string{"text", "arguments"},
		},

		Service: ExecuteCommands,

		Return: repository.Return{
			"error":   "string // Detailed error message including command, arguments, exit code, and stderr output if execution fails.",
			"output":  "string // Complete stdout output from the executed command.",
			"message": "string // Success confirmation message with command execution details.",
		},
	},
}

func init() {
	for _, v := range AnalysisCapabilities {
		AnalysistoolsFunc[v.Name] = v
	}
}

func AnalysisTools() map[string]repository.Function {
	return AnalysistoolsFunc
}

func GetAnalysisTools() []repository.Function {
	return AnalysisCapabilities
}

func GetAnalysisToolsMap() []map[string]any {
	arrayOfMap := make([]map[string]any, 0)
	for _, v := range AnalysisCapabilities {
		arrayOfMap = append(arrayOfMap, v.ToObject())
	}
	return arrayOfMap
}

```

## File: internal/service/orchestrator/orchestrator.go
Language: go | Tokens: 14332 | Size: 57331 bytes

**âš ï¸ Security Issues:**

ðŸŸ¢ **[LOW]** Line 676 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   fmt.Print("dost> ")
   ```

ðŸŸ¢ **[LOW]** Line 1649 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   { "file_names": ["config.json"], "contents": ["{ \"debug\": true }"], "offsets": [0] }
   ```

ðŸŸ¢ **[LOW]** Line 1804 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   - Adds line numbers to each line for precise reference and debugging
   ```

```go
package orchestrator

import (
	"bufio"
	"bytes"
	"context"
	"dost/internal/repository"
	"dost/internal/service"
	"dost/internal/service/analysis"
	"dost/internal/service/interactor"

	"dost/internal/service/coder"
	"dost/internal/service/planner"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"sort"
	"strings"
	"time"

	gitignore "github.com/sabhiram/go-gitignore"

	"github.com/spf13/viper"
)

type TaskStatus string

var OrchestratortoolsFunc map[string]repository.Function = make(map[string]repository.Function)

var TaskMap = make(map[string]Task)

var ChatHistory = make([]map[string]any, 0)

const (
	TaskPending   TaskStatus = "pending"
	TaskRunning   TaskStatus = "running"
	TaskCompleted TaskStatus = "completed"
	TaskFailed    TaskStatus = "failed"
)

var ignoreMatcher *gitignore.GitIgnore

type Task struct {
	ID           string            `json:"id"`
	Description  string            `json:"description"`
	AgentID      string            `json:"agent_id"`
	Inputs       map[string]any    `json:"inputs"`
	Outputs      map[string]any    `json:"outputs"`
	Status       TaskStatus        `json:"status"`
	CreatedAt    time.Time         `json:"created_at"`
	UpdatedAt    time.Time         `json:"updated_at"`
	Dependencies []string          `json:"dependencies"`
	Metadata     map[string]string `json:"metadata"`
}

type AgentOrchestrator repository.Agent

type InitialContext struct {
	OS              string
	Arch            string
	User            string
	Shell           string
	CWD             string
	GoVersion       string
	FolderStructure map[string]any
	InstalledTools  []string
	EnvVars         map[string]string
	ProjectFiles    []string
	ProjectType     string
	GitBranch       string
	InternetAccess  bool
	AgentRole       string
	Capabilities    []string
	Timezone        string
	SessionID       string
}

var defaultIgnore = map[string]bool{
	".git":         true,
	"node_modules": true,
	"vendor":       true,
	".venv":        true,
	".env":         true,
	".idea":        true,
	".vscode":      true,
	"__pycache__":  true,
	".dost":        true,
}

func GetInitialContext() InitialContext {
	ctx := InitialContext{
		OS:              runtime.GOOS,
		Arch:            runtime.GOARCH,
		User:            os.Getenv("USERNAME"),
		Shell:           detectDefaultShell(),
		CWD:             mustGetWorkingDir(),
		FolderStructure: GetProjectStructure(map[string]any{"path": "./"}),
		GoVersion:       runtime.Version(),
		InstalledTools:  detectTools(),
		EnvVars:         getImportantEnvVars(),
		ProjectFiles:    scanProjectFiles(),
		ProjectType:     detectProjectType(),
		GitBranch:       getGitBranch(),
		InternetAccess:  checkInternet(),
		Timezone:        getLocalTimezone(),
		SessionID:       generateSessionID(),
	}
	return ctx
}

func detectDefaultShell() string {
	if runtime.GOOS == "windows" {
		// prefer PowerShell if present
		if _, err := exec.LookPath("powershell"); err == nil {
			return "powershell"
		}
		return "cmd"
	}
	return os.Getenv("SHELL")
}

func mustGetWorkingDir() string {
	dir, err := os.Getwd()
	if err != nil {
		return "."
	}
	return dir
}

func detectTools() []string {
	var found []string
	val := os.Getenv("PATH")
	found = strings.Split(val, ";")
	return found
}

func getImportantEnvVars() map[string]string {
	keys := []string{"PATH", "GOROOT", "GOPATH", "JAVA_HOME"}
	env := make(map[string]string)
	for _, k := range keys {
		if v := os.Getenv(k); v != "" {
			env[k] = v
		}
	}
	return env
}

func scanProjectFiles() []string {
	files := []string{}
	filepath.Walk(".", func(path string, info os.FileInfo, err error) error {
		if err == nil && !info.IsDir() {
			if strings.HasSuffix(path, ".go") ||
				path == "go.mod" || path == "package.json" || path == "requirements.txt" ||
				path == "Dockerfile" || path == "README.md" {
				files = append(files, path)
			}
		}
		return nil
	})
	return files
}

func detectProjectType() string {
	if _, err := os.Stat("go.mod"); err == nil {
		return "Go project"
	}
	if _, err := os.Stat("package.json"); err == nil {
		return "Node.js project"
	}
	if _, err := os.Stat("requirements.txt"); err == nil {
		return "Python project"
	}
	return "Unknown"
}

func getGitBranch() string {
	cmd := exec.Command("git", "rev-parse", "--abbrev-ref", "HEAD")
	out, err := cmd.Output()
	if err != nil {
		return ""
	}
	return strings.TrimSpace(string(out))
}

func checkInternet() bool {
	cmd := exec.Command("ping", "-c", "1", "8.8.8.8")
	if runtime.GOOS == "windows" {
		cmd = exec.Command("ping", "-n", "1", "8.8.8.8")
	}
	if err := cmd.Run(); err != nil {
		return false
	}
	return true
}

func getLocalTimezone() string {
	_, tz := time.Now().Zone()
	return fmt.Sprintf("%d min offset", tz/60)
}

func generateSessionID() string {
	return fmt.Sprintf("%d", time.Now().UnixNano())
}

// Helper function to format files for Orchestrator
func formatFilesForOrchestrator(filesRead map[string]any) string {
	if len(filesRead) == 0 {
		return ""
	}

	var result strings.Builder
	result.WriteString("=== FILES CONTENT ===\n\n")

	for fileName, fileData := range filesRead {
		result.WriteString(fmt.Sprintf("FILE: %s\n", fileName))
		result.WriteString("=" + strings.Repeat("=", len(fileName)+6) + "\n")

		if chunks, ok := fileData.([]map[string]any); ok {
			for _, chunk := range chunks {
				if content, exists := chunk["content"].(string); exists {
					result.WriteString(content)
					result.WriteString("\n")
				}
			}
		}
		result.WriteString("\n" + strings.Repeat("-", 50) + "\n\n")
	}

	return result.String()
}

func (p *AgentOrchestrator) Interaction(args map[string]any) map[string]any {
	InitialContext := GetInitialContext()
	InitialContextBytes, err := json.Marshal(InitialContext)
	if err != nil {
		return map[string]any{"error": "Unable to get initial context"}
	}

	// --- Context Engine: generate codebase context ---
	var codeContext string
	cwd, _ := os.Getwd()
	contextFilePath, err := repository.RunContextEngine(cwd)
	if err != nil {
		fmt.Printf("âš ï¸  Context engine error: %v\n", err)
	} else if contextFilePath != "" {
		contextBytes, err := os.ReadFile(contextFilePath)
		if err != nil {
			fmt.Printf("âš ï¸  Failed to read context file: %v\n", err)
		} else {
			codeContext = string(contextBytes)
			fmt.Printf("ðŸ“Ž Loaded codebase context (%d bytes)\n", len(codeContext))
		}
	}

	// Build consolidated user message
	var userMessage strings.Builder

	// Add files content (from analysis)
	filesContent := formatFilesForOrchestrator(analysis.FilesRead)
	if filesContent != "" {
		userMessage.WriteString(filesContent)
		userMessage.WriteString("\n")
	}

	// Add initial context
	userMessage.WriteString("=== INITIAL CONTEXT ===\n")
	userMessage.WriteString(string(InitialContextBytes))
	userMessage.WriteString("\n\n")

	// Add query
	userMessage.WriteString("=== QUERY ===\n")
	if query, ok := args["query"].(string); ok {
		userMessage.WriteString(query)
	}
	log.Println("TEST: ORCHESTRATOR:  ", userMessage.String()[0:20])

	// Build parts for the first user message
	parts := []map[string]any{}

	// Include codebase context as inline text (compatible with all models)
	if codeContext != "" {
		parts = append(parts, map[string]any{
			"text": "=== CODEBASE CONTEXT ===\n" + codeContext + "\n=== END CODEBASE CONTEXT ===\n",
		})
	}

	// Add the main text part
	parts = append(parts, map[string]any{"text": userMessage.String()})

	// Push consolidated user message into ChatHistory
	ChatHistory = append(ChatHistory, map[string]any{
		"role":  "user",
		"parts": parts,
	})

	for {
		// Check if last model response requires exit instruction
		if len(ChatHistory) > 0 && ChatHistory[len(ChatHistory)-1]["role"] == "model" {
			ChatHistory = append(ChatHistory, map[string]any{
				"role": "user",
				"parts": []map[string]any{
					{
						"text": "If there are no more tasks to do, you can either respond with a final text message directly, or call exit-process with the final text. For simple conversational responses, prefer responding with text directly. For task completions, call exit-process.",
					},
				},
			})
		}

		output := p.RequestAgent(ChatHistory)

		if output["error"] != nil {
			fmt.Println("Error:", output["error"])
			os.Exit(1)
		}

		outputData, ok := output["output"].([]map[string]any)
		if !ok {
			fmt.Println("ERROR CONVERTING OUTPUT")
			return nil
		}

		if len(outputData) == 0 {
			fmt.Println("No output received")
			continue
		}

		// Process each output part
		hasFunctionCall := false
		hasTextOutput := false
		for _, part := range outputData {
			partType, hasType := part["type"].(string)
			if !hasType {
				continue
			}

			switch partType {
			case "text":
				// Text was already streamed in real-time by ParseSSEStream.
				// Nothing to do here â€” it's already displayed.
				hasTextOutput = true

			case "functionCall":
				hasFunctionCall = true
				name, nameOK := part["name"].(string)
				argsData, argsOK := part["args"].(map[string]any)
				if !nameOK || !argsOK {
					fmt.Println("Error: invalid function call data")
					continue
				}

				fmt.Println("Calling function:", name)
				if function, exists := OrchestratortoolsFunc[name]; exists {
					result := function.Run(argsData)

					// Check for exit condition
					if _, ok := result["exit"].(bool); ok {
						return nil
					}

					// Add function response to chat history
					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{
								"functionResponse": map[string]any{
									"name":     name,
									"response": result,
								},
							},
						},
					})

					if outputStr, ok := result["output"].(string); ok {
						fmt.Println("Result:", outputStr)
					}
				} else {
					fmt.Printf("Function %s not found\n", name)

					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{"text": fmt.Sprintf("Error: Function '%s' not found", name)},
						},
					})
				}
			}
		}

		// If the model responded with only text (no function calls),
		// treat it as the final response and exit the loop.
		if hasTextOutput && !hasFunctionCall {
			return nil
		}

		fmt.Println("---")
	}
}

func (p *AgentOrchestrator) NewAgent() {
	model := viper.GetString("ORCHESTRATOR.MODEL")
	if model == "" {
		model = "gemini-1.5-pro"
	}
	endPoints := fmt.Sprintf("https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse", model)

	analysisAgentMeta := repository.AgentMetadata{
		ID:             "Orchestrator-agent-v1",
		Name:           "Orchestrator Agent",
		Version:        "1.0.0",
		Type:           repository.AgentType(repository.AgentOrchestrator),
		Instructions:   repository.OrchestratorInstructions,
		LastActive:     time.Now(),
		MaxConcurrency: 5,
		Timeout:        30 * time.Second,
		Status:         "active",
		Tags:           []string{"analysis", "constraints", "inputs", "outputs", "validation"},
		Endpoints: map[string]string{
			"http": endPoints,
		},
	}
	p.Metadata = analysisAgentMeta
	p.Capabilities = OrchestratorCapabilities
}
func AskAnAgent(args map[string]any) map[string]any {

	text, ok := args["text"].(string)
	if ok {
		fmt.Println(text)
	}

	agentID, ok := args["agent_id"].(string)
	if !ok || agentID == "" {
		return map[string]any{
			"error":  "missing or invalid agent_id",
			"output": nil,
		}
	}

	task, ok := args["task"].(string)
	if !ok {
		return map[string]any{
			"error":  "missing or invalid task",
			"output": nil,
		}
	}

	var result map[string]any

	switch agentID {
	// case "analysis":

	// 	anaAgent := analysis.AgentAnalysis{}
	// 	anaAgent.NewAgent()
	// 	query := map[string]any{
	// 		"query": fmt.Sprintf("Here is the Task run an analysis for this task: \" %s\", ", task),
	// 	}
	// 	fmt.Println(query["query"])
	// 	analysisOutPut := anaAgent.Interaction(query)["analysis-id"]
	// 	analysisOutPutStr, ok := analysisOutPut.(string)
	// 	if ok {
	// 		analysisResult := analysis.AnalysisMap[analysisOutPutStr]
	// 		jsonBytes, err := json.MarshalIndent(analysisResult, "", "  ")
	// 		if err != nil {
	// 			fmt.Println("X Error marshalling JSON:", err)
	// 			return nil
	// 		}
	// 		result = map[string]any{"analysis": string(jsonBytes)}
	// 	} else {
	// 		result = map[string]any{"analysis": analysisOutPut}
	// 	}

	case "planner":
		planAgent := planner.AgentPlanner{}
		planAgent.NewAgent()
		planAgent.Interaction(map[string]any{
			"query": fmt.Sprintf("Here is the Task do a detail planning for this task: \" %s\", ", task),
		})
	case "coder":
		// Enhanced version with proper analysis checking and query enhancement
		analysis_id, hasAnalysisId := args["analysis-id"].(string)
		task, hasTask := args["task"].(string)

		if !hasTask {
			return map[string]any{
				"error":  "missing task parameter",
				"output": nil,
			}
		}

		var query map[string]any
		anaAgent := coder.AgentCoder{}
		anaAgent.NewAgent()

		// Check if analysis ID is provided and valid
		if hasAnalysisId && analysis_id != "" {
			prevAnalysis, analysisExists := analysis.AnalysisMap[analysis_id]

			if analysisExists {
				// Analysis found - include it in the query
				analysisForCoder, err := json.Marshal(prevAnalysis)
				if err != nil {
					return map[string]any{
						"error": "Error marshaling analysis data",
					}
				}

				// Enhanced query with analysis context
				query = map[string]any{
					"query": fmt.Sprintf(`CONTEXT: Previous Analysis Available
=====================================
%s

CURRENT TASK
=============
%s

INSTRUCTIONS
============
- Use the above analysis as context to inform your approach
- Build upon the insights from the previous analysis
- Ensure consistency with previous findings where applicable
- If the analysis contradicts the current task, prioritize the task requirements
- Provide detailed reasoning for your implementation decisions
- Do not hallucinate or make assumptions not supported by the analysis or task requirements`,
						string(analysisForCoder), task),
				}

				fmt.Printf("Using existing analysis (ID: %s) for enhanced query\n", analysis_id)
			} else {
				// Analysis ID provided but not found - log warning and proceed with basic query
				fmt.Printf("Warning: Analysis ID '%s' not found in AnalysisMap, proceeding with basic query\n", analysis_id)

				query = map[string]any{
					"query": fmt.Sprintf(`TASK
=====
%s

INSTRUCTIONS
============
- Analyze the task requirements thoroughly
- Provide a comprehensive implementation approach
- Consider edge cases and potential issues
- Ensure code quality and best practices
- Do not hallucinate or make unfounded assumptions`, task),
				}
			}
		} else {
			// No analysis ID provided - use enhanced basic query
			fmt.Println("No analysis ID provided, using enhanced basic query")

			query = map[string]any{
				"query": fmt.Sprintf(`TASK
=====
%s

INSTRUCTIONS
============
- Perform thorough analysis of the task requirements
- Break down complex requirements into manageable components
- Consider potential challenges and solutions
- Provide clear implementation strategy
- Follow coding best practices and standards
- Ensure comprehensive error handling
- Do not make assumptions beyond what's explicitly stated`, task),
			}
		}

		fmt.Printf("Generated Query:\n%s\n", query["query"])

		// Execute the agent interaction
		coderid := anaAgent.Interaction(query)["coder-id"].(string)
		result = map[string]any{
			"coder": coderid,
		}
	case "interactor":
		interAgent := interactor.AgentInteractor{}
		interAgent.NewAgent()
		query := map[string]any{"query": " Here is the Task do the task: \" " + task + "\",. Make sure to use the analysis-id and coder-id if provided in args."}
		interactorid := interAgent.Interaction(query)["interactor-id"].(string)
		result = map[string]any{
			"interactor": interactorid,
		}
	default:
		return map[string]any{
			"error":  fmt.Sprintf("unknown agent: %s", agentID),
			"output": nil,
		}
	}
	fmt.Println(result)

	return map[string]any{
		"error":  nil,
		"output": result,
	}
}

func CreateTasks(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Println(text)
	}
	rawTasks, ok := args["tasks"].([]interface{})
	if !ok {
		return map[string]any{"error": "missing or invalid 'tasks' (must be array)", "output": nil}
	}

	var createdTasks []Task

	for _, t := range rawTasks {
		taskArgs, ok := t.(map[string]any)
		if !ok {
			return map[string]any{"error": "each task must be an object", "output": nil}
		}

		id, ok := taskArgs["id"].(string)
		if !ok || id == "" {
			return map[string]any{"error": "each task must have a valid 'id'", "output": nil}
		}

		description, _ := taskArgs["description"].(string)
		agentID, _ := taskArgs["agent_id"].(string)

		task := Task{
			ID:          id,
			Description: description,
			AgentID:     agentID,
			Inputs:      make(map[string]any),
			Outputs:     make(map[string]any),
			Status:      TaskPending,
			CreatedAt:   time.Now(),
			UpdatedAt:   time.Now(),
		}

		// Optional fields
		if inputs, ok := taskArgs["inputs"].(map[string]any); ok {
			task.Inputs = inputs
		}
		if deps, ok := taskArgs["dependencies"].([]string); ok {
			task.Dependencies = deps
		}
		if meta, ok := taskArgs["metadata"].(map[string]string); ok {
			task.Metadata = meta
		}

		// Save in TaskMap
		TaskMap[task.ID] = task
		createdTasks = append(createdTasks, task)

		fmt.Printf("âœ… Created Task: %s (%s)\n", task.ID, task.Description)
	}

	return map[string]any{
		"error":  nil,
		"output": createdTasks,
	}
}

func TakeInputFromTerminal(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if !ok {
		return map[string]any{"error": "No Text Provided"}
	}
	fmt.Println(text)

	requirements, ok := args["requirements"].([]any)
	reader := bufio.NewReader(os.Stdin)

	// Case 1: No requirements -> just take a single input
	if !ok || len(requirements) == 0 {
		fmt.Print("dost> ")
		input, err := reader.ReadString('\n')
		if err != nil {
			return map[string]any{
				"error":  fmt.Sprintf("Error reading input: %v", err),
				"output": nil,
			}
		}
		input = strings.TrimSpace(input)
		if input == "" {
			return map[string]any{"error": nil, "output": "<no input provided>"}
		}
		return map[string]any{"error": nil, "output": input}
	}

	// Case 2: Requirements exist -> ask each question
	results := make(map[string]string)
	for _, req := range requirements {
		question, ok := req.(string)
		if !ok {
			continue
		}

		fmt.Printf("dost> %s: ", question)
		input, err := reader.ReadString('\n')
		if err != nil {
			return map[string]any{
				"error":  fmt.Sprintf("Error reading input: %v", err),
				"output": nil,
			}
		}

		input = strings.TrimSpace(input)
		if input == "" {
			results[question] = "<no input provided>"
		} else {
			results[question] = input
		}
	}

	return map[string]any{"error": nil, "output": results}
}

func ExitProcess(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		repository.StreamText(text)
	}

	fmt.Println("--- Task completed successfully! Exiting...")
	return map[string]any{"error": nil, "output": "Process exited successfully", "exit": true}

}

func ReadFiles(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Printf("ORCHESTRATOR: %s", text)
	}

	fileNames, ok := args["file_names"].([]interface{})
	if !ok {
		return map[string]any{
			"error":  "Invalid arguments: 'file_names' must be a slice of strings",
			"output": nil,
		}
	}

	var stringFileNames []string
	for _, v := range fileNames {
		s, ok := v.(string)
		if !ok {
			return map[string]any{
				"error":  "Invalid argument: 'file_names' contains non-string values",
				"output": nil,
			}
		}
		stringFileNames = append(stringFileNames, s)
	}

	readFiles := make(map[string]any)
	var notFoundFiles []string

	for _, fileName := range stringFileNames {
		file, err := os.Open(fileName)
		if err != nil {
			notFoundFiles = append(notFoundFiles, fileName)
			continue
		}
		defer file.Close()

		// Read all lines, skipping empty ones
		scanner := bufio.NewScanner(file)
		var lines []string
		lineNumber := 1
		for scanner.Scan() {
			line := scanner.Text()
			// Skip empty lines but track line numbers
			if strings.TrimSpace(line) != "" {
				// Add line number prefix to non-empty lines
				numberedLine := fmt.Sprintf("%d: %s", lineNumber, line)
				lines = append(lines, numberedLine)
			}
			lineNumber++
		}

		if err := scanner.Err(); err != nil {
			readFiles[fileName] = fmt.Sprintf("Error reading file: %v", err)
			continue
		}

		// Create proper chunks (non-overlapping)
		chunks := []map[string]any{}
		chunkSize := 40
		if len(lines) < 100 {
			chunks = []map[string]any{{
				"start":   1,
				"end":     len(lines),
				"content": strings.Join(lines, "\n"),
			}}
		} else {
			for i := 0; i < len(lines); i += chunkSize {
				end := i + chunkSize
				if end > len(lines) {
					end = len(lines)
				}

				// Build chunk content
				var chunkContent strings.Builder
				for j := i; j < end; j++ {
					chunkContent.WriteString(lines[j])
					if j < end-1 { // Don't add newline after last line in chunk
						chunkContent.WriteString("\n")
					}
				}

				chunks = append(chunks, map[string]any{
					"start":   i + 1,
					"end":     end,
					"content": chunkContent.String(),
				})
			}

			// Handle empty file edge case (all lines were empty)
			if len(lines) == 0 {
				chunks = append(chunks, map[string]any{
					"start":   1,
					"end":     0,
					"content": "",
				})
			}
		}

		readFiles[fileName] = chunks
		// Also append to the global FilesRead map
		analysis.FilesRead[fileName] = chunks
		fmt.Printf("Read file: %s (%d non-empty lines, %d chunks)\n", fileName, len(lines), len(chunks))
	}

	if len(notFoundFiles) > 0 {
		fmt.Printf("Files not found: %v\n", notFoundFiles)
	}

	return map[string]any{"error": nil, "output": readFiles}
}

func WriteFile(args map[string]any) map[string]any {
	/*
		args : {
			file_names : [ "test.txt" ],
			contents : [ "hello world" ],
			offsets: [ 0 ]
		}
	*/
	fileNames, hasFileNames := args["file_names"]
	contents, hasContents := args["contents"]
	offsets, hasOffsets := args["offsets"]

	if !hasFileNames || !hasContents {
		return map[string]any{"error": "Invalid arguments: file_names and contents required", "output": nil}
	}

	// Type assertions
	fileNamesSlice, ok1 := fileNames.([]interface{})
	contentsSlice, ok2 := contents.([]interface{})
	offsetsSlice, _ := offsets.([]interface{})

	if !ok1 || !ok2 {
		return map[string]any{"error": "Invalid arguments: file_names and contents must be slices", "output": nil}
	}
	// Check if offsets are provided and if the length matches
	if hasOffsets && len(offsetsSlice) != len(fileNamesSlice) {
		return map[string]any{"error": "Invalid arguments: offsets must have the same length as file_names", "output": nil}
	}

	if len(fileNamesSlice) != len(contentsSlice) {
		return map[string]any{"error": "Invalid arguments: file_names and contents must have the same length", "output": nil}
	}

	var errors []error
	var modifiedFiles []string

	for i, v := range fileNamesSlice {
		fileName := v.(string)
		if isCodingFile(fileName) {
			return map[string]any{
				"error": fmt.Sprintf("OPERATION BLOCKED: '%s' appears to be a programming/coding file. This function is restricted to text-only files (.txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex) to prevent accidental modification of source code.", fileName),
			}
		}

		// SECURITY CHECK: Verify this is an allowed text file type
		if !isAllowedTextFile(fileName) {
			return map[string]any{
				"error": fmt.Sprintf("OPERATION BLOCKED: '%s' file type is not allowed. Only text files (.txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex) can be edited by this function.", fileName),
			}
		}
		content := contentsSlice[i].(string)

		// Determine the offset for the current file
		var offset int64
		if hasOffsets {
			offset = int64(offsetsSlice[i].(float64))
			if offset < 0 {
				errors = append(errors, fmt.Errorf("invalid offset for file %s: offset must be non-negative", fileName))
				continue
			}
		}

		// Check if file exists. If not, open it to create it.
		file, err := os.OpenFile(fileName, os.O_WRONLY|os.O_CREATE, 0644)
		if err != nil {
			errors = append(errors, fmt.Errorf("failed to open/create file %s: %v", fileName, err))
			continue
		}
		defer file.Close()

		// Seek to the specified offset before writing
		_, err = file.Seek(offset, os.SEEK_SET)
		if err != nil {
			errors = append(errors, fmt.Errorf("failed to seek to offset for file %s: %v", fileName, err))
			continue
		}

		// Write the content to the file
		_, err = file.WriteString(content)
		if err != nil {
			errors = append(errors, fmt.Errorf("failed to write to file %s: %v", fileName, err))
			continue
		}

		fmt.Printf("Modified file: %s at offset %d\n", fileName, offset)
		modifiedFiles = append(modifiedFiles, fileName)
	}

	if len(errors) > 0 {
		return map[string]any{
			"error":  fmt.Sprintf("Errors: %v", errors),
			"output": fmt.Sprintf("Partially completed. Modified files: %v", modifiedFiles),
		}
	}

	return map[string]any{
		"error":  nil,
		"output": fmt.Sprintf("Files modified successfully: %v", modifiedFiles),
	}
}
func (p *AgentOrchestrator) RequestAgent(contents []map[string]any) map[string]any {
	fmt.Printf("Processing request with Orchestrator Agent: %s\n", p.Metadata.Name)

	// Build request payload
	request := map[string]any{
		"systemInstruction": map[string]any{
			"parts": []map[string]any{
				{"text": p.Metadata.Instructions},
			},
		},
		"toolConfig": map[string]any{
			"functionCallingConfig": map[string]any{
				"mode": "AUTO",
			},
		},
		"contents": contents,
		"tools": []map[string]any{
			{"functionDeclarations": GetOrchestratorToolsMap()},
		},
	}

	// Marshal request
	jsonBody, err := json.Marshal(request)
	if err != nil {
		return map[string]any{"error": err.Error(), "output": nil}
	}

	// Retry configuration
	const maxRetries = 5
	const maxWaitTime = 10 * time.Minute

	for attempt := 0; attempt <= maxRetries; attempt++ {
		// Create HTTP request
		req, err := http.NewRequestWithContext(
			context.Background(),
			"POST",
			p.Metadata.Endpoints["http"],
			bytes.NewBuffer(jsonBody),
		)
		if err != nil {
			return map[string]any{"error": err.Error(), "output": nil}
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("X-goog-api-key", viper.GetString("ORCHESTRATOR.API_KEY"))

		// Execute request with streaming-optimized client
		client := repository.NewStreamingHTTPClient()
		resp, err := client.Do(req)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}
		defer resp.Body.Close()

		// Success case - parse streaming response
		if resp.StatusCode == http.StatusOK {
			// Parse SSE stream with real-time display
			streamResp, err := repository.ParseSSEStream(resp.Body, true)
			if err != nil {
				if attempt == maxRetries {
					return map[string]any{"error": err.Error(), "output": nil}
				}
				time.Sleep(repository.ExponentialBackoff(attempt))
				continue
			}

			// Convert to standard output format
			output := repository.ConvertStreamResponseToOutput(streamResp)

			// Save chat history
			historyEntry := repository.BuildChatHistoryFromStream(streamResp, "orchestrator")
			if historyEntry != nil {
				ChatHistory = append(ChatHistory, historyEntry)
			}

			p.Metadata.LastActive = time.Now()
			return map[string]any{"error": nil, "output": output}
		}

		// Read body for error cases
		bodyBytes, err := io.ReadAll(resp.Body)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Handle 429 Too Many Requests
		if resp.StatusCode == http.StatusTooManyRequests {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Rate limit exceeded after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}
			retryDelay := repository.ParseRetryDelay(string(bodyBytes))
			waitTime := retryDelay
			if waitTime <= 0 {
				waitTime = repository.ExponentialBackoff(attempt)
			}
			if waitTime > maxWaitTime {
				waitTime = maxWaitTime
			}
			fmt.Printf("Orchestrator rate limit hit (attempt %d/%d). Waiting %v...\n",
				attempt+1, maxRetries+1, waitTime)
			time.Sleep(waitTime)
			continue
		}

		// Retry 5xx server errors
		if resp.StatusCode >= 500 && resp.StatusCode < 600 {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Server error after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}
			fmt.Printf("Orchestrator server error (attempt %d/%d). Retrying...\n",
				attempt+1, maxRetries+1)
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Fail fast on other 4xx
		return map[string]any{
			"error":  fmt.Sprintf("HTTP %d: %s", resp.StatusCode, string(bodyBytes)),
			"output": nil,
		}
	}

	return map[string]any{
		"error":  fmt.Sprintf("Max retries (%d) exceeded", maxRetries),
		"output": nil,
	}
}

func ExecuteCommands(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Println(text)
	}

	// Get current working directory
	wd, err := os.Getwd()
	if err != nil {
		return map[string]any{"error": err.Error()}
	}

	// Extract command
	cmdStr, ok := args["command"].(string)
	if !ok || cmdStr == "" {
		return map[string]any{"error": "Invalid command"}
	}

	// Extract arguments (as array instead of a single string)
	var argList []string
	if rawArgs, ok := args["arguments"]; ok {
		switch v := rawArgs.(type) {
		case string:
			// split on spaces if user passed a string
			if v != "" {
				argList = strings.Fields(v)
			}
		case []any:
			for _, a := range v {
				if s, ok := a.(string); ok {
					argList = append(argList, s)
				}
			}
		}
	}
	fmt.Println(">DOST\\")
	fmt.Printf("%s %v", cmdStr, argList)
	if !service.TakePermission {
		fmt.Printf("\nAbout to run command in %s:\n> %s\nPress ENTER to continue or Ctrl+C to cancel...", wd, argList)
		bufio.NewReader(os.Stdin).ReadBytes('\n') // wait for Enter
	}
	// Handle `cd` separately
	if cmdStr == "cd" {
		if len(argList) == 0 {
			return map[string]any{"error": "cd requires a path"}
		}
		newDir := argList[0]
		if !filepath.IsAbs(newDir) {
			newDir = filepath.Join(wd, newDir)
		}
		if err := os.Chdir(newDir); err != nil {
			return map[string]any{"error": fmt.Sprintf("failed to change directory: %v", err)}
		}
		return map[string]any{"message": fmt.Sprintf("Changed directory to %s", newDir)}
	}

	// Build command properly
	cmd := exec.Command(cmdStr, argList...)
	cmd.Dir = wd
	var stdoutBuf, stderrBuf bytes.Buffer
	cmd.Stdin = os.Stdin
	cmd.Stdout = io.MultiWriter(os.Stdout, &stdoutBuf)
	cmd.Stderr = io.MultiWriter(os.Stderr, &stderrBuf)

	log.Default().Printf("Running command in %s: %s %v\n", wd, cmdStr, argList)

	err = cmd.Run()
	if err != nil {
		return map[string]any{
			"error": fmt.Sprintf("command failed: [%s %v] %v || CONSOLE/TERMINAL:%v",
				cmdStr, argList, err, stderrBuf.String()),
		}
	}

	return map[string]any{
		"message": "Command executed successfully",
		"output":  stdoutBuf.String(),
	}
}
func EditFile(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Printf("ORCHESTRATOR: %s\n", text)
	}

	filepathInput, ok := args["file_path"].(string)
	if !ok {
		return map[string]any{"error": "ERROR READING PATH"}
	}

	// SECURITY CHECK: Verify this is not a coding file
	if isCodingFile(filepathInput) {
		return map[string]any{
			"error": fmt.Sprintf("OPERATION BLOCKED: '%s' appears to be a programming/coding file. This function is restricted to text-only files (.txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex) to prevent accidental modification of source code.", filepathInput),
		}
	}

	// SECURITY CHECK: Verify this is an allowed text file type
	if !isAllowedTextFile(filepathInput) {
		return map[string]any{
			"error": fmt.Sprintf("OPERATION BLOCKED: '%s' file type is not allowed. Only text files (.txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex) can be edited by this function.", filepathInput),
		}
	}

	changes, ok := args["changes"].([]interface{})
	if !ok {
		return map[string]any{"error": "REQUIRED CHANGES MAP"}
	}

	// Convert changes into structured format
	type changeInfo struct {
		startLine int
		startCol  int
		endLine   int
		endCol    int
		operation string
		content   string
	}

	toInt := func(v any) (int, bool) {
		switch val := v.(type) {
		case float64:
			return int(val), true
		case int:
			return val, true
		default:
			return 0, false
		}
	}

	var processedChanges []changeInfo
	for _, c := range changes {
		ch, ok := c.(map[string]any)
		if !ok {
			return map[string]any{"error": "INVALID CHANGE FORMAT"}
		}

		startLine, _ := toInt(ch["start_line_number"])
		startCol, _ := toInt(ch["start_line_col"])
		endLine, _ := toInt(ch["end_line_number"])
		endCol, _ := toInt(ch["end_line_col"])
		operation, _ := ch["operation"].(string)
		content, _ := ch["content"].(string)

		processedChanges = append(processedChanges, changeInfo{
			startLine: startLine,
			startCol:  startCol,
			endLine:   endLine,
			endCol:    endCol,
			operation: operation,
			content:   content,
		})
	}

	// Sort changes by start line & col (descending to avoid position conflicts)
	sort.Slice(processedChanges, func(i, j int) bool {
		if processedChanges[i].startLine == processedChanges[j].startLine {
			return processedChanges[i].startCol > processedChanges[j].startCol
		}
		return processedChanges[i].startLine > processedChanges[j].startLine
	})

	// Read entire file into memory first
	fileContent, err := os.ReadFile(filepathInput)
	if err != nil {
		return map[string]any{"error": "CANNOT READ INPUT FILE: " + err.Error()}
	}

	lines := strings.Split(string(fileContent), "\n")

	// Apply changes from last to first (to maintain line numbers)
	for _, change := range processedChanges {
		switch change.operation {
		case "delete":
			if change.startLine > 0 && change.endLine <= len(lines) {
				// Delete lines (1-indexed to 0-indexed)
				start := change.startLine - 1
				end := change.endLine
				if end > len(lines) {
					end = len(lines)
				}
				lines = append(lines[:start], lines[end:]...)
			}

		case "replace":
			if change.startLine > 0 && change.startLine <= len(lines) {
				lineIdx := change.startLine - 1
				if lineIdx < len(lines) {
					line := lines[lineIdx]
					if change.startCol <= len(line) && change.endCol <= len(line) {
						newLine := line[:change.startCol] + change.content + line[change.endCol:]
						lines[lineIdx] = newLine
					}
				}
			}

		case "write":
			if change.startLine > 0 && change.startLine <= len(lines) {
				lineIdx := change.startLine - 1
				if lineIdx < len(lines) {
					line := lines[lineIdx]
					if change.startCol <= len(line) {
						newLine := line[:change.startCol] + change.content + line[change.startCol:]
						lines[lineIdx] = newLine
					}
				}
			}
		}
	}

	// Write back to original file
	newContent := strings.Join(lines, "\n")
	err = os.WriteFile(filepathInput, []byte(newContent), 0644)
	if err != nil {
		return map[string]any{"error": "CANNOT WRITE TO FILE: " + err.Error()}
	}

	return map[string]any{
		"output": fmt.Sprintf("Successfully edited text file: %s", filepathInput),
	}
}
func GetProjectStructure(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		fmt.Println(text)
	}

	loadGitIgnore()
	path := args["path"].(string)
	var builder strings.Builder
	builder.WriteString(path + "\n")
	err := getProjectStructureRecursive(path, "", &builder)
	if err != nil {
		return map[string]any{"error": err, "output": nil}
	}

	if builder.String() == "." || builder.String() == "" {
		return map[string]any{"error": nil, "output": "<empty directory>"}
	}
	return map[string]any{"error": nil, "output": builder.String()}
}
func loadGitIgnore() {
	if _, err := os.Stat(".gitignore"); err == nil {
		ignoreMatcher, _ = gitignore.CompileIgnoreFile(".gitignore")
	}
}
func getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {
	entries, err := os.ReadDir(path)
	if err != nil {
		return err
	}

	for i, entry := range entries {
		entryPath := filepath.Join(path, entry.Name())

		// skip ignored entries
		if ignoreMatcher != nil {
			relPath, _ := filepath.Rel(".", entryPath)
			if ignoreMatcher.MatchesPath(relPath) {
				continue
			}
		}
		if defaultIgnore[entry.Name()] {
			// âœ… Skip this directory and its contents completely
			if entry.IsDir() {
				continue
			}
		}

		// draw branch
		connector := "â”œâ”€â”€"
		if i == len(entries)-1 {
			connector = "â””â”€â”€"
		}
		builder.WriteString(prefix + connector + " " + entry.Name() + "\n")

		// recursively descend
		if entry.IsDir() {
			subPrefix := prefix
			if i == len(entries)-1 {
				subPrefix += "    "
			} else {
				subPrefix += "â”‚   "
			}
			// ðŸš« Don't go inside ignored directories
			if !defaultIgnore[entry.Name()] {
				err := getProjectStructureRecursive(entryPath, subPrefix, builder)
				if err != nil {
					return err
				}
			}
		}
	}

	return nil
}
func isAllowedTextFile(filePath string) bool {
	// Get file extension and convert to lowercase
	ext := strings.ToLower(filepath.Ext(filePath))

	// Define allowed text file extensions
	allowedExtensions := map[string]bool{
		".txt":  true, // Plain text files
		".md":   true, // Markdown files
		".rst":  true, // reStructuredText files
		".log":  true, // Log files
		".csv":  true, // Comma-separated values
		".json": true, // JSON data files
		".xml":  true, // XML files
		".yaml": true, // YAML files
		".yml":  true, // YAML files (alternate extension)
		".html": true, // HTML markup (content files, not code)
		".css":  true, // CSS stylesheets (content files, not code)
		".ini":  true, // Configuration files
		".cfg":  true, // Configuration files
		".conf": true, // Configuration files
		".rtf":  true, // Rich Text Format
		".tex":  true, // LaTeX files
		"":      true, // Files without extension (often text files)
	}

	return allowedExtensions[ext]
}

// isCodingFile checks if the file extension belongs to programming/coding files
func isCodingFile(filePath string) bool {
	ext := strings.ToLower(filepath.Ext(filePath))

	codingExtensions := map[string]bool{

		".go":    true, // Go
		".py":    true, // Python
		".js":    true, // JavaScript
		".ts":    true, // TypeScript
		".jsx":   true, // React JSX
		".tsx":   true, // TypeScript JSX
		".java":  true, // Java
		".c":     true, // C
		".cpp":   true, // C++
		".cc":    true, // C++
		".cxx":   true, // C++
		".h":     true, // C/C++ headers
		".hpp":   true, // C++ headers
		".php":   true, // PHP
		".rb":    true, // Ruby
		".swift": true, // Swift
		".kt":    true, // Kotlin
		".rs":    true, // Rust
		".vue":   true, // Vue.js
		".scala": true, // Scala
		".r":     true, // R
		".m":     true, // Objective-C/MATLAB
		".pl":    true, // Perl
		".lua":   true, // Lua
		".dart":  true, // Dart
		".elm":   true, // Elm
		".clj":   true, // Clojure
		".hs":    true, // Haskell
		".f90":   true, // Fortran
		".pas":   true, // Pascal
		".asm":   true, // Assembly

		".sh":   true, // Shell scripts
		".bash": true, // Bash scripts
		".zsh":  true, // Zsh scripts
		".fish": true, // Fish scripts
		".bat":  true, // Windows batch files
		".cmd":  true, // Windows command files
		".ps1":  true, // PowerShell scripts

		".sql": true, // SQL files

		".makefile":   true, // Makefiles
		".dockerfile": true, // Docker files
		".gradle":     true, // Gradle build files
		".maven":      true, // Maven files
		".cmake":      true, // CMake files
	}

	return codingExtensions[ext]
}

var OrchestratorCapabilities = []repository.Function{{
	Name: "execute-command-in-terminal",
	Description: `Run any valid shell/terminal command in the current working directory. 
Use for:
- File operations (create, delete, list, copy files, move files, rename files)
- Navigation (cd, ls)
- Package management (npm, pip, go, dart, flutter, etc.)
- Build tools (make, go build, flutter build, etc.)
- Executing programs, checking versions, inspecting system state
- Git operations (status, diff, add, commit, push, pull, log, branch, etc.)

Always provide the command and arguments separately.
Example: { "command": "git", "arguments": ["commit", "-m", "testing through this tool"] }`,

	Parameters: repository.Parameters{
		Type: repository.TypeObject,
		Properties: map[string]*repository.Properties{
			"command": {
				Type:        repository.TypeString,
				Description: "Base command to execute (e.g., git, go, npm, python, ls)",
			},
			"arguments": {
				Type: repository.TypeArray,
				Items: &repository.Properties{
					Type:        repository.TypeString,
					Description: "Each argument passed separately (e.g., [\"commit\", \"-m\", \"msg\"])",
				},
				Description: "Optional arguments for the command as an array",
			},
		},
		Required: []string{"command"},
		Optional: []string{"arguments"},
	},

	Service: ExecuteCommands,

	Return: repository.Return{
		"error":  "string",
		"output": "string",
	},
},
	{
		Name:        "edit-file",
		Description: "Edits ONLY text-based files (txt, md, rst, log, csv, json, xml, yaml, yml, html, css, ini, cfg, conf, rtf, tex) at a given path by applying specified changes. This function is STRICTLY RESTRICTED to non-coding files to prevent accidental modification of source code. Programming files (.go, .py, .js, .java, .c, .cpp, .h, .php, .rb, .swift, .kt, .rs, .ts, .jsx, .tsx, .vue, .scala, .sh, .bat, .ps1, .sql, .r, .m, .pl, .lua, .dart, .elm, .clj, .hs, .f90, .pas, .asm, etc.) are explicitly blocked for safety.",
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Additional context or instructions provided by the AI for the edit operation.",
				},
				"file_path": {
					Type:        repository.TypeString,
					Description: "The path of the TEXT FILE to edit (only .txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex files allowed). Example: './folder/document.txt' or './notes.md'. Programming files are blocked.",
				},
				"changes": {
					Type:        repository.TypeArray,
					Description: "A list of changes to apply to the text file, with each change specifying a selection and an operation.",
					Items: &repository.Properties{
						Type:        repository.TypeObject,
						Description: "Operation Meta data",
						Properties: map[string]*repository.Properties{
							"start_line_number": {
								Type:        repository.TypeInteger,
								Description: "The starting line number (1-based) of the change range.",
							},
							"start_line_col": {
								Type:        repository.TypeInteger,
								Description: "The starting column number (0-based) of the change range.",
							},
							"end_line_number": {
								Type:        repository.TypeInteger,
								Description: "The ending line number (1-based) of the change range.",
							},
							"end_line_col": {
								Type:        repository.TypeInteger,
								Description: "The ending column number (0-based) of the change range.",
							},
							"operation": {
								Enum:        []string{"delete", "replace", "write"},
								Type:        repository.TypeString,
								Description: "The operation to perform on the selected range. Options: 'delete' (remove text), 'replace' (replace text with new content), or 'write' (insert new content at start).",
							},
							"content": {
								Type:        repository.TypeString,
								Description: "The replacement or insertion text to apply. Required for 'replace' and 'write' operations.",
							},
						},
						Required: []string{"start_line_number", "start_line_col", "end_line_number", "end_line_col", "operation", "content"},
					},
				},
			},
			Required: []string{"text", "file_path", "changes"},
		},
		Service: EditFile,
	},
	{
		Name: "take-input-from-terminal",
		Description: `Prompts the user in the terminal for multiple required inputs.
Use this whenever you are missing essential details, such as:
- File names
- Function parameters
- Configuration values
- User choices`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"requirements": {
					Type:        repository.TypeArray,
					Description: "A list of questions or keys to ask the user for input",
					Items: &repository.Properties{
						Type: "string",
					},
				},
				"text": {
					Type:        repository.TypeString,
					Description: "A text which you want to say to user, instead of returning text output give it in this parameter",
				},
			},
			Required: []string{"requirements", "text"},
		},
		Service: TakeInputFromTerminal,
		Return:  repository.Return{"error": "string", "output": "object"},
	},
	{
		Name: "exit-process",
		Description: `When you feel that the task is fully completed, always call this function to exit the process.
âš ï¸ Important:
- Before calling, make sure all steps are done, bugs are fixed, and the user is satisfied.
- Instead of just returning raw text, always compile everything (final output, explanations, summaries, code, results, etc.) into a single clear text message.
- Put that final compiled text inside the "text" parameter. This is what the user will see as the final answer.`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "The final compiled text output for the user (summary, results, explanations, etc.)",
				},
			},
			Required: []string{"text"},
		},
		Service: ExitProcess,
		Return: repository.Return{
			"error":  "string",
			"output": "string",
		},
	},
	{
		Name: "write-file",
		Description: `Write or overwrite file contents with precise control over offsets and data placement.  
This tool provides COMPLETE file manipulation capabilities, enabling:

ðŸ“ BASIC FILE OPERATIONS:
- Full overwrite: Replace the entire content of an existing file with new data.
- Append mode: Add content at the end of the file by setting offset equal to file size.
- Partial overwrite: Modify specific portions of a file without affecting the rest.
- Sparse file creation: Insert padding/zero-bytes automatically when offset exceeds file size.

ðŸ“‚ USE CASES:
- Create or update configuration files (e.g., .env, config.json, settings.yaml).
- Maintain logs, append new entries without altering existing data.
- Replace corrupted sections of a binary/text file.
- Write test fixtures or datasets programmatically.
- Manage source code updates while preserving line/byte positions.

âš™ï¸ ADVANCED FEATURES:
- Multi-file support: Operate on multiple files in one call.
- Precise byte-level control: Offsets allow low-level file manipulations.
- Data replacement: Insert/overwrite any part of a file with new content slices.
- Sparse handling: Automatically generates empty byte padding for large jumps in offset.
- Integration: Always call 'read_files' first to load current file state before modification.

ðŸš« SAFETY & USAGE NOTES:
- âš ï¸ Be careful when overwriting: it PERMANENTLY replaces existing file content.
- Always confirm offsets and file names to avoid unintentional data loss.
- Ensure file extensions match expected format (.txt, .json, .go, .py, etc.).
- Using offsets incorrectly can corrupt structured files (e.g., JSON, XML).
- Use sparse file creation only if downstream systems can handle them properly.

ðŸ“Š COMMON PATTERNS:
- Full overwrite:
  { "file_names": ["config.json"], "contents": ["{ \"debug\": true }"], "offsets": [0] }

- Append to file:
  { "file_names": ["log.txt"], "contents": ["New log entry"], "offsets": [<current_file_size>] }

- Overwrite at position:
  { "file_names": ["data.bin"], "contents": ["FF00AA"], "offsets": [128] }

- Create sparse file:
  { "file_names": ["huge.dat"], "contents": ["End Marker"], "offsets": [1000000000] }

ðŸ–¥ï¸ EXAMPLES:
- Replace entire README.md with new content.
- Append a new migration entry into a SQL file.
- Patch a corrupted section of a binary executable.
- Programmatically generate structured text/data files.
- ONLY text-based files (txt, md, rst, log, csv, json, xml, yaml, yml, html, css, ini, cfg, conf, rtf, tex) at a given path by applying specified changes. This function is STRICTLY RESTRICTED to non-coding files to prevent accidental modification of source code. Programming files (.go, .py, .js, .java, .c, .cpp, .h, .php, .rb, .swift, .kt, .rs, .ts, .jsx, .tsx, .vue, .scala, .sh, .bat, .ps1, .sql, .r, .m, .pl, .lua, .dart, .elm, .clj, .hs, .f90, .pas, .asm, etc.) are explicitly blocked for safety.
This tool is your gateway to precise file manipulation and content management. Use it to create, append, overwrite, and manage files across any project lifecycle with full byte-level control.`,

		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"file_names": {
					Type:        repository.TypeArray,
					Items:       &repository.Properties{Type: repository.TypeString},
					Description: "List of file names (with extensions) where operations will be performed. Each file corresponds to matching index of 'contents' and 'offsets'.",
				},
				"contents": {
					Type:        repository.TypeArray,
					Items:       &repository.Properties{Type: repository.TypeString},
					Description: "Full content strings to write into files. Each entry aligns with 'file_names' and 'offsets'.",
				},
				"offsets": {
					Type:  repository.TypeArray,
					Items: &repository.Properties{Type: repository.TypeNumber},
					Description: `Array of byte offsets controlling write position for each file:
- Omit or set 0 â†’ Overwrite entire file from beginning.
- Equal to file size â†’ Append new content at the end.
- Within file size â†’ Overwrite content starting from that offset.
- Beyond file size â†’ Create sparse file with zero-padding.`,
				},
			},
			Required: []string{"file_names", "contents", "offsets"},
		},

		Service: WriteFile,

		Return: repository.Return{
			"error":  "string // Error details if write fails (invalid path, permissions, etc.).",
			"output": "string // Confirmation details such as bytes written, offsets applied, and file names affected.",
		},
	},

	{
		Name: "ask-an-agent",
		Description: `Route a task to a specific agent for processing.
Available agents:
- analysis: Performs task analysis and validation
- planning: Creates execution plans
- execution: Executes planned tasks`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "A text which you want to say to user, instead of returning text output give it in this parameter",
				},
				"agent_id": {
					Type:        repository.TypeString,
					Description: "The ID of the agent to route the task to (analysis, planning, execution)",
					Enum:        []string{"analysis", "coder", "planner", "interactor"},
				},
				"task": {
					Type:        repository.TypeString,
					Description: "The task which is to be processed by the agent, if nothing available just give the proper detailed query",
				},
				"analysis-id": {
					Type:        repository.TypeString,
					Description: "The Analysis which you got from analysis agent keep it simple and detailed with each and every analysis and bullet points. Since coder agent will also need it so make sure to give it.",
				},
			},
			Required: []string{"agent_id", "task", "analysis-id"},
		},
		Service: AskAnAgent,
		Return:  repository.Return{"error": "string", "output": "object"},
	},
	{
		Name: "create-tasks",
		Description: `Create multiple tasks and store them in the TaskMap.
Each task must have an ID and can have optional description, agent_id, inputs, dependencies, outputs, and metadata.`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "A text which you want to say to user, instead of returning text output give it in this parameter",
				},
				"tasks": {
					Type:        repository.TypeArray,
					Description: "Array of task objects to create",
					Items: &repository.Properties{
						Type: repository.TypeObject,
						Properties: map[string]*repository.Properties{
							"id": {
								Type:        repository.TypeString,
								Description: "Unique identifier for the task (required)",
							},
							"description": {
								Type:        repository.TypeString,
								Description: "Optional description of the task",
							},
							"agent_id": {
								Type:        repository.TypeString,
								Description: "Agent assigned to this task (optional)",
							},
							"inputs": {
								Type:        repository.TypeObject,
								Description: "Input parameters required for the task",
							},
							"outputs": {
								Type:        repository.TypeObject,
								Description: "Expected or generated outputs for the task",
							},
							"dependencies": {
								Type:        repository.TypeArray,
								Items:       &repository.Properties{Type: repository.TypeString},
								Description: "IDs of tasks this task depends on",
							},
							"metadata": {
								Type: repository.TypeObject,
								Properties: map[string]*repository.Properties{
									"key": {Type: repository.TypeString},
								},
								Description: "Custom metadata key-value pairs",
							},
						},
						Required: []string{"id", "description"},
					},
				},
			},
			Required: []string{"tasks"},
		},
		Service: CreateTasks,
		Return:  repository.Return{"error": "string", "output": "array"},
	},

	{
		Name: "read-files",
		Description: `Read and analyze multiple files efficiently in a single operation. 
	
	IMPORTANT: This function can read MULTIPLE files simultaneously - pass ALL file paths you need in the file_names array rather than calling this function multiple times for individual files.
	
	Key features:
	- Reads multiple files in one call (more efficient than multiple separate calls)
	- Automatically skips empty lines to save tokens and improve clarity
	- Adds line numbers to each line for precise reference and debugging
	- Chunks large files automatically for better processing
	- Stores read files globally for reuse across the session
	
	Best practices:
	- Pass ALL required file paths in a single call: ["file1.go", "file2.md", "file3.txt"]
	- Use when you need to analyze code structure, configuration files, documentation, or any text-based content
	- Ideal for cross-file analysis, dependency checking, or comprehensive codebase review
	
	Example usage scenarios:
	- Code analysis: ["main.go", "utils.go", "config.yaml"]
	- Documentation review: ["README.md", "CHANGELOG.md", "API.md"]
	- Configuration audit: ["docker-compose.yml", ".env", "nginx.conf"]
	
	The function returns structured data with line numbers, making it easy to reference specific parts of files in subsequent analysis.`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Optional message to display to the user explaining what files you're reading and why, instead of just returning output silently",
				},
				"file_names": {
					Type:        repository.TypeArray,
					Description: "Array of file paths to read simultaneously. IMPORTANT: Include ALL files you need in this single array rather than making multiple function calls. Examples: ['main.go', 'config.yaml'], ['src/app.js', 'package.json', 'README.md']",
					Items: &repository.Properties{
						Type: "string",
					},
				},
			},
			Required: []string{"file_names"},
		},
		Service: ReadFiles,
		Return: repository.Return{
			"error":  "string - null if successful, error message if failed",
			"output": "object - map of filename to chunks with line numbers and content",
		},
	},
}

func init() {
	for _, v := range OrchestratorCapabilities {
		OrchestratortoolsFunc[v.Name] = v
	}
}

func OrchestratorTools() map[string]repository.Function {
	return OrchestratortoolsFunc
}

func GetOrchestratorTools() []repository.Function {
	return OrchestratorCapabilities
}

func GetOrchestratorToolsMap() []map[string]any {
	arrayOfMap := make([]map[string]any, 0)
	for _, v := range OrchestratorCapabilities {
		arrayOfMap = append(arrayOfMap, v.ToObject())
	}
	return arrayOfMap
}

```

## File: internal/service/coder/coder.go
Language: go | Tokens: 12956 | Size: 51827 bytes

**âš ï¸ Security Issues:**

ðŸŸ¢ **[LOW]** Line 582 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   fmt.Print("dost> ")
   ```

ðŸŸ¢ **[LOW]** Line 1294 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   Provides sophisticated error handling with context-aware debugging and automatic retry mechanisms.
   ```

ðŸŸ¢ **[LOW]** Line 1314 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   Description: "Contextual description of the operation being performed for enhanced logging and debugging capabilities.",
   ```

```go
package coder

import (
	"bufio"
	"bytes"
	"context"
	"dost/internal/repository"
	"dost/internal/service"
	"dost/internal/service/analysis"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"sort"
	"strings"
	"time"
	"unicode/utf8"

	"github.com/google/uuid"
	gitignore "github.com/sabhiram/go-gitignore"
	"github.com/spf13/viper"
)

// Coder capabilities definitions.
const (
	CreateFileFromName   = "create_file"
	ReadFileFromName     = "read_file"
	ListDirectoryName    = "list_directory"
	DeleteFileOrDirName  = "delete_file_or_dir"
	EditFileFromName     = "edit_file"
	RequestUserInputName = "request_user_input"
)

const CreateFileDescription = `Creates new files with precise content placement and intelligent path resolution. 
Supports atomic file creation with automatic directory structure generation, UTF-8 encoding, and collision handling. 
Overwrites existing files when explicitly required. Optimized for multi-file project scaffolding and code generation workflows.`

const ReadFileDescription = `Performs high-performance file content retrieval with intelligent encoding detection and memory-optimized streaming. 
Supports batch reading operations, automatic charset conversion, and binary-safe content handling. 
Essential for code analysis, dependency inspection, and project structure understanding before modifications.`

const ListDirectoryDescription = `Provides comprehensive directory traversal with intelligent filtering, recursive scanning capabilities, and .gitignore awareness. 
Returns structured metadata including file types, sizes, permissions, and modification timestamps. 
Optimized for project discovery, dependency analysis, and codebase exploration workflows.`

const DeleteFileOrDirDescription = `Executes safe file and directory removal operations with rollback capabilities and dependency validation. 
Supports recursive deletion with conflict detection, backup creation, and atomic cleanup operations. 
Includes safety checks to prevent accidental deletion of critical project files and version control data.`

const EditFileDescription = `Advanced multi-operation file editor with precise line-column targeting and atomic change application. 
Supports sophisticated edit operations including insertions, deletions, replacements, and multi-region modifications. 
Features intelligent conflict resolution, syntax-aware editing, and transaction-based changes with rollback support. 
Optimized for complex refactoring, code generation, and automated maintenance tasks.`

const RequestUserInputDescription = `Interactive terminal interface for real-time user communication and decision-making workflows. 
Provides formatted input prompts with validation, timeout handling, and context-aware questioning. 
Essential for gathering requirements, confirming destructive operations, and obtaining user preferences during development.`

var CodertoolsFunc map[string]repository.Function = make(map[string]repository.Function)
var ignoreMatcher *gitignore.GitIgnore

var ChatHistory = make([]map[string]any, 0)
var defaultIgnore = map[string]bool{
	".git":         true,
	"node_modules": true,
	"vendor":       true,
	".venv":        true,
	".env":         true,
	".idea":        true,
	".vscode":      true,
	"__pycache__":  true,
	".dost":        true,
}

type InitialContext struct {
	OS              string
	Arch            string
	User            string
	Shell           string
	CWD             string
	GoVersion       string
	FolderStructure map[string]any
	InstalledTools  []string
	EnvVars         map[string]string
	ProjectFiles    []string
	ProjectType     string
	GitBranch       string
	InternetAccess  bool
	AgentRole       string
	Capabilities    []string
	Timezone        string
	SessionID       string
}
type changeInfo struct {
	startLine int
	startCol  int
	endLine   int
	endCol    int
	operation string
	content   string
	valid     bool
}

func GetInitialContext() InitialContext {
	ctx := InitialContext{
		OS:              runtime.GOOS,
		Arch:            runtime.GOARCH,
		User:            os.Getenv("USERNAME"),
		Shell:           detectDefaultShell(),
		CWD:             mustGetWorkingDir(),
		FolderStructure: GetProjectStructure(map[string]any{"path": "./"}),
		GoVersion:       runtime.Version(),
		InstalledTools:  detectTools(),
		EnvVars:         getImportantEnvVars(),
		ProjectFiles:    scanProjectFiles(),
		ProjectType:     detectProjectType(),
		GitBranch:       getGitBranch(),
		InternetAccess:  checkInternet(),
		Timezone:        getLocalTimezone(),
		SessionID:       generateSessionID(),
	}
	return ctx
}

func detectDefaultShell() string {
	if runtime.GOOS == "windows" {
		// prefer PowerShell if present
		if _, err := exec.LookPath("powershell"); err == nil {
			return "powershell"
		}
		return "cmd"
	}
	return os.Getenv("SHELL")
}

func mustGetWorkingDir() string {
	dir, err := os.Getwd()
	if err != nil {
		return "."
	}
	return dir
}

func detectTools() []string {
	var found []string
	val := os.Getenv("PATH")
	found = strings.Split(val, ";")
	return found
}

func getImportantEnvVars() map[string]string {
	keys := []string{"PATH", "GOROOT", "GOPATH", "JAVA_HOME"}
	env := make(map[string]string)
	for _, k := range keys {
		if v := os.Getenv(k); v != "" {
			env[k] = v
		}
	}
	return env
}

func scanProjectFiles() []string {
	files := []string{}
	filepath.Walk(".", func(path string, info os.FileInfo, err error) error {
		if err == nil && !info.IsDir() {
			if strings.HasSuffix(path, ".go") ||
				path == "go.mod" || path == "package.json" || path == "requirements.txt" ||
				path == "Dockerfile" || path == "README.md" {
				files = append(files, path)
			}
		}
		return nil
	})
	return files
}

func detectProjectType() string {
	if _, err := os.Stat("go.mod"); err == nil {
		return "Go project"
	}
	if _, err := os.Stat("package.json"); err == nil {
		return "Node.js project"
	}
	if _, err := os.Stat("requirements.txt"); err == nil {
		return "Python project"
	}
	return "Unknown"
}

func getGitBranch() string {
	cmd := exec.Command("git", "rev-parse", "--abbrev-ref", "HEAD")
	out, err := cmd.Output()
	if err != nil {
		return ""
	}
	return strings.TrimSpace(string(out))
}

func checkInternet() bool {
	cmd := exec.Command("ping", "-c", "1", "8.8.8.8")
	if runtime.GOOS == "windows" {
		cmd = exec.Command("ping", "-n", "1", "8.8.8.8")
	}
	if err := cmd.Run(); err != nil {
		return false
	}
	return true
}

func getLocalTimezone() string {
	_, tz := time.Now().Zone()
	return fmt.Sprintf("%d min offset", tz/60)
}

func generateSessionID() string {
	return fmt.Sprintf("%d", time.Now().UnixNano())
}

type AgentCoder repository.Agent

const coderName = "coder"

const coderVersion = "0.1.0"

// args must and only contains "query"
// Helper function to format files for Coder
func formatFilesForCoder(filesRead map[string]any) string {
	if len(filesRead) == 0 {
		return ""
	}

	var result strings.Builder
	result.WriteString("=== FILES CONTENT ===\n\n")

	for fileName, fileData := range filesRead {
		result.WriteString(fmt.Sprintf("FILE: %s\n", fileName))
		result.WriteString("=" + strings.Repeat("=", len(fileName)+6) + "\n")

		if chunks, ok := fileData.([]map[string]any); ok {
			for _, chunk := range chunks {
				if content, exists := chunk["content"].(string); exists {
					result.WriteString(content)
					result.WriteString("\n")
				}
			}
		}
		result.WriteString("\n" + strings.Repeat("-", 50) + "\n\n")
	}

	return result.String()
}

func (p *AgentCoder) Interaction(args map[string]any) map[string]any {
	InitialContext := GetInitialContext()
	InitialContextBytes, err := json.Marshal(InitialContext)
	if err != nil {
		return map[string]any{"error": "Unable to get initial context"}
	}

	var userMessage strings.Builder

	filesContent := formatFilesForCoder(analysis.FilesRead)
	if filesContent != "" {
		userMessage.WriteString(filesContent)
		userMessage.WriteString("\n")
	}

	// Add initial context
	userMessage.WriteString("=== INITIAL CONTEXT ===\n")
	userMessage.WriteString(string(InitialContextBytes))
	userMessage.WriteString("\n\n")

	// Add query
	userMessage.WriteString("=== QUERY ===\n")
	if query, ok := args["query"].(string); ok {
		userMessage.WriteString(query)
	}
	log.Println("TEST: CODER:  ", userMessage.String()[0:20])
	// Push consolidated user message into ChatHistory
	ChatHistory = append(ChatHistory, map[string]any{
		"role": "user",
		"parts": []map[string]any{
			{"text": userMessage.String()},
		},
	})

	for {
		// Ensure exit-process is always enforced
		if len(ChatHistory) > 0 && ChatHistory[len(ChatHistory)-1]["role"] == "model" {
			ChatHistory = append(ChatHistory, map[string]any{
				"role": "user",
				"parts": []map[string]any{
					{
						"text": "If you feel there is no task left and nothing to do, call exit-process. Because only that can stop you and finish the program. Don't respond with text, no text output should be there, call the exit-process. PERIOD",
					},
				},
			})
		}

		output := p.RequestAgent(ChatHistory)

		if output["error"] != nil {
			fmt.Println("Error:", output["error"])
			os.Exit(1)
		}

		outputData, ok := output["output"].([]map[string]any)
		if !ok {
			fmt.Println("ERROR CONVERTING OUTPUT")
			return nil
		}

		if len(outputData) == 0 {
			fmt.Println("No output received")
			continue
		}

		// Process each output part
		for _, part := range outputData {
			partType, hasType := part["type"].(string)
			if !hasType {
				continue
			}

			switch partType {
			case "text":
				if text, ok := part["data"].(string); ok {
					fmt.Println("Agent:", text)
				}

			case "functionCall":
				name, nameOK := part["name"].(string)
				argsData, argsOK := part["args"].(map[string]any)

				if !nameOK || !argsOK {
					fmt.Println("Error: invalid function call data")
					continue
				}

				fmt.Println("Calling function:", name)

				// Execute the function
				if function, exists := CodertoolsFunc[name]; exists {
					result := function.Run(argsData)

					// Check for exit condition
					if _, ok := result["exit"].(bool); ok {
						return map[string]any{"coder-id": result["output"]}
					}

					// Add function response back to chat history
					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{
								"functionResponse": map[string]any{
									"name":     name,
									"response": result,
								},
							},
						},
					})

					if outputStr, ok := result["output"].(string); ok {
						fmt.Println("Result:", outputStr)
					}
				} else {
					fmt.Printf("Function %s not found\n", name)

					// Add error response into chat
					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{"text": fmt.Sprintf("Error: Function '%s' not found", name)},
						},
					})
				}
			}
		}

		fmt.Println("---")
	}
}

// NewAgent creates and initializes a new AgentCoder instance.
func (c *AgentCoder) NewAgent() {
	model := viper.GetString("CODER.MODEL")
	if model == "" {
		model = "gemini-1.5-pro"
	}
	endPoints := fmt.Sprintf("https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse", model)
	id := fmt.Sprintf("coder-%s", uuid.NewString())

	agentMetadata := repository.AgentMetadata{
		ID:             id,
		Name:           coderName,
		Version:        coderVersion,
		Type:           repository.AgentCoder,
		Instructions:   repository.CoderInstructions,
		MaxConcurrency: 5,
		Timeout:        10 * time.Minute,
		Tags:           []string{"coder", "code", "programming", "development"},
		Endpoints:      map[string]string{"http": endPoints},
		Context:        make(map[string]any),
		Status:         "active",
		LastActive:     time.Now(),
	}

	c.Metadata = agentMetadata
	c.Capabilities = CoderCapabilities

}

// RequestAgent is the main entry point for the AgentCoder to handle incoming tasks.
func (c *AgentCoder) RequestAgent(contents []map[string]any) map[string]any {
	fmt.Printf("Processing request with Coder Agent: %s\n", c.Metadata.Name)

	// Build request payload
	request := map[string]any{
		"systemInstruction": map[string]any{
			"parts": []map[string]any{
				{"text": c.Metadata.Instructions},
			},
		},
		"toolConfig": map[string]any{
			"functionCallingConfig": map[string]any{
				"mode": "ANY",
			},
		},
		"contents": contents,
		"tools": []map[string]any{
			{"functionDeclarations": GetCoderCapabilitiesArrayMap()},
		},
	}

	// Marshal request body
	jsonBody, err := json.Marshal(request)
	if err != nil {
		return map[string]any{"error": err.Error(), "output": nil}
	}

	// Retry config
	const maxRetries = 5
	const maxWaitTime = 10 * time.Minute

	for attempt := 0; attempt <= maxRetries; attempt++ {
		// Create HTTP request
		req, err := http.NewRequestWithContext(
			context.Background(),
			"POST",
			c.Metadata.Endpoints["http"],
			bytes.NewBuffer(jsonBody),
		)
		if err != nil {
			return map[string]any{"error": err.Error(), "output": nil}
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("X-goog-api-key", viper.GetString("CODER.API_KEY"))

		// Execute request with timeout
		client := repository.NewStreamingHTTPClient()
		resp, err := client.Do(req)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}
		defer resp.Body.Close()

		// Success case - parse streaming response
		if resp.StatusCode == http.StatusOK {
			// Parse SSE stream with real-time display
			streamResp, err := repository.ParseSSEStream(resp.Body, true)
			if err != nil {
				if attempt == maxRetries {
					return map[string]any{"error": err.Error(), "output": nil}
				}
				time.Sleep(repository.ExponentialBackoff(attempt))
				continue
			}

			// Convert to standard output format
			output := repository.ConvertStreamResponseToOutput(streamResp)

			// Save chat history
			historyEntry := repository.BuildChatHistoryFromStream(streamResp, "coder")
			if historyEntry != nil {
				ChatHistory = append(ChatHistory, historyEntry)
			}

			c.Metadata.LastActive = time.Now()
			return map[string]any{"error": nil, "output": output}
		}

		// Read body for error cases
		bodyBytes, err := io.ReadAll(resp.Body)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Handle rate limits
		if resp.StatusCode == http.StatusTooManyRequests {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Rate limit exceeded after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}
			retryDelay := repository.ParseRetryDelay(string(bodyBytes))
			waitTime := retryDelay
			if waitTime <= 0 {
				waitTime = repository.ExponentialBackoff(attempt)
			}
			if waitTime > maxWaitTime {
				waitTime = maxWaitTime
			}
			fmt.Printf("Rate limit hit (attempt %d/%d). Waiting %v before retry...\n",
				attempt+1, maxRetries+1, waitTime)
			time.Sleep(waitTime)
			continue
		}

		// Retry on server errors
		if resp.StatusCode >= 500 && resp.StatusCode < 600 {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Server error after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}
			fmt.Printf("Server error (attempt %d/%d). Waiting %v before retry...\n",
				attempt+1, maxRetries+1, repository.ExponentialBackoff(attempt))
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Client errors (400â€“499) except 429 â†’ don't retry
		return map[string]any{
			"error":  fmt.Sprintf("HTTP %d: %s", resp.StatusCode, string(bodyBytes)),
			"output": nil,
		}
	}

	return map[string]any{
		"error":  fmt.Sprintf("Max retries (%d) exceeded", maxRetries),
		"output": nil,
	}
}

// ToMap serializes the AgentCoder into a map.
func (c *AgentCoder) ToMap() map[string]any {
	agent := repository.Agent(*c)
	return agent.ToMap()
}

func TakeInputFromTerminal(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if !ok {
		return map[string]any{"error": "No Text Provided"}
	}
	fmt.Println(text)

	requirements, ok := args["requirements"].([]any)
	reader := bufio.NewReader(os.Stdin)

	// Case 1: No requirements -> just take a single input
	if !ok || len(requirements) == 0 {
		fmt.Print("dost> ")
		input, err := reader.ReadString('\n')
		if err != nil {
			return map[string]any{
				"error":  fmt.Sprintf("Error reading input: %v", err),
				"output": nil,
			}
		}
		input = strings.TrimSpace(input)
		if input == "" {
			return map[string]any{"error": nil, "output": "<no input provided>"}
		}
		return map[string]any{"error": nil, "output": input}
	}

	// Case 2: Requirements exist -> ask each question
	results := make(map[string]string)
	for _, req := range requirements {
		question, ok := req.(string)
		if !ok {
			continue
		}

		fmt.Printf("dost> %s: ", question)
		input, err := reader.ReadString('\n')
		if err != nil {
			return map[string]any{
				"error":  fmt.Sprintf("Error reading input: %v", err),
				"output": nil,
			}
		}

		input = strings.TrimSpace(input)
		if input == "" {
			results[question] = "<no input provided>"
		} else {
			results[question] = input
		}
	}

	return map[string]any{"error": nil, "output": results}
}

// CreateFile creates new files - FIXED VERSION
func CreateFile(data map[string]any) map[string]any {
	text, ok := data["text"].(string)
	if ok {
		fmt.Printf("CODER: %s\n", text)
	}

	// Handle both single file and multiple files
	fileNames, hasFileNames := data["file_paths"].([]interface{})
	contents, hasContents := data["contents"].([]interface{})

	// Single file creation (backward compatibility)
	if path, hasPath := data["path"].(string); hasPath {
		content, hasContent := data["content"].(string)
		if !hasContent {
			return map[string]any{"error": "content is required"}
		}

		dir := filepath.Dir(path)
		if err := os.MkdirAll(dir, 0755); err != nil {
			return map[string]any{"error": fmt.Sprintf("failed to create directory for file: %v", err)}
		}

		if err := os.WriteFile(path, []byte(content), 0644); err != nil {
			return map[string]any{"error": fmt.Sprintf("failed to create file: %v", err)}
		}

		return map[string]any{
			"status": "completed",
			"output": fmt.Sprintf("File created successfully at %s", path),
		}
	}

	// Multiple files creation
	if !hasFileNames || !hasContents {
		return map[string]any{"error": "file_paths and contents are required"}
	}

	if len(fileNames) != len(contents) {
		return map[string]any{"error": "file_paths and contents arrays must have the same length"}
	}

	var createdFiles []string
	var errors []string

	for i, fileNameInterface := range fileNames {
		fileName, ok := fileNameInterface.(string)
		if !ok {
			errors = append(errors, fmt.Sprintf("Invalid file name at index %d", i))
			continue
		}

		content, ok := contents[i].(string)
		if !ok {
			errors = append(errors, fmt.Sprintf("Invalid content at index %d", i))
			continue
		}

		// Create directory if it doesn't exist
		dir := filepath.Dir(fileName)
		if dir != "." && dir != "" {
			if err := os.MkdirAll(dir, 0755); err != nil {
				errors = append(errors, fmt.Sprintf("Failed to create directory for %s: %v", fileName, err))
				continue
			}
		}

		// Write the file
		if err := os.WriteFile(fileName, []byte(content), 0644); err != nil {
			errors = append(errors, fmt.Sprintf("Failed to create %s: %v", fileName, err))
			continue
		}

		createdFiles = append(createdFiles, fileName)
		fmt.Printf("Created file: %s\n", fileName)
	}

	if len(errors) > 0 {
		return map[string]any{
			"error":         strings.Join(errors, "; "),
			"output":        fmt.Sprintf("Created %d files successfully", len(createdFiles)),
			"created_files": createdFiles,
		}
	}

	return map[string]any{
		"status": "completed",
		"output": fmt.Sprintf("Successfully created %d files: %s", len(createdFiles), strings.Join(createdFiles, ", ")),
	}
}

// ReadFile reads the content of a file from a specified path.
func ReadFiles(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Printf("CODER: %s", text)
	}

	fileNames, ok := args["file_paths"].([]interface{})
	if !ok {
		return map[string]any{
			"error":  "Invalid arguments: 'file_paths' must be a slice of strings",
			"output": nil,
		}
	}

	var stringFileNames []string
	for _, v := range fileNames {
		s, ok := v.(string)
		if !ok {
			log.Fatal("Invalid argument: 'file_paths' contains non-string values")
			return map[string]any{
				"error":  "Invalid argument: 'file_paths' contains non-string values",
				"output": nil,
			}
		}
		stringFileNames = append(stringFileNames, s)
	}

	readFiles := make(map[string]any)
	var notFoundFiles []string

	for _, fileName := range stringFileNames {
		file, err := os.Open(fileName)
		if err != nil {
			notFoundFiles = append(notFoundFiles, fileName)
			continue
		}
		defer file.Close()

		// Read all lines, skipping empty ones
		scanner := bufio.NewScanner(file)
		var lines []string
		lineNumber := 1
		for scanner.Scan() {
			line := scanner.Text()
			// Skip empty lines but track line numbers
			if strings.TrimSpace(line) != "" {
				// Add line number prefix to non-empty lines
				numberedLine := fmt.Sprintf("%d: %s", lineNumber, line)
				lines = append(lines, numberedLine)
			}
			lineNumber++
		}

		if err := scanner.Err(); err != nil {
			readFiles[fileName] = fmt.Sprintf("Error reading file: %v", err)
			continue
		}

		// Create proper chunks (non-overlapping)
		chunks := []map[string]any{}
		chunkSize := 40
		if len(lines) < 100 {
			chunks = []map[string]any{{
				"start":   1,
				"end":     len(lines),
				"content": strings.Join(lines, "\n"),
			}}
		} else {
			for i := 0; i < len(lines); i += chunkSize {
				end := i + chunkSize
				if end > len(lines) {
					end = len(lines)
				}

				// Build chunk content
				var chunkContent strings.Builder
				for j := i; j < end; j++ {
					chunkContent.WriteString(lines[j])
					if j < end-1 { // Don't add newline after last line in chunk
						chunkContent.WriteString("\n")
					}
				}

				chunks = append(chunks, map[string]any{
					"start":   i + 1,
					"end":     end,
					"content": chunkContent.String(),
				})
			}

			// Handle empty file edge case (all lines were empty)
			if len(lines) == 0 {
				chunks = append(chunks, map[string]any{
					"start":   1,
					"end":     0,
					"content": "",
				})
			}
		}

		readFiles[fileName] = chunks
		// Also append to the global FilesRead map
		analysis.FilesRead[fileName] = chunks
		fmt.Printf("Read file: %s (%d non-empty lines, %d chunks)\n", fileName, len(lines), len(chunks))
	}

	if len(notFoundFiles) > 0 {
		fmt.Printf("Files not found: %v\n", notFoundFiles)
	}

	return map[string]any{"error": nil, "output": readFiles}
}

func ExecuteCommands(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Println(text)
	}

	// Get current working directory
	wd, err := os.Getwd()
	if err != nil {
		return map[string]any{"error": err.Error()}
	}

	// Extract command
	cmdStr, ok := args["command"].(string)
	if !ok || cmdStr == "" {
		return map[string]any{"error": "Invalid command"}
	}

	// Extract arguments (as array instead of a single string)
	var argList []string
	if rawArgs, ok := args["arguments"]; ok {
		switch v := rawArgs.(type) {
		case string:
			// split on spaces if user passed a string
			if v != "" {
				argList = strings.Fields(v)
			}
		case []any:
			for _, a := range v {
				if s, ok := a.(string); ok {
					argList = append(argList, s)
				}
			}
		}
	}
	fmt.Println(">DOST\\")
	fmt.Printf("%s %v", cmdStr, argList)
	if !service.TakePermission {
		fmt.Printf("\nAbout to run command in %s:\n> %s\nPress ENTER to continue or Ctrl+C to cancel...", wd, argList)
		bufio.NewReader(os.Stdin).ReadBytes('\n') // wait for Enter
	}
	// Handle `cd` separately
	if cmdStr == "cd" {
		if len(argList) == 0 {
			return map[string]any{"error": "cd requires a path"}
		}
		newDir := argList[0]
		if !filepath.IsAbs(newDir) {
			newDir = filepath.Join(wd, newDir)
		}
		if err := os.Chdir(newDir); err != nil {
			return map[string]any{"error": fmt.Sprintf("failed to change directory: %v", err)}
		}
		return map[string]any{"message": fmt.Sprintf("Changed directory to %s", newDir)}
	}

	// Build command properly
	cmd := exec.Command(cmdStr, argList...)
	cmd.Dir = wd
	var stdoutBuf, stderrBuf bytes.Buffer
	cmd.Stdin = os.Stdin
	cmd.Stdout = io.MultiWriter(os.Stdout, &stdoutBuf)
	cmd.Stderr = io.MultiWriter(os.Stderr, &stderrBuf)

	log.Default().Printf("Running command in %s: %s %v\n", wd, cmdStr, argList)

	err = cmd.Run()
	if err != nil {
		return map[string]any{
			"error": fmt.Sprintf("command failed: [%s %v] %v || CONSOLE/TERMINAL:%v",
				cmdStr, argList, err, stderrBuf.String()),
		}
	}

	return map[string]any{
		"message": "Command executed successfully",
		"output":  stdoutBuf.String(),
	}
}

// EditFile edits a file at a given path.
// Piece Table - what is it ??

func EditFile(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok {
		fmt.Printf("CODER: %s\n", text)
	}

	filepathInput, ok := args["file_path"].(string)
	if !ok {
		return map[string]any{"error": "ERROR READING PATH"}
	}

	changes, ok := args["changes"].([]interface{})
	if !ok {
		return map[string]any{"error": "REQUIRED CHANGES MAP"}
	}

	// Enhanced change structure with validation

	toInt := func(v any) (int, bool) {
		switch val := v.(type) {
		case float64:
			return int(val), true
		case int:
			return val, true
		default:
			return 0, false
		}
	}

	var processedChanges []changeInfo
	for i, c := range changes {
		ch, ok := c.(map[string]any)
		if !ok {
			return map[string]any{"error": fmt.Sprintf("INVALID CHANGE FORMAT at index %d", i)}
		}

		startLine, startLineOk := toInt(ch["start_line_number"])
		startCol, startColOk := toInt(ch["start_line_col"])
		endLine, endLineOk := toInt(ch["end_line_number"])
		endCol, endColOk := toInt(ch["end_line_col"])
		operation, operationOk := ch["operation"].(string)
		content, contentOk := ch["content"].(string)

		// Validate all required fields are present and correct type
		if !startLineOk || !startColOk || !endLineOk || !endColOk || !operationOk || !contentOk {
			return map[string]any{"error": fmt.Sprintf("MISSING OR INVALID FIELDS in change %d", i)}
		}

		// Validate operation type
		if operation != "delete" && operation != "replace" && operation != "write" {
			return map[string]any{"error": fmt.Sprintf("INVALID OPERATION '%s' in change %d. Must be 'delete', 'replace', or 'write'", operation, i)}
		}

		// Validate line/column numbers make sense
		if startLine < 1 || endLine < 1 {
			return map[string]any{"error": fmt.Sprintf("LINE NUMBERS must be >= 1 in change %d", i)}
		}

		if startCol < 0 || endCol < 0 {
			return map[string]any{"error": fmt.Sprintf("COLUMN NUMBERS must be >= 0 in change %d", i)}
		}

		// For single-line operations, validate column order
		if startLine == endLine && startCol > endCol && operation != "write" {
			return map[string]any{"error": fmt.Sprintf("START COLUMN cannot be > END COLUMN on same line in change %d", i)}
		}

		processedChanges = append(processedChanges, changeInfo{
			startLine: startLine,
			startCol:  startCol,
			endLine:   endLine,
			endCol:    endCol,
			operation: operation,
			content:   content,
			valid:     true,
		})
	}

	// Read file with better error handling
	fileContent, err := os.ReadFile(filepathInput)
	if err != nil {
		if os.IsNotExist(err) {
			return map[string]any{"error": fmt.Sprintf("FILE NOT FOUND: %s", filepathInput)}
		}
		return map[string]any{"error": fmt.Sprintf("CANNOT READ FILE: %s - %v", filepathInput, err)}
	}

	// Handle different line endings
	content := string(fileContent)
	content = strings.ReplaceAll(content, "\r\n", "\n") // Windows -> Unix
	content = strings.ReplaceAll(content, "\r", "\n")   // Old Mac -> Unix
	lines := strings.Split(content, "\n")

	// Validate all changes against file bounds before applying any
	for i, change := range processedChanges {
		if change.startLine > len(lines) || change.endLine > len(lines) {
			return map[string]any{"error": fmt.Sprintf("LINE NUMBER OUT OF BOUNDS in change %d: file has %d lines, but change references line %d", i, len(lines), max(change.startLine, change.endLine))}
		}

		// Check column bounds for start position
		if change.startLine <= len(lines) {
			lineIdx := change.startLine - 1
			lineLen := utf8.RuneCountInString(lines[lineIdx])
			if change.startCol > lineLen {
				return map[string]any{"error": fmt.Sprintf("START COLUMN OUT OF BOUNDS in change %d: line %d has %d characters, but change references column %d", i, change.startLine, lineLen, change.startCol)}
			}
		}

		// Check column bounds for end position (for same line operations)
		if change.startLine == change.endLine && change.endLine <= len(lines) {
			lineIdx := change.endLine - 1
			lineLen := utf8.RuneCountInString(lines[lineIdx])
			if change.endCol > lineLen {
				return map[string]any{"error": fmt.Sprintf("END COLUMN OUT OF BOUNDS in change %d: line %d has %d characters, but change references column %d", i, change.endLine, lineLen, change.endCol)}
			}
		}
	}

	// Sort changes by position (last to first to avoid position conflicts)
	sort.Slice(processedChanges, func(i, j int) bool {
		if processedChanges[i].startLine == processedChanges[j].startLine {
			return processedChanges[i].startCol > processedChanges[j].startCol
		}
		return processedChanges[i].startLine > processedChanges[j].startLine
	})

	// Apply changes from last to first
	for _, change := range processedChanges {
		switch change.operation {
		case "delete":
			lines = applyDelete(lines, change)
		case "replace":
			lines = applyReplace(lines, change)
		case "write":
			lines = applyWrite(lines, change)
		}
	}

	// Write back to file
	newContent := strings.Join(lines, "\n")
	err = os.WriteFile(filepathInput, []byte(newContent), 0644)
	if err != nil {
		return map[string]any{"error": fmt.Sprintf("CANNOT WRITE TO FILE: %s - %v", filepathInput, err)}
	}

	return map[string]any{"output": fmt.Sprintf("Successfully applied %d changes to %s", len(processedChanges), filepathInput)}
}

// Helper function for delete operations
func applyDelete(lines []string, change changeInfo) []string {
	startIdx := change.startLine - 1
	endIdx := change.endLine - 1

	if change.startLine == change.endLine {
		// Single line deletion - remove characters within the line
		if startIdx < len(lines) {
			line := lines[startIdx]
			runes := []rune(line)
			if change.startCol <= len(runes) && change.endCol <= len(runes) {
				newRunes := append(runes[:change.startCol], runes[change.endCol:]...)
				lines[startIdx] = string(newRunes)
			}
		}
	} else {
		// Multi-line deletion
		if startIdx < len(lines) && endIdx < len(lines) {
			// Keep part of first line before start column
			firstLinePart := ""
			if startIdx < len(lines) {
				firstLineRunes := []rune(lines[startIdx])
				if change.startCol <= len(firstLineRunes) {
					firstLinePart = string(firstLineRunes[:change.startCol])
				}
			}

			// Keep part of last line after end column
			lastLinePart := ""
			if endIdx < len(lines) {
				lastLineRunes := []rune(lines[endIdx])
				if change.endCol <= len(lastLineRunes) {
					lastLinePart = string(lastLineRunes[change.endCol:])
				}
			}

			// Combine remaining parts
			combinedLine := firstLinePart + lastLinePart

			// Remove the range and insert combined line
			newLines := make([]string, 0, len(lines)-(endIdx-startIdx))
			newLines = append(newLines, lines[:startIdx]...)
			newLines = append(newLines, combinedLine)
			newLines = append(newLines, lines[endIdx+1:]...)
			lines = newLines
		}
	}
	return lines
}

// Helper function for replace operations
func applyReplace(lines []string, change changeInfo) []string {
	// First delete the range, then insert new content
	lines = applyDelete(lines, change)

	// Now insert the new content at the start position
	writeChange := changeInfo{
		startLine: change.startLine,
		startCol:  change.startCol,
		endLine:   change.startLine,
		endCol:    change.startCol,
		operation: "write",
		content:   change.content,
	}
	return applyWrite(lines, writeChange)
}

// Helper function for write operations
func applyWrite(lines []string, change changeInfo) []string {
	if change.startLine-1 < len(lines) {
		lineIdx := change.startLine - 1
		line := lines[lineIdx]
		runes := []rune(line)

		if change.startCol <= len(runes) {
			// Handle multi-line content insertion
			newContent := change.content
			contentLines := strings.Split(newContent, "\n")

			if len(contentLines) == 1 {
				// Single line insertion
				newRunes := append(runes[:change.startCol], append([]rune(contentLines[0]), runes[change.startCol:]...)...)
				lines[lineIdx] = string(newRunes)
			} else {
				// Multi-line insertion
				beforeRunes := runes[:change.startCol]
				afterRunes := runes[change.startCol:]

				// First line: existing content before + first new line
				firstNewLine := string(beforeRunes) + contentLines[0]

				// Last line: last new content + existing content after
				lastNewLine := contentLines[len(contentLines)-1] + string(afterRunes)

				// Build new lines array
				newLines := make([]string, 0, len(lines)+len(contentLines)-1)
				newLines = append(newLines, lines[:lineIdx]...)
				newLines = append(newLines, firstNewLine)
				newLines = append(newLines, contentLines[1:len(contentLines)-1]...)
				newLines = append(newLines, lastNewLine)
				newLines = append(newLines, lines[lineIdx+1:]...)
				lines = newLines
			}
		}
	}
	return lines
}

// GetProjectStructure returns the project structure as a string, ignoring files and directories specified in .gitignore.
// If a .gitignore file is not found, it uses a default ignore list.
// It takes the project path as input.
func GetProjectStructure(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		fmt.Println(text)
	}

	loadGitIgnore()
	path := args["path"].(string)
	var builder strings.Builder
	builder.WriteString(path + "\n")
	err := getProjectStructureRecursive(path, "", &builder)
	if err != nil {
		return map[string]any{"error": err, "output": nil}
	}

	if builder.String() == "." || builder.String() == "" {
		return map[string]any{"error": nil, "output": "<empty directory>"}
	}
	return map[string]any{"error": nil, "output": builder.String()}
}

func getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {
	entries, err := os.ReadDir(path)
	if err != nil {
		return err
	}

	for i, entry := range entries {
		entryPath := filepath.Join(path, entry.Name())

		// skip ignored entries
		if ignoreMatcher != nil {
			relPath, _ := filepath.Rel(".", entryPath)
			if ignoreMatcher.MatchesPath(relPath) {
				continue
			}
		}
		if defaultIgnore[entry.Name()] {
			// âœ… Skip this directory and its contents completely
			if entry.IsDir() {
				continue
			}
		}

		// draw branch
		connector := "â”œâ”€â”€"
		if i == len(entries)-1 {
			connector = "â””â”€â”€"
		}
		builder.WriteString(prefix + connector + " " + entry.Name() + "\n")

		// recursively descend
		if entry.IsDir() {
			subPrefix := prefix
			if i == len(entries)-1 {
				subPrefix += "    "
			} else {
				subPrefix += "â”‚   "
			}
			// ðŸš« Don't go inside ignored directories
			if !defaultIgnore[entry.Name()] {
				err := getProjectStructureRecursive(entryPath, subPrefix, builder)
				if err != nil {
					return err
				}
			}
		}
	}

	return nil
}

func loadGitIgnore() {
	if _, err := os.Stat(".gitignore"); err == nil {
		ignoreMatcher, _ = gitignore.CompileIgnoreFile(".gitignore")
	}
}
func ExitProcess(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		fmt.Println(text)
	}

	fmt.Println("--- Task completed successfully! Exiting...")
	return map[string]any{"error": nil, "output": "Task Completed Successfully", "exit": true}

}

var CoderCapabilities = []repository.Function{
	{
		Name: "exit-process",
		Description: `Gracefully terminates the coding session with comprehensive completion validation and user satisfaction confirmation.
Performs final quality checks, validates all requirements fulfillment, and ensures clean project state before exit.
Triggers automatic documentation generation, test result summaries, and deployment readiness assessment.

Critical Exit Criteria:
âœ“ All specified tasks completed with verified functionality
âœ“ Code quality standards met (linting, formatting, testing)
âœ“ No unresolved bugs or compilation errors
âœ“ User acceptance and satisfaction confirmed
âœ“ Project documentation updated and accurate`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Professional completion summary and final recommendations for the user. Include project status, deliverables completed, and next steps.",
				},
			},
			Required: []string{},
		},
		Service: ExitProcess,
		Return: repository.Return{
			"error":  "string // System error if graceful exit fails",
			"output": "string // Final completion report and recommendations",
		},
	},

	{
		Name: "execute-command-in-terminal",
		Description: `Advanced terminal command executor with intelligent process management, output streaming, and environment isolation.
Supports complex command chaining, environment variable injection, and real-time output monitoring.
Provides sophisticated error handling with context-aware debugging and automatic retry mechanisms.

Specialized Use Cases:
ðŸ”§ Development Operations: Package management, dependency installation, build automation
ðŸ§ª Quality Assurance: Syntax validation, linting, testing, code analysis
ðŸ“¦ Build Systems: Compilation, bundling, optimization, deployment preparation  
ðŸ” System Analysis: Performance profiling, resource monitoring, diagnostic commands
âš¡ Performance Optimization: Benchmark execution, memory analysis, CPU profiling

Advanced Syntax Checking Examples:
â€¢ C/C++: { "command": "clang++", "arguments": ["-fsyntax-only", "-Wall", "-Wextra", "source.cpp"] }
â€¢ TypeScript: { "command": "tsc", "arguments": ["--noEmit", "--strict", "app.ts"] }
â€¢ Rust: { "command": "cargo", "arguments": ["check", "--all-features"] }
â€¢ Go: { "command": "go", "arguments": ["vet", "./..."] }`,

		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Contextual description of the operation being performed for enhanced logging and debugging capabilities.",
				},
				"command": {
					Type:        repository.TypeString,
					Description: "Primary executable command with full path resolution and environment variable support (e.g., 'npm', 'docker', 'kubectl', 'terraform').",
				},
				"arguments": {
					Type: repository.TypeArray,
					Items: &repository.Properties{
						Type:        repository.TypeString,
						Description: "Individual command arguments with proper escaping and parameter validation.",
					},
					Description: "Structured argument array supporting complex parameter passing, flag combinations, and multi-value options.",
				},
			},
			Required: []string{"command"},
			Optional: []string{"text", "arguments"},
		},

		Service: ExecuteCommands,

		Return: repository.Return{
			"error":   "string // Comprehensive error information including exit codes, stderr output, and diagnostic context",
			"output":  "string // Complete stdout capture with formatting preservation and encoding handling",
			"message": "string // Operation status summary with performance metrics and execution context",
		},
	},

	{
		Name: "get-project-structure",
		Description: `Intelligent project architecture analyzer with deep codebase understanding and dependency mapping.
Generates comprehensive project topology with file relationships, module dependencies, and architectural patterns.
Respects configuration files (.gitignore, .dockerignore, etc.) and provides smart filtering for development-relevant content.

Advanced Features:
ðŸ—ï¸  Architectural Pattern Detection: Identifies MVC, microservices, monorepo structures
ðŸ“Š Dependency Graph Generation: Maps import/export relationships and circular dependencies  
ðŸ” Code Metrics Analysis: LOC, complexity, test coverage distribution
ðŸ“ Smart Categorization: Separates source, tests, config, documentation, and assets
âš¡ Performance Optimized: Handles large codebases with intelligent caching and indexing`,

		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"path": {
					Type:        repository.TypeString,
					Description: "Target directory path with support for relative/absolute paths, symlink resolution, and workspace detection ('.' for current directory).",
				},
				"text": {
					Type:        repository.TypeString,
					Description: "Context description for the analysis operation, enabling targeted exploration and focused reporting.",
				},
			},
			Required: []string{"path"},
		},
		Service: GetProjectStructure,
		Return: repository.Return{
			"error":  "string // Detailed error information with path resolution and permission issues",
			"output": "string // Structured project tree with metadata, file types, and architectural insights",
		},
	},

	{
		Name: EditFileFromName,
		Description: `State-of-the-art multi-operation file editor with atomic transaction support and intelligent change management.
Provides surgical precision for code modifications with advanced conflict detection and resolution mechanisms.
Supports complex refactoring operations, batch changes, and syntax-aware transformations.

Revolutionary Capabilities:
ðŸŽ¯ Precision Targeting: Line-column accurate positioning with Unicode-aware character counting
ðŸ”„ Atomic Operations: All-or-nothing change application with automatic rollback on conflicts
ðŸ§  Context Awareness: Understands code structure, indentation, and language-specific formatting
ðŸ›¡ï¸  Safety Mechanisms: Pre-change validation, backup creation, and integrity verification
âš¡ Batch Processing: Multiple simultaneous edits with dependency ordering and optimization

Supported Operations:
â€¢ 'delete': Surgical removal of code blocks with smart whitespace handling
â€¢ 'replace': Context-aware content replacement with automatic formatting adjustment  
â€¢ 'write': Intelligent insertion with indentation matching and import management`,

		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Comprehensive context description explaining the rationale, expected outcomes, and architectural impact of the proposed changes.",
				},
				"file_path": {
					Type:        repository.TypeString,
					Description: "Absolute or relative file path with intelligent resolution, symlink following, and workspace-aware pathing (e.g., './src/components/App.tsx').",
				},
				"changes": {
					Type:        repository.TypeArray,
					Description: "Ordered sequence of atomic edit operations with precise targeting, conflict detection, and dependency-aware execution scheduling.",
					Items: &repository.Properties{
						Type:        repository.TypeObject,
						Description: "Individual edit operation with comprehensive metadata and validation parameters.",
						Properties: map[string]*repository.Properties{
							"start_line_number": {
								Type:        repository.TypeInteger,
								Description: "1-indexed starting line number with bounds validation and Unicode-aware line counting.",
							},
							"start_line_col": {
								Type:        repository.TypeInteger,
								Description: "0-indexed starting column position with UTF-8 character boundary awareness and tab expansion handling.",
							},
							"end_line_number": {
								Type:        repository.TypeInteger,
								Description: "1-indexed ending line number (inclusive) with multi-line operation support and overflow protection.",
							},
							"end_line_col": {
								Type:        repository.TypeInteger,
								Description: "0-indexed ending column position (exclusive) with precise character range selection and encoding safety.",
							},
							"operation": {
								Enum:        []string{"delete", "replace", "write"},
								Type:        repository.TypeString,
								Description: "Edit operation type: 'delete' (remove selected range), 'replace' (substitute with new content), 'write' (insert at position without removal).",
							},
							"content": {
								Type:        repository.TypeString,
								Description: "Replacement or insertion text with automatic encoding detection, line ending normalization, and indentation intelligence.",
							},
						},
						Required: []string{"start_line_number", "start_line_col", "end_line_number", "end_line_col", "operation", "content"},
					},
				},
			},
			Required: []string{"text", "file_path", "changes"},
		},
		Service: EditFile,
		Return: repository.Return{
			"error":  "string // Detailed failure analysis with conflict resolution suggestions and rollback information",
			"output": "string // Success confirmation with change summary, performance metrics, and validation results",
		},
	},

	{
		Name: RequestUserInputName,
		Description: `Advanced interactive communication interface with intelligent prompt generation and response validation.
Provides context-aware questioning with smart defaults, input validation, and conversation flow management.
Optimized for gathering requirements, confirming critical operations, and collaborative decision-making.

Enhanced Features:
ðŸ’¬ Smart Prompting: Context-aware question generation with helpful examples and constraints
ðŸŽ¯ Input Validation: Real-time validation with error correction suggestions and format guidance
â±ï¸  Timeout Management: Configurable timeouts with default fallback values and retry mechanisms
ðŸ”’ Security Aware: Sensitive input handling with masking options and secure transmission`,

		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Professionally formatted prompt message with clear instructions, context, examples, and expected input format specifications.",
				},
			},
			Required: []string{"text"},
		},
		Service: TakeInputFromTerminal,
		Return: repository.Return{
			"error":  "string // Input collection errors with retry suggestions and alternative interaction methods",
			"output": "string // User response with validation status and normalized formatting",
		},
	},

	{
		Name: "create-file",
		Description: `Advanced multi-file creation system with intelligent project scaffolding and atomic batch operations.
Supports sophisticated file generation workflows with template processing, automatic directory creation, and collision handling.
Optimized for project initialization, code generation, and infrastructure setup with enterprise-grade reliability.

Revolutionary Capabilities:
ðŸ—ï¸  Smart Scaffolding: Automatic directory structure creation with permission management
ðŸ“ Template Processing: Variable interpolation, conditional content, and dynamic generation
ðŸ›¡ï¸  Collision Management: Intelligent handling of existing files with backup and merge options
âš¡ Batch Optimization: Atomic multi-file operations with transaction rollback support
ðŸ” Content Validation: Syntax checking, encoding verification, and format compliance`,

		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"file_paths": {
					Type:        repository.TypeArray,
					Items:       &repository.Properties{Type: repository.TypeString},
					Description: "Array of file paths with intelligent path resolution, directory auto-creation, and naming conflict prevention (e.g., ['src/utils/helper.ts', 'tests/helper.test.ts']).",
				},
				"contents": {
					Type:        repository.TypeArray,
					Items:       &repository.Properties{Type: repository.TypeString},
					Description: "Corresponding content array with template processing, encoding optimization, and syntax validation for each file creation.",
				},
			},
			Required: []string{"file_paths", "contents"},
		},
		Service: CreateFile,
		Return: repository.Return{
			"error":  "string // Comprehensive error reporting with file-specific failures and recovery suggestions",
			"output": "string // Detailed creation summary with file statistics, validation results, and project impact analysis",
		},
	},

	{
		Name: "read-files",
		Description: `High-performance batch file reader with intelligent caching, encoding detection, and content analysis capabilities.
Provides comprehensive file inspection with metadata extraction, dependency analysis, and code structure understanding.
Essential for codebase exploration, dependency validation, and informed modification planning.

Advanced Intelligence:
ðŸš€ Performance Optimized: Parallel reading with memory management and streaming for large files
ðŸ§  Content Analysis: Automatic language detection, syntax validation, and structural analysis  
ðŸ” Smart Filtering: Binary detection, encoding validation, and content-type classification
ðŸ“Š Metadata Extraction: File statistics, dependency mapping, and complexity metrics
ðŸ’¾ Intelligent Caching: Smart caching with invalidation and memory optimization`,

		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"file_paths": {
					Type: repository.TypeArray,
					Items: &repository.Properties{
						Type:        repository.TypeString,
						Description: "File path with intelligent resolution, symlink handling, and workspace-aware pathing.",
					},
					Description: "Array of file paths for batch reading operations with automatic deduplication and dependency ordering.",
				},
				"text": {
					Type:        repository.TypeString,
					Description: "Context description explaining the purpose of reading these files for enhanced logging and operation tracking.",
				},
			},
			Required: []string{"file_paths"},
		},
		Service: ReadFiles,
		Return: repository.Return{
			"error":  "string // Detailed error analysis with per-file status and resolution recommendations",
			"output": "map[string]any // Structured file content mapping with metadata, encoding info, and analysis results",
		},
	},
}

// GetCoderCapabilities returns the list of all capabilities for the AgentCoder.
func GetCoderCapabilities() []repository.Function {
	return CoderCapabilities
}

// GetCoderCapabilitiesArrayMap returns the capabilities as a list of maps for API use.
func GetCoderCapabilitiesArrayMap() []map[string]any {
	coderMap := make([]map[string]any, 0)
	for _, v := range CoderCapabilities {
		coderMap = append(coderMap, v.ToObject())
	}
	return coderMap
}

// GetCoderCapabilitiesMap returns the capabilities as a map for internal use.
func GetCoderCapabilitiesMap() map[string]repository.Function {
	coderMap := make(map[string]repository.Function)
	for _, v := range CoderCapabilities {
		coderMap[v.Name] = v
	}
	return coderMap
}
func init() {
	for _, v := range CoderCapabilities {
		CodertoolsFunc[v.Name] = v
	}
}

```

## File: internal/repository/streaming.go
Language: go | Tokens: 1393 | Size: 5572 bytes

**âš ï¸ Security Issues:**

ðŸŸ¢ **[LOW]** Line 120 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   fmt.Print(part.Text)
   ```

ðŸŸ¢ **[LOW]** Line 156 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   fmt.Print(" ")
   ```

ðŸŸ¢ **[LOW]** Line 158 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   fmt.Print(word)
   ```

```go
// USED AI
package repository

import (
	"bufio"
	"crypto/tls"
	"encoding/json"
	"fmt"
	"io"
	"net"
	"net/http"
	"os"
	"strings"
	"time"
)

// StreamChunk represents a single chunk from the streaming API
type StreamChunk struct {
	Candidates []struct {
		Content struct {
			Parts []struct {
				Text         string `json:"text"`
				FunctionCall *struct {
					Name string         `json:"name"`
					Args map[string]any `json:"args"`
				} `json:"functionCall"`
			} `json:"parts"`
			Role string `json:"role"`
		} `json:"content"`
		FinishReason string `json:"finishReason,omitempty"`
	} `json:"candidates"`
	UsageMetadata *struct {
		PromptTokenCount     int `json:"promptTokenCount"`
		CandidatesTokenCount int `json:"candidatesTokenCount"`
		TotalTokenCount      int `json:"totalTokenCount"`
	} `json:"usageMetadata,omitempty"`
}

// StreamResponse accumulates the complete response from streaming chunks
type StreamResponse struct {
	TextParts     []string
	FunctionCalls []map[string]any
	FinishReason  string
}

// NewStreamingHTTPClient creates an HTTP client optimized for SSE streaming.
// It forces HTTP/1.1 (better SSE compatibility), disables response buffering,
// and uses a long timeout suitable for streaming responses.
func NewStreamingHTTPClient() *http.Client {
	return &http.Client{
		// No timeout on the client level â€” streaming responses can take minutes.
		// Individual connection timeouts are handled by the Transport.
		Timeout: 0,
		Transport: &http.Transport{
			// Force HTTP/1.1 for proper SSE streaming support
			ForceAttemptHTTP2: false,
			TLSNextProto:      make(map[string]func(authority string, c *tls.Conn) http.RoundTripper),
			// Connection-level timeouts
			DialContext: (&net.Dialer{
				Timeout:   30 * time.Second,
				KeepAlive: 30 * time.Second,
			}).DialContext,
			TLSHandshakeTimeout:   15 * time.Second,
			ResponseHeaderTimeout: 30 * time.Second,
			// Disable compression so SSE events arrive immediately
			DisableCompression: true,
		},
	}
}

// ParseSSEStream reads Server-Sent Events from the Gemini API.
// The API returns SSE format when using ?alt=sse parameter.
// Each event line starts with "data: " followed by a JSON object.
// When displayRealtime is true, text chunks are printed to stdout immediately.
func ParseSSEStream(body io.ReadCloser, displayRealtime bool) (*StreamResponse, error) {
	defer body.Close()

	scanner := bufio.NewScanner(body)
	// Increase buffer size to handle large SSE lines (up to 1MB)
	scanner.Buffer(make([]byte, 0, 1024*1024), 1024*1024)

	response := &StreamResponse{
		TextParts:     []string{},
		FunctionCalls: []map[string]any{},
	}

	for scanner.Scan() {
		line := scanner.Text()

		// Skip empty lines (SSE uses blank lines as event separators)
		if strings.TrimSpace(line) == "" {
			continue
		}

		// SSE format: "data: {json}"
		if !strings.HasPrefix(line, "data: ") {
			continue
		}

		jsonData := strings.TrimPrefix(line, "data: ")

		// Parse the JSON chunk
		var chunk StreamChunk
		if err := json.Unmarshal([]byte(jsonData), &chunk); err != nil {
			// Skip malformed chunks but continue processing
			continue
		}

		// Process each candidate in the chunk
		for _, candidate := range chunk.Candidates {
			if candidate.FinishReason != "" {
				response.FinishReason = candidate.FinishReason
			}

			for _, part := range candidate.Content.Parts {
				// Handle text parts â€” stream to stdout immediately
				if part.Text != "" {
					response.TextParts = append(response.TextParts, part.Text)
					if displayRealtime {
						fmt.Print(part.Text)
						os.Stdout.Sync()
					}
				}

				// Handle function calls
				if part.FunctionCall != nil {
					response.FunctionCalls = append(response.FunctionCalls, map[string]any{
						"name": part.FunctionCall.Name,
						"args": part.FunctionCall.Args,
					})
				}
			}
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("error reading stream: %w", err)
	}

	// Print newline after streamed text
	if displayRealtime && len(response.TextParts) > 0 {
		fmt.Println()
	}

	if len(response.TextParts) == 0 && len(response.FunctionCalls) == 0 {
		return nil, fmt.Errorf("no data received from stream")
	}

	return response, nil
}

func StreamText(text string) {
	words := strings.Fields(text)
	for i, word := range words {
		if i > 0 {
			fmt.Print(" ")
		}
		fmt.Print(word)
		os.Stdout.Sync()
		time.Sleep(30 * time.Millisecond)
	}
	fmt.Println()
	os.Stdout.Sync()
}

// ConvertStreamResponseToOutput converts a StreamResponse to the standard output format
func ConvertStreamResponseToOutput(streamResp *StreamResponse) []map[string]any {
	output := []map[string]any{}

	for _, text := range streamResp.TextParts {
		output = append(output, map[string]any{
			"type": "text",
			"data": text,
		})
	}

	for _, fc := range streamResp.FunctionCalls {
		output = append(output, map[string]any{
			"type": "functionCall",
			"name": fc["name"],
			"args": fc["args"],
		})
	}

	return output
}

// BuildChatHistoryFromStream builds a chat history entry from a streaming response
func BuildChatHistoryFromStream(streamResp *StreamResponse, role string) map[string]any {
	parts := []map[string]any{}

	for _, text := range streamResp.TextParts {
		parts = append(parts, map[string]any{"text": text})
	}

	for _, fc := range streamResp.FunctionCalls {
		parts = append(parts, map[string]any{
			"functionCall": map[string]any{
				"name": fc["name"],
				"args": fc["args"],
			},
		})
	}

	if len(parts) == 0 {
		return nil
	}

	return map[string]any{
		"role":  role,
		"parts": parts,
	}
}

```

## File: internal/service/planner/planner.go
Language: go | Tokens: 7009 | Size: 28036 bytes

**âš ï¸ Security Issues:**

ðŸŸ¢ **[LOW]** Line 617 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   log.Printf("DEBUG: Received args for PutPlanForAgent: %+v", args)
   ```

ðŸŸ¢ **[LOW]** Line 836 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   fmt.Print("dost> ")
   ```

```go
package planner

import (
	"bufio"
	"bytes"
	"context"
	"dost/internal/repository"
	"dost/internal/service/analysis"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"strings"
	"time"

	gitignore "github.com/sabhiram/go-gitignore"

	"github.com/spf13/viper"
)

var ignoreMatcher *gitignore.GitIgnore
var PlannertoolsFunc map[string]repository.Function = make(map[string]repository.Function)

var ChatHistory = make([]map[string]any, 0)
var defaultIgnore = map[string]bool{
	".git":         true,
	"node_modules": true,
	"vendor":       true,
	".venv":        true,
	".env":         true,
	".idea":        true,
	".vscode":      true,
	"__pycache__":  true,
	".dost":        true,
}

type Plans struct {
	PlanID          string   `json:"planId"`
	Title           string   `json:"title"`
	Objective       string   `json:"objective"`
	Assumptions     []string `json:"assumptions"`
	Steps           []Step   `json:"steps"`
	SuccessCriteria []string `json:"successCriteria"`
	Fallbacks       []string `json:"fallbacks"`
}

// Step represents an individual step in the plan.
type Step struct {
	ID           int      `json:"id"`
	Description  string   `json:"description"`
	Agent        string   `json:"agent"`
	Inputs       []string `json:"inputs"`
	Outputs      []string `json:"outputs"`
	Dependencies []int    `json:"dependencies"`
}

// Global storage for plans
var PlansMap = make(map[string]Plans, 0)

type AgentPlanner repository.Agent

type InitialContext struct {
	OS              string
	Arch            string
	User            string
	Shell           string
	CWD             string
	GoVersion       string
	FolderStructure map[string]any
	InstalledTools  []string
	EnvVars         map[string]string
	ProjectFiles    []string
	ProjectType     string
	GitBranch       string
	InternetAccess  bool
	AgentRole       string
	Capabilities    []string
	Timezone        string
	SessionID       string
}

func GetInitialContext() InitialContext {
	ctx := InitialContext{
		OS:              runtime.GOOS,
		Arch:            runtime.GOARCH,
		User:            os.Getenv("USERNAME"),
		Shell:           detectDefaultShell(),
		CWD:             mustGetWorkingDir(),
		FolderStructure: GetProjectStructure(map[string]any{"path": "./"}),
		GoVersion:       runtime.Version(),
		InstalledTools:  detectTools(),
		EnvVars:         getImportantEnvVars(),
		ProjectFiles:    scanProjectFiles(),
		ProjectType:     detectProjectType(),
		GitBranch:       getGitBranch(),
		InternetAccess:  checkInternet(),
		Timezone:        getLocalTimezone(),
		SessionID:       generateSessionID(),
	}
	return ctx
}
func GetProjectStructure(args map[string]any) map[string]any {
	loadGitIgnore()
	path := args["path"].(string)
	var builder strings.Builder
	builder.WriteString(path + "\n")
	err := getProjectStructureRecursive(path, "", &builder)
	if err != nil {
		return map[string]any{"error": err, "output": nil}
	}

	if builder.String() == "." || builder.String() == "" {
		return map[string]any{"error": nil, "output": "<empty directory>"}
	}
	return map[string]any{"error": nil, "output": builder.String()}
}
func getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {
	entries, err := os.ReadDir(path)
	if err != nil {
		return err
	}

	for i, entry := range entries {
		entryPath := filepath.Join(path, entry.Name())

		// skip ignored entries
		if ignoreMatcher != nil {
			relPath, _ := filepath.Rel(".", entryPath)
			if ignoreMatcher.MatchesPath(relPath) {
				continue
			}
		} else if defaultIgnore[entry.Name()] {
			continue
		}

		// draw branch
		connector := "â”œâ”€â”€"
		if i == len(entries)-1 {
			connector = "â””â”€â”€"
		}
		builder.WriteString(prefix + connector + " " + entry.Name() + "\n")

		// recursively descend
		if entry.IsDir() {
			subPrefix := prefix
			if i == len(entries)-1 {
				subPrefix += "    "
			} else {
				subPrefix += "â”‚   "
			}
			err := getProjectStructureRecursive(entryPath, subPrefix, builder)
			if err != nil {
				return err
			}
		}
	}

	return nil
}

func loadGitIgnore() {
	if _, err := os.Stat(".gitignore"); err == nil {
		ignoreMatcher, _ = gitignore.CompileIgnoreFile(".gitignore")
	}
}
func detectDefaultShell() string {
	if runtime.GOOS == "windows" {
		// prefer PowerShell if present
		if _, err := exec.LookPath("powershell"); err == nil {
			return "powershell"
		}
		return "cmd"
	}
	return os.Getenv("SHELL")
}

func mustGetWorkingDir() string {
	dir, err := os.Getwd()
	if err != nil {
		return "."
	}
	return dir
}

func detectTools() []string {
	var found []string
	val := os.Getenv("PATH")
	found = strings.Split(val, ";")
	return found
}

func getImportantEnvVars() map[string]string {
	keys := []string{"PATH", "GOROOT", "GOPATH", "JAVA_HOME"}
	env := make(map[string]string)
	for _, k := range keys {
		if v := os.Getenv(k); v != "" {
			env[k] = v
		}
	}
	return env
}

func scanProjectFiles() []string {
	files := []string{}
	filepath.Walk(".", func(path string, info os.FileInfo, err error) error {
		if err == nil && !info.IsDir() {
			if strings.HasSuffix(path, ".go") ||
				path == "go.mod" || path == "package.json" || path == "requirements.txt" ||
				path == "Dockerfile" || path == "README.md" {
				files = append(files, path)
			}
		}
		return nil
	})
	return files
}

func detectProjectType() string {
	if _, err := os.Stat("go.mod"); err == nil {
		return "Go project"
	}
	if _, err := os.Stat("package.json"); err == nil {
		return "Node.js project"
	}
	if _, err := os.Stat("requirements.txt"); err == nil {
		return "Python project"
	}
	return "Unknown"
}

func getGitBranch() string {
	cmd := exec.Command("git", "rev-parse", "--abbrev-ref", "HEAD")
	out, err := cmd.Output()
	if err != nil {
		return ""
	}
	return strings.TrimSpace(string(out))
}

func checkInternet() bool {
	cmd := exec.Command("ping", "-c", "1", "8.8.8.8")
	if runtime.GOOS == "windows" {
		cmd = exec.Command("ping", "-n", "1", "8.8.8.8")
	}
	if err := cmd.Run(); err != nil {
		return false
	}
	return true
}

func getLocalTimezone() string {
	_, tz := time.Now().Zone()
	return fmt.Sprintf("%d min offset", tz/60)
}

func generateSessionID() string {
	return fmt.Sprintf("%d", time.Now().UnixNano())
}

// Helper function to format files for Orchestrator
func formatFilesForOrchestrator(filesRead map[string]any) string {
	if len(filesRead) == 0 {
		return ""
	}

	var result strings.Builder
	result.WriteString("=== FILES CONTENT ===\n\n")

	for fileName, fileData := range filesRead {
		result.WriteString(fmt.Sprintf("FILE: %s\n", fileName))
		result.WriteString("=" + strings.Repeat("=", len(fileName)+6) + "\n")

		if chunks, ok := fileData.([]map[string]any); ok {
			for _, chunk := range chunks {
				if content, exists := chunk["content"].(string); exists {
					result.WriteString(content)
					result.WriteString("\n")
				}
			}
		}
		result.WriteString("\n" + strings.Repeat("-", 50) + "\n\n")
	}

	return result.String()
}

func (p *AgentPlanner) Interaction(args map[string]any) map[string]any {
	InitialContext := GetInitialContext()
	InitialContextBytes, err := json.Marshal(InitialContext)
	if err != nil {
		return map[string]any{"error": "Unable to get initial context"}
	}

	var userMessage strings.Builder

	// Add files content (from analysis)
	filesContent := formatFilesForOrchestrator(analysis.FilesRead)
	if filesContent != "" {
		userMessage.WriteString(filesContent)
		userMessage.WriteString("\n")
	}

	// Add initial context
	userMessage.WriteString("=== INITIAL CONTEXT ===\n")
	userMessage.WriteString(string(InitialContextBytes))
	userMessage.WriteString("\n\n")

	// Add query
	userMessage.WriteString("=== QUERY ===\n")
	if query, ok := args["query"].(string); ok {
		userMessage.WriteString(query)
	}
	log.Println("TEST: ORCHESTRATOR:  ", userMessage.String()[0:20])

	// Push consolidated user message into ChatHistory
	ChatHistory = append(ChatHistory, map[string]any{
		"role": "user",
		"parts": []map[string]any{
			{"text": userMessage.String()},
		},
	})

	for {
		// fmt.Println("Current ChatHistory:", ChatHistory)
		if ChatHistory[len(ChatHistory)-1]["role"] == "model" {
			ChatHistory = append(ChatHistory, map[string]any{
				"role": "user",
				"parts": map[string]any{
					"text": "If you feel there is not task left and nothing to do , call exit-process. Because only that can stop you and finish the program. Don't Respond with text , No text output should be there , call the exit-process. PERIOD",
				},
			})
		}
		output := p.RequestAgent(ChatHistory)

		if output["error"] != nil {
			fmt.Println("Error:", output["error"])
			os.Exit(1)
		}

		outputData, ok := output["output"].([]map[string]any)
		if !ok {
			fmt.Println("ERROR CONVERTING OUTPUT")
			return nil
		}

		if len(outputData) == 0 {
			fmt.Println("No output received")
			continue
		}

		// Process each output part
		for _, part := range outputData {
			partType, hasType := part["type"].(string)
			if !hasType {
				continue
			}

			if partType == "text" {
				// Handle text response
				if text, ok := part["data"].(string); ok {
					fmt.Println("Agent:", text)
				}
			} else if partType == "functionCall" {
				// Handle function call
				name, nameOK := part["name"].(string)
				argsData, argsOK := part["args"].(map[string]any)

				if !nameOK || !argsOK {
					fmt.Println("Error: invalid function call data")
					continue
				}

				fmt.Println("Calling function:", name)

				// Execute the function
				if function, exists := PlannertoolsFunc[name]; exists {
					result := function.Run(argsData)
					fmt.Println(result)
					if _, ok = result["exit"].(bool); ok {

						return map[string]any{}
					}
					// Add function response to chat history
					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{
								"functionResponse": map[string]any{
									"name":     name,
									"response": result,
								},
							},
						},
					})

					// Display result if it's a string
					if outputStr, ok := result["output"].(string); ok {
						fmt.Println("Result:", outputStr)
					}
				} else {
					fmt.Printf("Function %s not found\n", name)
				}
			}
		}

		// Continue the conversation loop
		fmt.Println("---")
	}
}

func (c *AgentPlanner) RequestAgent(contents []map[string]any) map[string]any {
	fmt.Printf("Processing request with Planner Agent: %s\n", c.Metadata.Name)

	// Build request payload
	request := map[string]any{
		"systemInstruction": map[string]any{
			"parts": []map[string]any{
				{"text": c.Metadata.Instructions},
			},
		},
		"toolConfig": map[string]any{
			"functionCallingConfig": map[string]any{
				"mode": "ANY",
			},
		},
		"contents": contents,
		"tools": []map[string]any{
			{"functionDeclarations": GetPlannerArrayMap()},
		},
	}

	// Marshal request body
	jsonBody, err := json.Marshal(request)
	if err != nil {
		return map[string]any{"error": err.Error(), "output": nil}
	}

	// Retry config
	const maxRetries = 5
	const maxWaitTime = 10 * time.Minute

	for attempt := 0; attempt <= maxRetries; attempt++ {
		// Create HTTP request
		req, err := http.NewRequestWithContext(
			context.Background(),
			"POST",
			c.Metadata.Endpoints["http"],
			bytes.NewBuffer(jsonBody),
		)
		if err != nil {
			return map[string]any{"error": err.Error(), "output": nil}
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("X-goog-api-key", viper.GetString("PLANNER.API_KEY"))

		// Execute request with timeout
		client := repository.NewStreamingHTTPClient()
		resp, err := client.Do(req)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}
		defer resp.Body.Close()

		// Success case - parse streaming response
		if resp.StatusCode == http.StatusOK {
			// Parse SSE stream with real-time display
			streamResp, err := repository.ParseSSEStream(resp.Body, true)
			if err != nil {
				if attempt == maxRetries {
					return map[string]any{"error": err.Error(), "output": nil}
				}
				time.Sleep(repository.ExponentialBackoff(attempt))
				continue
			}

			// Convert to standard output format
			output := repository.ConvertStreamResponseToOutput(streamResp)

			// Save chat history
			historyEntry := repository.BuildChatHistoryFromStream(streamResp, "planner")
			if historyEntry != nil {
				ChatHistory = append(ChatHistory, historyEntry)
			}

			c.Metadata.LastActive = time.Now()
			return map[string]any{"error": nil, "output": output}
		}

		// Read body for error cases
		bodyBytes, err := io.ReadAll(resp.Body)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Handle rate limits
		if resp.StatusCode == http.StatusTooManyRequests {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Rate limit exceeded after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}
			retryDelay := repository.ParseRetryDelay(string(bodyBytes))
			waitTime := retryDelay
			if waitTime <= 0 {
				waitTime = repository.ExponentialBackoff(attempt)
			}
			if waitTime > maxWaitTime {
				waitTime = maxWaitTime
			}
			fmt.Printf("Rate limit hit (attempt %d/%d). Waiting %v before retry...\n",
				attempt+1, maxRetries+1, waitTime)
			time.Sleep(waitTime)
			continue
		}

		// Retry on server errors
		if resp.StatusCode >= 500 && resp.StatusCode < 600 {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Server error after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}
			fmt.Printf("Server error (attempt %d/%d). Waiting %v before retry...\n",
				attempt+1, maxRetries+1, repository.ExponentialBackoff(attempt))
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Client errors (400â€“499) except 429 â†’ don't retry
		return map[string]any{
			"error":  fmt.Sprintf("HTTP %d: %s", resp.StatusCode, string(bodyBytes)),
			"output": nil,
		}
	}

	return map[string]any{
		"error":  fmt.Sprintf("Max retries (%d) exceeded", maxRetries),
		"output": nil,
	}
}

func (p *AgentPlanner) NewAgent() {
	model := viper.GetString("PLANNER.MODEL")
	if model == "" {
		model = "gemini-1.5-pro"
	}

	instructions := repository.PlannerInstructions

	PlannerAgentMeta := repository.AgentMetadata{
		ID:             "Planner-agent-v1",
		Name:           "Planner Agent",
		Version:        "1.0.0",
		Type:           repository.AgentType(repository.AgentPlanner),
		Instructions:   instructions,
		LastActive:     time.Now(),
		MaxConcurrency: 5,
		Timeout:        30 * time.Second,
		Status:         "active",
		Tags:           []string{"Planner", "constraints", "inputs", "outputs", "validation"},
		Endpoints: map[string]string{
			"http": fmt.Sprintf("https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse", model),
		},
	}

	p.Metadata = PlannerAgentMeta
	p.Capabilities = PlannerCapabilities
	PlannertoolsFunc = make(map[string]repository.Function)
	for _, tool := range PlannerCapabilities {
		PlannertoolsFunc[tool.Name] = tool
	}
}

func GetPlannerArrayMap() []map[string]any {
	arrayOfMap := make([]map[string]any, 0)
	for _, v := range PlannerCapabilities {
		arrayOfMap = append(arrayOfMap, v.ToObject())
	}
	return arrayOfMap
}

// GenerateTasklist will take input from user and generate a tasklist and return to user
func GenerateTasklist(args map[string]any) map[string]any {
	name, ok := args["name"].(string)
	instructions, ok2 := args["instructions"].(string)

	if !ok || !ok2 {
		return map[string]any{"error": "insufficient parameters"}
	}
	return map[string]any{"output": "Tasklist name is " + name + " tasklist instructions are " + instructions}
}

// Key changes to make planner agent return output like coder agent:

// 1. Add an exit-process function to PlannerCapabilities

// Enhanced validation and error handling
func PutPlanForAgent(args map[string]any) map[string]any {
	log.Printf("DEBUG: Received args for PutPlanForAgent: %+v", args)

	// Check if args is empty or nil
	if args == nil || len(args) == 0 {
		return map[string]any{
			"success": false,
			"error":   "No parameters provided. I need you to call gather-plan-requirements first to collect the necessary information.",
			"action":  "call gather-plan-requirements function to collect plan details from user",
		}
	}

	// Create Plans struct directly from args (no nested "plan" object)
	var plan Plans

	// Extract title
	if title, ok := args["title"].(string); ok {
		plan.Title = title
	}

	// Extract objective
	if objective, ok := args["objective"].(string); ok {
		plan.Objective = objective
	}

	// Extract planId (optional)
	if planId, ok := args["planId"].(string); ok {
		plan.PlanID = planId
	}

	// Extract steps
	if stepsData, ok := args["steps"].([]any); ok {
		for i, stepData := range stepsData {
			if stepMap, ok := stepData.(map[string]any); ok {
				step := Step{
					ID: i + 1, // Auto-assign ID
				}

				if desc, ok := stepMap["description"].(string); ok {
					step.Description = desc
				}

				if agent, ok := stepMap["agent"].(string); ok {
					step.Agent = agent
				} else {
					step.Agent = "GeneralAgent" // Default agent
				}

				// Handle inputs array
				if inputs, ok := stepMap["inputs"].([]any); ok {
					for _, input := range inputs {
						if inputStr, ok := input.(string); ok {
							step.Inputs = append(step.Inputs, inputStr)
						}
					}
				}

				// Handle outputs array
				if outputs, ok := stepMap["outputs"].([]any); ok {
					for _, output := range outputs {
						if outputStr, ok := output.(string); ok {
							step.Outputs = append(step.Outputs, outputStr)
						}
					}
				}

				// Handle dependencies array
				if deps, ok := stepMap["dependencies"].([]any); ok {
					for _, dep := range deps {
						if depInt, ok := dep.(float64); ok {
							step.Dependencies = append(step.Dependencies, int(depInt))
						}
					}
				}

				plan.Steps = append(plan.Steps, step)
			}
		}
	}

	// Extract assumptions (optional)
	if assumptions, ok := args["assumptions"].([]any); ok {
		for _, assumption := range assumptions {
			if assumptionStr, ok := assumption.(string); ok {
				plan.Assumptions = append(plan.Assumptions, assumptionStr)
			}
		}
	}

	// Extract successCriteria (optional)
	if criteria, ok := args["successCriteria"].([]any); ok {
		for _, criterion := range criteria {
			if criterionStr, ok := criterion.(string); ok {
				plan.SuccessCriteria = append(plan.SuccessCriteria, criterionStr)
			}
		}
	}

	// Extract fallbacks (optional)
	if fallbacks, ok := args["fallbacks"].([]any); ok {
		for _, fallback := range fallbacks {
			if fallbackStr, ok := fallback.(string); ok {
				plan.Fallbacks = append(plan.Fallbacks, fallbackStr)
			}
		}
	}

	// Generate unique plan ID if not provided
	if plan.PlanID == "" {
		plan.PlanID = fmt.Sprintf("plan_%d", time.Now().Unix())
	}

	// Enhanced validation with specific guidance
	validationErrors := []string{}

	if plan.Title == "" {
		validationErrors = append(validationErrors, "Missing required field: 'title'")
	}

	if plan.Objective == "" {
		validationErrors = append(validationErrors, "Missing required field: 'objective'")
	}

	if len(plan.Steps) == 0 {
		validationErrors = append(validationErrors, "Missing required field: 'steps' (must have at least one step)")
	}

	if len(validationErrors) > 0 {
		return map[string]any{
			"success": false,
			"error":   "Plan validation failed: " + strings.Join(validationErrors, ", "),
			"requirements": []string{
				"title: A descriptive name for your plan",
				"objective: A clear statement of what this plan achieves",
				"steps: An array of at least one step with 'description' field",
			},
			"example": `{
  "plan": {
    "title": "Setup Development Environment",
    "objective": "Configure a complete development environment for the project",
    "steps": [
      {
        "description": "Install required dependencies",
        "agent": "SystemAgent"
      },
      {
        "description": "Configure database connection", 
        "agent": "DatabaseAgent"
      }
    ]
  }
}`,
		}
	}

	// Validate and fix steps
	for i, step := range plan.Steps {
		if step.Description == "" {
			return map[string]any{
				"success": false,
				"error":   fmt.Sprintf("Step %d is missing required 'description' field", i+1),
				"hint":    "Each step must have a clear description of what should be done",
			}
		}

		// Auto-assign agent if missing
		if step.Agent == "" {
			plan.Steps[i].Agent = "GeneralAgent"
		}

		// Auto-assign ID if missing
		if step.ID == 0 {
			plan.Steps[i].ID = i + 1
		}
	}

	// Store the plan
	PlansMap[plan.PlanID] = plan

	// Return successful response
	return map[string]any{
		"success": true,
		"planId":  plan.PlanID,
		"message": fmt.Sprintf("Plan '%s' created successfully with %d steps", plan.Title, len(plan.Steps)),
		"plan":    plan,
	}
}
func getKeys(m map[string]any) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}

func ExitProcess(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		fmt.Println(text)
	}
	marshabData, err := json.Marshal(PlansMap)
	if err != nil {
		return map[string]any{"error": err.Error()}
	}

	return map[string]any{"error": nil, "output": string(marshabData), "exit": true}
}

func TakeInputFromTerminal(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if !ok {
		return map[string]any{"error": "No Text Provided"}
	}
	fmt.Println(text)

	requirements, ok := args["requirements"].([]any)
	reader := bufio.NewReader(os.Stdin)

	// Case 1: No requirements -> just take a single input
	if !ok || len(requirements) == 0 {
		fmt.Print("dost> ")
		input, err := reader.ReadString('\n')
		if err != nil {
			return map[string]any{
				"error":  fmt.Sprintf("Error reading input: %v", err),
				"output": nil,
			}
		}
		input = strings.TrimSpace(input)
		if input == "" {
			return map[string]any{"error": nil, "output": "<no input provided>"}
		}
		return map[string]any{"error": nil, "output": input}
	}

	// Case 2: Requirements exist -> ask each question
	results := make(map[string]string)
	for _, req := range requirements {
		question, ok := req.(string)
		if !ok {
			continue
		}

		fmt.Printf("dost> %s: ", question)
		input, err := reader.ReadString('\n')
		if err != nil {
			return map[string]any{
				"error":  fmt.Sprintf("Error reading input: %v", err),
				"output": nil,
			}
		}

		input = strings.TrimSpace(input)
		if input == "" {
			results[question] = "<no input provided>"
		} else {
			results[question] = input
		}
	}

	return map[string]any{"error": nil, "output": results}
}

// 3. Add exit-process to PlannerCapabilities array
var PlannerCapabilities = []repository.Function{
	{
		Name: "exit-process",
		Description: `Gracefully terminates the planning session with comprehensive completion validation and user satisfaction confirmation.
Performs final quality checks, validates all requirements fulfillment, and ensures clean planning state before exit.
Triggers automatic documentation generation, plan summaries, and implementation readiness assessment.

Critical Exit Criteria:
âœ“ All specified planning tasks completed with verified structure
âœ“ Plan quality standards met (clarity, feasibility, completeness)
âœ“ No unresolved planning issues or missing requirements
âœ“ User acceptance and satisfaction confirmed
âœ“ Planning documentation updated and accurate`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Professional completion summary and final recommendations for the user. Include planning status, deliverables completed, and next steps.",
				},
			},
			Required: []string{},
		},
		Service: ExitProcess,
		Return: repository.Return{
			"error":  "string // System error if graceful exit fails",
			"output": "string // Final completion report and recommendations",
		},
	},

	{
		Name: "create-plan",
		Description: `Creates a structured execution plan. Provide plan fields directly (not nested under 'plan' key).

REQUIRED FIELDS:
- title: Descriptive name for the plan  
- objective: Clear statement of what the plan achieves
- steps: Array of at least one step, each with:
  - description: What this step does (REQUIRED)
  - agent: Which agent executes this step (optional, defaults to "GeneralAgent")

OPTIONAL FIELDS:
- planId: Unique identifier (auto-generated if missing)
- assumptions: List of prerequisites  
- successCriteria: How to measure success
- fallbacks: What to do if steps fail

EXAMPLE USAGE:
{
  "title": "User Registration System",
  "objective": "Implement secure user signup process", 
  "steps": [
    {
      "description": "Create user database schema",
      "agent": "DatabaseAgent"
    },
    {
      "description": "Build registration API endpoint", 
      "agent": "BackendAgent"
    }
  ]
}`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"planId": {
					Type:        repository.TypeString,
					Description: "Unique plan identifier (auto-generated if not provided)",
				},
				"title": {
					Type:        repository.TypeString,
					Description: "REQUIRED: Descriptive title for the plan",
				},
				"objective": {
					Type:        repository.TypeString,
					Description: "REQUIRED: Clear objective statement",
				},
				"steps": {
					Type:        repository.TypeArray,
					Description: "REQUIRED: At least one execution step",
					Items: &repository.Properties{
						Type: repository.TypeObject,
						Properties: map[string]*repository.Properties{
							"id":           {Type: repository.TypeInteger, Description: "Step number (auto-assigned if missing)"},
							"description":  {Type: repository.TypeString, Description: "REQUIRED: What this step does"},
							"agent":        {Type: repository.TypeString, Description: "Which agent executes (defaults to GeneralAgent)"},
							"inputs":       {Type: repository.TypeArray, Items: &repository.Properties{Type: repository.TypeString}},
							"outputs":      {Type: repository.TypeArray, Items: &repository.Properties{Type: repository.TypeString}},
							"dependencies": {Type: repository.TypeArray, Items: &repository.Properties{Type: repository.TypeInteger}},
						},
						Required: []string{"description"},
					},
				},
				"assumptions":     {Type: repository.TypeArray, Items: &repository.Properties{Type: repository.TypeString}},
				"successCriteria": {Type: repository.TypeArray, Items: &repository.Properties{Type: repository.TypeString}},
				"fallbacks":       {Type: repository.TypeArray, Items: &repository.Properties{Type: repository.TypeString}},
			},
			Required: []string{"title", "objective", "steps"},
		},
		Service: PutPlanForAgent,
	},
	{
		Name:        "take-input-from-terminal",
		Description: `Collects input from the user via terminal interaction.`,
		Parameters: repository.Parameters{
			Type: repository.TypeObject,
			Properties: map[string]*repository.Properties{
				"text": {
					Type:        repository.TypeString,
					Description: "Prompt text to display to user",
				},
				"requirements": {
					Type:        repository.TypeArray,
					Description: "List of specific questions to ask (optional)",
					Items:       &repository.Properties{Type: repository.TypeString},
				},
			},
			Required: []string{"text", "requirements"},
		},
		Service: TakeInputFromTerminal,
	},
}

// 4. Update the init function to include all planner tools
func init() {
	for _, v := range PlannerCapabilities {
		PlannertoolsFunc[v.Name] = v
	}
}

```

## File: internal/config/config.go
Language: go | Tokens: 975 | Size: 3902 bytes

**âš ï¸ Security Issues:**

ðŸŸ¢ **[LOW]** Line 25 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   Debug   bool   `mapstructure:"debug"`
   ```

ðŸŸ¢ **[LOW]** Line 108 - Debug Code
   *Debug code or security TODO in production*
   Tool: regex
   ```
   viper.SetDefault("app.debug", false)
   ```

```go
package config

import (
	"github.com/spf13/viper"
)

// Config holds all configuration for our application
type Config struct {
	App          AppConfig          `mapstructure:"app"`
	AI           AIConfig           `mapstructure:"ai"`
	CRITIC       CriticConfig       `mapstructure:"critic"`
	EXECUTOR     ExecutorConfig     `mapstructure:"executor"`
	KNOWLEDGE    KnowledgeConfig    `mapstructure:"knowledge"`
	PLANNER      PlannerConfig      `mapstructure:"planner"`
	ORCHESTRATOR OrchestratorConfig `mapstructure:"orchestrator"`
	CODER        CoderConfig        `mapstructure:"coder"`
	Logger       LoggerConfig       `mapstructure:"logger"`
}

// AppConfig holds application-specific configuration
type AppConfig struct {
	Name    string `mapstructure:"name"`
	Version string `mapstructure:"version"`
	Port    int    `mapstructure:"port"`
	Debug   bool   `mapstructure:"debug"`
}
type CriticConfig struct {
	API_KEY string `mapstructure:"API_KEY"`
	ORG     string `mapstructure:"ORG"`
	MODEL   string `mapstructure:"MODEL"`
}
type OrchestratorConfig struct {
	API_KEY string `mapstructure:"API_KEY"`
	ORG     string `mapstructure:"ORG"`
	MODEL   string `mapstructure:"MODEL"`
}
type ExecutorConfig struct {
	API_KEY string `mapstructure:"API_KEY"`
	ORG     string `mapstructure:"ORG"`
	MODEL   string `mapstructure:"MODEL"`
}
type KnowledgeConfig struct {
	API_KEY string `mapstructure:"API_KEY"`
	ORG     string `mapstructure:"ORG"`
	MODEL   string `mapstructure:"MODEL"`
}
type PlannerConfig struct {
	API_KEY string `mapstructure:"API_KEY"`
	ORG     string `mapstructure:"ORG"`
	MODEL   string `mapstructure:"MODEL"`
}
type CoderConfig struct {
	API_KEY string `mapstructure:"API_KEY"`
	ORG     string `mapstructure:"ORG"`
	MODEL   string `mapstructure:"MODEL"`
}

// LoggerConfig holds logger configuration
type LoggerConfig struct {
	Level  string `mapstructure:"level"`
	Format string `mapstructure:"format"`
}

type AIConfig struct {
	CoderURL string `mapstructure:"CODER_URL"`
	CoderAPI string `mapstructure:"CODER_API"`
	CoderORG string `mapstructure:"CODER_ORG"`

	PlannerURL string `mapstructure:"PLANNER_URL"`
	PlannerAPI string `mapstructure:"PLANNER_API"`
	PlannerORG string `mapstructure:"PLANNER_ORG"`

	OrchestratorURL string `mapstructure:"ORCHESTRATOR_URL"`
	OrchestratorAPI string `mapstructure:"ORCHESTRATOR_API"`
	OrchestratorORG string `mapstructure:"ORCHESTRATOR_ORG"`

	CriticURL string `mapstructure:"CRITIC_URL"`
	CriticAPI string `mapstructure:"CRITIC_API"`
	CriticORG string `mapstructure:"CRITIC_ORG"`

	ExecutorURL string `mapstructure:"EXECUTOR_URL"`
	ExecutorAPI string `mapstructure:"EXECUTOR_API"`
	ExecutorORG string `mapstructure:"EXECUTOR_ORG"`

	KnowledgeURL string `mapstructure:"KNOWLEDGE_URL"`
	KnowledgeAPI string `mapstructure:"KNOWLEDGE_API"`
	KnowledgeORG string `mapstructure:"KNOWLEDGE_ORG"`

	// [DEPRECATED]
	API_KEY string `mapstructure:"API_KEY"`
	ORG     string `mapstructure:"ORG"`
	MODEL   string `mapstructure:"MODEL"`

	// TODO: Will Work on implementing this
	TEMPERATURE float32 `mapstructure:"TEMPERATURE"`
	MAX_TOKENS  int     `mapstructure:"MAX_TOKENS"`
	TOP_P       float32 `mapstructure:"TOP_P"`
}

// Load reads configuration from file and environment variables
// Config file location is determined by the caller (see cmd/app/root.go InitConfig)
// and supports platform-independent paths
func Load() (*Config, error) {
	// Set default values
	viper.SetDefault("app.name", "dost")
	viper.SetDefault("app.version", "1.0.0")
	viper.SetDefault("app.port", 8080)
	viper.SetDefault("app.debug", false)

	viper.SetDefault("ai.API_KEY", "YOUR_API_KEY")
	viper.SetDefault("ai.ORG", "YOUR_ORG")
	viper.SetDefault("ai.MODEL", "YOUR_MODEL")

	viper.SetDefault("logger.level", "info")
	viper.SetDefault("logger.format", "json")

	var config Config
	if err := viper.Unmarshal(&config); err != nil {
		return nil, err
	}

	return &config, nil
}

```

## File: internal/service/interactor/interactor.go
Language: go | Tokens: 4068 | Size: 16273 bytes

```go
package interactor

import (
	"bytes"
	"context"
	"dost/internal/repository"
	"dost/internal/service/analysis"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"strings"
	"time"

	"github.com/google/uuid"
	gitignore "github.com/sabhiram/go-gitignore"
	"github.com/spf13/viper"
)

var ignoreMatcher *gitignore.GitIgnore
var InteractorToolsFunc map[string]repository.Function = make(map[string]repository.Function)
var ChatHistory = make([]map[string]any, 0)
var defaultIgnore = map[string]bool{
	".git":         true,
	"node_modules": true,
	"vendor":       true,
	".venv":        true,
	".env":         true,
	".idea":        true,
	".vscode":      true,
	"__pycache__":  true,
	".dost":        true,
}

type InitialContext struct {
	OS              string
	Arch            string
	User            string
	Shell           string
	CWD             string
	GoVersion       string
	FolderStructure map[string]any
	InstalledTools  []string
	EnvVars         map[string]string
	ProjectFiles    []string
	ProjectType     string
	GitBranch       string
	InternetAccess  bool
	AgentRole       string
	Capabilities    []string
	Timezone        string
	SessionID       string
}
type changeInfo struct {
	startLine int
	startCol  int
	endLine   int
	endCol    int
	operation string
	content   string
	valid     bool
}

func GetInitialContext() InitialContext {
	ctx := InitialContext{
		OS:              runtime.GOOS,
		Arch:            runtime.GOARCH,
		User:            os.Getenv("USERNAME"),
		Shell:           detectDefaultShell(),
		CWD:             mustGetWorkingDir(),
		FolderStructure: GetProjectStructure(map[string]any{"path": "./"}),
		GoVersion:       runtime.Version(),
		InstalledTools:  detectTools(),
		EnvVars:         getImportantEnvVars(),
		ProjectFiles:    scanProjectFiles(),
		ProjectType:     detectProjectType(),
		GitBranch:       getGitBranch(),
		InternetAccess:  checkInternet(),
		Timezone:        getLocalTimezone(),
		SessionID:       generateSessionID(),
	}
	return ctx
}

func detectDefaultShell() string {
	if runtime.GOOS == "windows" {
		// prefer PowerShell if present
		if _, err := exec.LookPath("powershell"); err == nil {
			return "powershell"
		}
		return "cmd"
	}
	return os.Getenv("SHELL")
}

func mustGetWorkingDir() string {
	dir, err := os.Getwd()
	if err != nil {
		return "."
	}
	return dir
}

func detectTools() []string {
	var found []string
	val := os.Getenv("PATH")
	found = strings.Split(val, ";")
	return found
}

func getImportantEnvVars() map[string]string {
	keys := []string{"PATH", "GOROOT", "GOPATH", "JAVA_HOME"}
	env := make(map[string]string)
	for _, k := range keys {
		if v := os.Getenv(k); v != "" {
			env[k] = v
		}
	}
	return env
}

func scanProjectFiles() []string {
	files := []string{}
	filepath.Walk(".", func(path string, info os.FileInfo, err error) error {
		if err == nil && !info.IsDir() {
			if strings.HasSuffix(path, ".go") ||
				path == "go.mod" || path == "package.json" || path == "requirements.txt" ||
				path == "Dockerfile" || path == "README.md" {
				files = append(files, path)
			}
		}
		return nil
	})
	return files
}

func detectProjectType() string {
	if _, err := os.Stat("go.mod"); err == nil {
		return "Go project"
	}
	if _, err := os.Stat("package.json"); err == nil {
		return "Node.js project"
	}
	if _, err := os.Stat("requirements.txt"); err == nil {
		return "Python project"
	}
	return "Unknown"
}

func getGitBranch() string {
	cmd := exec.Command("git", "rev-parse", "--abbrev-ref", "HEAD")
	out, err := cmd.Output()
	if err != nil {
		return ""
	}
	return strings.TrimSpace(string(out))
}

func checkInternet() bool {
	cmd := exec.Command("ping", "-c", "1", "8.8.8.8")
	if runtime.GOOS == "windows" {
		cmd = exec.Command("ping", "-n", "1", "8.8.8.8")
	}
	if err := cmd.Run(); err != nil {
		return false
	}
	return true
}

func getLocalTimezone() string {
	_, tz := time.Now().Zone()
	return fmt.Sprintf("%d min offset", tz/60)
}

func generateSessionID() string {
	return fmt.Sprintf("%d", time.Now().UnixNano())
}

func formatFilesForInteractor(filesRead map[string]any) string {
	if len(filesRead) == 0 {
		return ""
	}

	var result strings.Builder
	result.WriteString("=== FILES CONTENT ===\n\n")

	for fileName, fileData := range filesRead {
		result.WriteString(fmt.Sprintf("FILE: %s\n", fileName))
		result.WriteString("=" + strings.Repeat("=", len(fileName)+6) + "\n")

		if chunks, ok := fileData.([]map[string]any); ok {
			for _, chunk := range chunks {
				if content, exists := chunk["content"].(string); exists {
					result.WriteString(content)
					result.WriteString("\n")
				}
			}
		}
		result.WriteString("\n" + strings.Repeat("-", 50) + "\n\n")
	}

	return result.String()
}

type AgentInteractor repository.Agent

const interactorName = "Interactor"
const interactorVersion = "0.1.0"

// NewAgent creates and initializes a new AgentInteractor instance.
func (c *AgentInteractor) NewAgent() {
	model := viper.GetString("INTERACTOR.MODEL")
	if model == "" {
		model = "gemini-1.5-pro"
	}
	endPoints := fmt.Sprintf("https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse", model)
	id := fmt.Sprintf("interactor-%s", uuid.NewString())

	agentMetadata := repository.AgentMetadata{
		ID:             id,
		Name:           interactorName,
		Version:        interactorVersion,
		Type:           repository.AgentInteractor,
		Instructions:   repository.InteractorInstructions,
		MaxConcurrency: 5,
		Timeout:        10 * time.Minute,
		Tags:           []string{"interactor", "interaction", "user", "conversation"},
		Endpoints:      map[string]string{"http": endPoints},
		Context:        make(map[string]any),
		Status:         "active",
		LastActive:     time.Now(),
	}

	c.Metadata = agentMetadata
	c.Capabilities = InteractorCapabilities

}

func (p *AgentInteractor) Interaction(args map[string]any) map[string]any {
	InitialContext := GetInitialContext()
	InitialContextBytes, err := json.Marshal(InitialContext)
	if err != nil {
		return map[string]any{"error": "Unable to get initial context"}
	}

	var userMessage strings.Builder

	filesContent := formatFilesForInteractor(analysis.FilesRead)
	if filesContent != "" {
		userMessage.WriteString(filesContent)
		userMessage.WriteString("\n")
	}

	// Add initial context
	userMessage.WriteString("=== INITIAL CONTEXT ===\n")
	userMessage.WriteString(string(InitialContextBytes))
	userMessage.WriteString("\n\n")

	// Add query
	userMessage.WriteString("=== QUERY ===\n")
	if query, ok := args["query"].(string); ok {
		userMessage.WriteString(query)
	}
	log.Println("TEST: CODER:  ", userMessage.String()[0:20])
	// Push consolidated user message into ChatHistory
	ChatHistory = append(ChatHistory, map[string]any{
		"role": "user",
		"parts": []map[string]any{
			{"text": userMessage.String()},
		},
	})

	for {
		// Ensure exit-process is always enforced
		if len(ChatHistory) > 0 && ChatHistory[len(ChatHistory)-1]["role"] == "model" {
			ChatHistory = append(ChatHistory, map[string]any{
				"role": "user",
				"parts": []map[string]any{
					{
						"text": "If you feel there is no task left and nothing to do, call exit-process. Because only that can stop you and finish the program. Don't respond with text, no text output should be there, call the exit-process. PERIOD",
					},
				},
			})
		}

		output := p.RequestAgent(ChatHistory)

		if output["error"] != nil {
			fmt.Println("Error:", output["error"])
			os.Exit(1)
		}

		outputData, ok := output["output"].([]map[string]any)
		if !ok {
			fmt.Println("ERROR CONVERTING OUTPUT")
			return nil
		}

		if len(outputData) == 0 {
			fmt.Println("No output received")
			continue
		}

		// Process each output part
		for _, part := range outputData {
			partType, hasType := part["type"].(string)
			if !hasType {
				continue
			}

			switch partType {
			case "text":
				if text, ok := part["data"].(string); ok {
					fmt.Println("Agent:", text)
				}

			case "functionCall":
				name, nameOK := part["name"].(string)
				argsData, argsOK := part["args"].(map[string]any)

				if !nameOK || !argsOK {
					fmt.Println("Error: invalid function call data")
					continue
				}

				fmt.Println("Calling function:", name)

				// Execute the function
				if function, exists := InteractorToolsFunc[name]; exists {
					result := function.Run(argsData)

					// Check for exit condition
					if _, ok := result["exit"].(bool); ok {
						return map[string]any{"coder-id": result["output"]}
					}

					// Add function response back to chat history
					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{
								"functionResponse": map[string]any{
									"name":     name,
									"response": result,
								},
							},
						},
					})

					if outputStr, ok := result["output"].(string); ok {
						fmt.Println("Result:", outputStr)
					}
				} else {
					fmt.Printf("Function %s not found\n", name)

					// Add error response into chat
					ChatHistory = append(ChatHistory, map[string]any{
						"role": "user",
						"parts": []map[string]any{
							{"text": fmt.Sprintf("Error: Function '%s' not found", name)},
						},
					})
				}
			}
		}

		fmt.Println("---")
	}
}

func (c *AgentInteractor) RequestAgent(contents []map[string]any) map[string]any {
	fmt.Printf("Processing request with Coder Agent: %s\n", c.Metadata.Name)

	// Build request payload
	request := map[string]any{
		"systemInstruction": map[string]any{
			"parts": []map[string]any{
				{"text": c.Metadata.Instructions},
			},
		},
		"toolConfig": map[string]any{
			"functionCallingConfig": map[string]any{
				"mode": "ANY",
			},
		},
		"contents": contents,
		"tools": []map[string]any{
			{"functionDeclarations": GetInteractorCapabilitiesArrayMap()},
		},
	}

	// Marshal request body
	jsonBody, err := json.Marshal(request)
	if err != nil {
		return map[string]any{"error": err.Error(), "output": nil}
	}

	// Retry config
	const maxRetries = 5
	const maxWaitTime = 10 * time.Minute

	for attempt := 0; attempt <= maxRetries; attempt++ {
		// Create HTTP request
		req, err := http.NewRequestWithContext(
			context.Background(),
			"POST",
			c.Metadata.Endpoints["http"],
			bytes.NewBuffer(jsonBody),
		)
		if err != nil {
			return map[string]any{"error": err.Error(), "output": nil}
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("X-goog-api-key", viper.GetString("CODER.API_KEY"))

		// Execute request with timeout
		client := repository.NewStreamingHTTPClient()
		resp, err := client.Do(req)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}
		defer resp.Body.Close()

		// Success case - parse streaming response
		if resp.StatusCode == http.StatusOK {
			// Parse SSE stream with real-time display
			streamResp, err := repository.ParseSSEStream(resp.Body, true)
			if err != nil {
				if attempt == maxRetries {
					return map[string]any{"error": err.Error(), "output": nil}
				}
				time.Sleep(repository.ExponentialBackoff(attempt))
				continue
			}

			// Convert to standard output format
			output := repository.ConvertStreamResponseToOutput(streamResp)

			// Save chat history
			historyEntry := repository.BuildChatHistoryFromStream(streamResp, "interactor")
			if historyEntry != nil {
				ChatHistory = append(ChatHistory, historyEntry)
			}

			c.Metadata.LastActive = time.Now()
			return map[string]any{"error": nil, "output": output}
		}

		// Read body for error cases
		bodyBytes, err := io.ReadAll(resp.Body)
		if err != nil {
			if attempt == maxRetries {
				return map[string]any{"error": err.Error(), "output": nil}
			}
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Handle rate limits
		if resp.StatusCode == http.StatusTooManyRequests {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Rate limit exceeded after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}
			retryDelay := repository.ParseRetryDelay(string(bodyBytes))
			waitTime := retryDelay
			if waitTime <= 0 {
				waitTime = repository.ExponentialBackoff(attempt)
			}
			if waitTime > maxWaitTime {
				waitTime = maxWaitTime
			}
			fmt.Printf("Rate limit hit (attempt %d/%d). Waiting %v before retry...\n",
				attempt+1, maxRetries+1, waitTime)
			time.Sleep(waitTime)
			continue
		}

		// Retry on server errors
		if resp.StatusCode >= 500 && resp.StatusCode < 600 {
			if attempt == maxRetries {
				return map[string]any{
					"error": fmt.Sprintf("Server error after %d retries. HTTP %d: %s",
						maxRetries, resp.StatusCode, string(bodyBytes)),
					"output": nil,
				}
			}
			fmt.Printf("Server error (attempt %d/%d). Waiting %v before retry...\n",
				attempt+1, maxRetries+1, repository.ExponentialBackoff(attempt))
			time.Sleep(repository.ExponentialBackoff(attempt))
			continue
		}

		// Client errors (400â€“499) except 429 â†’ don't retry
		return map[string]any{
			"error":  fmt.Sprintf("HTTP %d: %s", resp.StatusCode, string(bodyBytes)),
			"output": nil,
		}
	}

	return map[string]any{
		"error":  fmt.Sprintf("Max retries (%d) exceeded", maxRetries),
		"output": nil,
	}
}

// GetProjectStructure returns the project structure as a string, ignoring files and directories specified in .gitignore.
// If a .gitignore file is not found, it uses a default ignore list.
// It takes the project path as input.
func GetProjectStructure(args map[string]any) map[string]any {
	text, ok := args["text"].(string)
	if ok && text != "" {
		fmt.Println(text)
	}

	loadGitIgnore()
	path := args["path"].(string)
	var builder strings.Builder
	builder.WriteString(path + "\n")
	err := getProjectStructureRecursive(path, "", &builder)
	if err != nil {
		return map[string]any{"error": err, "output": nil}
	}

	if builder.String() == "." || builder.String() == "" {
		return map[string]any{"error": nil, "output": "<empty directory>"}
	}
	return map[string]any{"error": nil, "output": builder.String()}
}

func getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {
	entries, err := os.ReadDir(path)
	if err != nil {
		return err
	}

	for i, entry := range entries {
		entryPath := filepath.Join(path, entry.Name())

		// skip ignored entries
		if ignoreMatcher != nil {
			relPath, _ := filepath.Rel(".", entryPath)
			if ignoreMatcher.MatchesPath(relPath) {
				continue
			}
		}
		if defaultIgnore[entry.Name()] {
			// âœ… Skip this directory and its contents completely
			if entry.IsDir() {
				continue
			}
		}

		// draw branch
		connector := "â”œâ”€â”€"
		if i == len(entries)-1 {
			connector = "â””â”€â”€"
		}
		builder.WriteString(prefix + connector + " " + entry.Name() + "\n")

		// recursively descend
		if entry.IsDir() {
			subPrefix := prefix
			if i == len(entries)-1 {
				subPrefix += "    "
			} else {
				subPrefix += "â”‚   "
			}
			// ðŸš« Don't go inside ignored directories
			if !defaultIgnore[entry.Name()] {
				err := getProjectStructureRecursive(entryPath, subPrefix, builder)
				if err != nil {
					return err
				}
			}
		}
	}

	return nil
}

func loadGitIgnore() {
	if _, err := os.Stat(".gitignore"); err == nil {
		ignoreMatcher, _ = gitignore.CompileIgnoreFile(".gitignore")
	}
}

var InteractorCapabilities = []repository.Function{}

func GetInteractorCapabilities() []repository.Function {
	return InteractorCapabilities
}

// GetInteractorCapabilitiesArrayMap returns the capabilities as a list of maps for API use.
func GetInteractorCapabilitiesArrayMap() []map[string]any {
	coderMap := make([]map[string]any, 0)
	for _, v := range InteractorCapabilities {
		coderMap = append(coderMap, v.ToObject())
	}
	return coderMap
}

// GetInteractorCapabilitiesMap returns the capabilities as a map for internal use.
func GetInteractorCapabilitiesMap() map[string]repository.Function {
	coderMap := make(map[string]repository.Function)
	for _, v := range InteractorCapabilities {
		coderMap[v.Name] = v
	}
	return coderMap
}
func init() {
	for _, v := range InteractorCapabilities {
		InteractorToolsFunc[v.Name] = v
	}
}

```

## File: internal/repository/tasks.go
Language: go | Tokens: 2169 | Size: 8678 bytes

```go
package repository

import (
	"encoding/json"
	"fmt"
	"strings"
	"time"
)

type TaskStatus string

const (
	StatusPending    TaskStatus = "pending"
	StatusInProgress TaskStatus = "in_progress"
	StatusCompleted  TaskStatus = "completed"
	StatusFailed     TaskStatus = "failed"
	StatusStuck      TaskStatus = "stuck"
)

type TaskTracker struct {
	// Core Task Info
	TaskID    string     `json:"taskId"`
	Title     string     `json:"title"`
	Status    TaskStatus `json:"status"`
	Priority  int        `json:"priority"` // 1-5, 5 being highest
	CreatedBy string     `json:"createdBy"`

	// Progress Tracking
	CurrentPhase   string   `json:"currentPhase"`
	CompletedSteps []string `json:"completedSteps"`
	PendingSteps   []string `json:"pendingSteps"`

	// File Operations
	FilesCreated  []string `json:"filesCreated"`
	FilesModified []string `json:"filesModified"`

	// Command Execution
	CommandsRun           []string `json:"commandsRun"`
	FailedCommands        []string `json:"failedCommands"`
	LastSuccessfulCommand string   `json:"lastSuccessfulCommand"`

	// AI Interaction
	LastAIResponse       string         `json:"lastAiResponse"`
	LastFunctionCall     string         `json:"lastFunctionCall"`
	LastFunctionResponse map[string]any `json:"lastFunctionResponse"`

	// Iteration & Loop Prevention
	Iteration                  int `json:"iteration"`
	ConsecutiveReadCalls       int `json:"consecutiveReadCalls"`
	ConsecutiveSameCommands    int `json:"consecutiveSameCommands"`
	FunctionCallsThisIteration int `json:"functionCallsThisIteration"`
	EmptyResponseCount         int `json:"emptyResponseCount"`

	// Error Handling
	LastError           string   `json:"lastError"`
	ErrorCount          int      `json:"errorCount"`
	DependencyErrors    []string `json:"dependencyErrors"`
	ConsecutiveFailures int      `json:"consecutiveFailures"`

	// State Flags
	TaskCompleted             bool `json:"taskCompleted"`
	ErrorsFound               bool `json:"errorsFound"`
	BuildAttempted            bool `json:"buildAttempted"`
	RequiresFixing            bool `json:"requiresFixing"`
	ProjectStructureRetrieved bool `json:"projectStructureRetrieved"`

	// Advanced Tracking
	LastActionType         string `json:"lastActionType"`
	ConversationResetCount int    `json:"conversationResetCount"`

	// Timing
	StartTime        time.Time      `json:"startTime"`
	LastSuccessTime  time.Time      `json:"lastSuccessTime"`
	MaxExecutionTime time.Duration  `json:"maxExecutionTime"`
	IdleTime         time.Duration  `json:"idleTime"`
	PlanningComplete bool           `json:"planningComplete"`
	ExecutionPlan    map[string]any `json:"executionPlan"`
	NextStep         string         `json:"nextStep"`
}

func (T *TaskTracker) ToObject() map[string]any {

	// Convert struct to JSON
	jsonData, err := json.Marshal(T)
	if err != nil {
		fmt.Println("Error marshaling JSON:", err)
		return nil
	}

	// Unmarshal JSON into a map[string]any
	var taskMap map[string]any
	err = json.Unmarshal(jsonData, &taskMap)
	if err != nil {
		fmt.Println("Error unmarshaling JSON:", err)
		return nil
	}
	return taskMap
}
func NewTask(params map[string]any) map[string]any {
	title, _ := params["title"].(string)
	createdBy, _ := params["createdBy"].(string)
	status, _ := params["status"].(TaskStatus)

	// Extract planning data if provided
	planningComplete, _ := params["planningComplete"].(bool)
	executionPlan, _ := params["executionPlan"].(map[string]any)
	nextStep, _ := params["nextStep"].(string)

	tracker := TaskTracker{
		TaskID:               generateTaskID(),
		Title:                title,
		Status:               status,
		Priority:             3, // Default medium priority
		CreatedBy:            createdBy,
		CurrentPhase:         "initialization",
		CompletedSteps:       make([]string, 0),
		PendingSteps:         make([]string, 0),
		FilesCreated:         make([]string, 0),
		FilesModified:        make([]string, 0),
		CommandsRun:          make([]string, 0),
		FailedCommands:       make([]string, 0),
		DependencyErrors:     make([]string, 0),
		StartTime:            time.Now(),
		LastSuccessTime:      time.Now(),
		MaxExecutionTime:     30 * time.Minute,
		LastFunctionResponse: make(map[string]any),
		PlanningComplete:     planningComplete,
		ExecutionPlan:        executionPlan,
		NextStep:             nextStep,
	}

	return map[string]any{
		"error":  nil,
		"output": tracker.ToObject(),
	}
}

// Helper function to generate unique task ID
func generateTaskID() string {
	return fmt.Sprintf("task_%d", time.Now().UnixNano())
}
func ShouldTerminate(tracker *TaskTracker) bool {
	// Time-based termination
	if time.Since(tracker.StartTime) > tracker.MaxExecutionTime {
		fmt.Printf("â° Maximum execution time (%v) reached\n", tracker.MaxExecutionTime)
		return true
	}

	// Task explicitly completed
	if tracker.TaskCompleted {
		return true
	}

	// Too many empty responses
	if tracker.EmptyResponseCount > 10 {
		fmt.Printf("ðŸ”‡ Too many empty AI responses (%d)\n", tracker.EmptyResponseCount)
		return true
	}

	// Too many conversation resets
	if tracker.ConversationResetCount > 5 {
		fmt.Printf("ðŸ”„ Too many conversation resets (%d)\n", tracker.ConversationResetCount)
		return true
	}

	// Excessive errors without progress
	if tracker.ErrorCount > 20 && len(tracker.FilesCreated) == 0 && len(tracker.CommandsRun) == 0 {
		fmt.Printf("ðŸ’¥ Too many errors (%d) with no tangible progress\n", tracker.ErrorCount)
		return true
	}

	// Long idle time without meaningful actions
	if tracker.IdleTime > 3*time.Minute {
		fmt.Printf("ðŸ˜´ No meaningful progress for %v\n", tracker.IdleTime)
		return true
	}

	// Successful completion indicators
	if IsTaskLikelyComplete(tracker) {
		fmt.Printf("ðŸŽ¯ Task appears to be complete based on heuristics\n")
		tracker.TaskCompleted = true
		return true
	}

	return false
}

// Check if task is likely complete based on heuristics
func IsTaskLikelyComplete(tracker *TaskTracker) bool {
	// Basic success patterns
	if len(tracker.FilesCreated) > 0 && len(tracker.CommandsRun) > 0 && tracker.ErrorCount < 3 {
		return true
	}

	// Hello world type tasks
	taskLower := strings.ToLower(tracker.Title)
	if strings.Contains(taskLower, "hello") && strings.Contains(taskLower, "world") {
		return len(tracker.FilesCreated) > 0 || len(tracker.FilesModified) > 0
	}

	// Simple file creation tasks
	if strings.Contains(taskLower, "create") && strings.Contains(taskLower, "file") {
		return len(tracker.FilesCreated) > 0
	}

	// Build/compile tasks that succeeded
	if (strings.Contains(taskLower, "build") || strings.Contains(taskLower, "compile")) && tracker.BuildAttempted {
		return len(tracker.FailedCommands) == 0 || tracker.LastSuccessfulCommand != ""
	}

	return false
}

// Check if we should pause for user input
func ShouldPauseForUserInput(tracker *TaskTracker) bool {
	// Don't pause too early
	if tracker.Iteration < 5 {
		return false
	}

	// Pause if too many dependency errors
	if len(tracker.DependencyErrors) > 3 {
		return true
	}

	// Pause after many iterations without clear progress
	if tracker.Iteration > 15 && len(tracker.FilesCreated) == 0 && len(tracker.CommandsRun) == 0 {
		return true
	}

	return false
}

func EvaluateTaskCompletionWithErrorAnalysis(tracker *TaskTracker, returns map[string]any, originalTask string) bool {
	if tracker.TaskCompleted {
		return true
	}

	if tracker.ErrorCount > 10 && len(tracker.FilesCreated) > 1 {
		fmt.Printf("âš ï¸ Too many errors, but files were created. Marking as complete.\n")
		return true
	}

	// Simple task completion for basic tasks like "hello world"
	taskLower := strings.ToLower(originalTask)
	if strings.Contains(taskLower, "hello") && strings.Contains(taskLower, "world") {
		if len(tracker.FilesCreated) > 0 || len(tracker.FilesModified) > 0 {
			fmt.Printf("âœ… Hello world task complete: file created/modified\n")
			return true
		}
	}

	if len(tracker.FilesCreated) >= 1 && len(tracker.CommandsRun) > 0 {
		fmt.Printf("ðŸ—‚ï¸ Task appears complete: files created and commands executed\n")
		return true
	}

	if tracker.Iteration > 20 && len(tracker.FilesCreated) > 0 && len(tracker.CompletedSteps) > 3 {
		fmt.Printf("ðŸ”¥ Auto-completing task due to iteration limit with progress\n")
		return true
	}

	// Check if AI explicitly marked as complete
	outputs, ok := returns["output"].([]map[string]any)
	if ok {
		for _, output := range outputs {
			if text, ok := output["text"].(string); ok {
				textUpper := strings.ToUpper(text)
				if strings.Contains(textUpper, "TASK_COMPLETE") ||
					strings.Contains(textUpper, "TASK COMPLETED") ||
					strings.Contains(textUpper, "SUCCESSFULLY COMPLETED") {
					return true
				}
			}
		}
	}

	return false
}

```

## File: internal/repository/file_upload.go
Language: go | Tokens: 1612 | Size: 6451 bytes

```go
package repository

import (
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"mime"
	"net/http"
	"os"
	"path/filepath"
	"time"
)

// FileUploadResponse represents the Gemini File API response
type FileUploadResponse struct {
	File struct {
		Name        string `json:"name"`
		DisplayName string `json:"displayName"`
		MimeType    string `json:"mimeType"`
		SizeBytes   string `json:"sizeBytes"`
		CreateTime  string `json:"createTime"`
		UpdateTime  string `json:"updateTime"`
		URI         string `json:"uri"`
		State       string `json:"state"`
	} `json:"file"`
}

// FileCacheEntry stores cached file upload info
type FileCacheEntry struct {
	FileURI     string    `json:"file_uri"`
	ContentHash string    `json:"content_hash"`
	UploadedAt  time.Time `json:"uploaded_at"`
	FilePath    string    `json:"file_path"`
}

const cacheDir = ".dost_cache"
const cacheFile = "file_cache.json"
const cacheMaxAge = 47 * time.Hour // Gemini keeps files for 48h, refresh at 47h

// hashFile computes SHA-256 hash of a file
func hashFile(path string) (string, error) {
	f, err := os.Open(path)
	if err != nil {
		return "", err
	}
	defer f.Close()

	h := sha256.New()
	if _, err := io.Copy(h, f); err != nil {
		return "", err
	}
	return hex.EncodeToString(h.Sum(nil)), nil
}

// loadCache reads the local file cache
func loadFileCache() (*FileCacheEntry, error) {
	data, err := os.ReadFile(filepath.Join(cacheDir, cacheFile))
	if err != nil {
		return nil, err
	}
	var entry FileCacheEntry
	if err := json.Unmarshal(data, &entry); err != nil {
		return nil, err
	}
	return &entry, nil
}

// saveCache writes the local file cache
func saveFileCache(entry *FileCacheEntry) error {
	os.MkdirAll(cacheDir, 0755)
	data, err := json.MarshalIndent(entry, "", "  ")
	if err != nil {
		return err
	}
	return os.WriteFile(filepath.Join(cacheDir, cacheFile), data, 0644)
}

// UploadFile uploads a file to the Gemini File API and returns the file URI.
func UploadFile(filePath, apiKey string) (string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return "", fmt.Errorf("failed to open file: %w", err)
	}
	defer file.Close()

	// Detect MIME type
	ext := filepath.Ext(filePath)
	mimeType := mime.TypeByExtension(ext)
	if mimeType == "" {
		mimeType = "text/plain"
	}

	// Build the upload URL
	uploadURL := fmt.Sprintf(
		"https://generativelanguage.googleapis.com/upload/v1beta/files?key=%s",
		apiKey,
	)

	// Create multipart request â€” Gemini expects raw file body with metadata headers
	req, err := http.NewRequest("POST", uploadURL, file)
	if err != nil {
		return "", fmt.Errorf("failed to create request: %w", err)
	}

	displayName := filepath.Base(filePath)
	req.Header.Set("Content-Type", mimeType)
	req.Header.Set("X-Goog-Upload-Protocol", "raw")
	req.Header.Set("X-Goog-Upload-Display-Name", displayName)

	client := &http.Client{Timeout: 60 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", fmt.Errorf("upload request failed: %w", err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("failed to read response: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("upload failed (HTTP %d): %s", resp.StatusCode, string(body))
	}

	var uploadResp FileUploadResponse
	if err := json.Unmarshal(body, &uploadResp); err != nil {
		return "", fmt.Errorf("failed to parse response: %w", err)
	}

	if uploadResp.File.URI == "" {
		return "", fmt.Errorf("no file URI in response: %s", string(body))
	}

	// Check if already ACTIVE (small files are often ACTIVE immediately)
	if uploadResp.File.State != "ACTIVE" && uploadResp.File.Name != "" {
		if err := waitForFileActive(uploadResp.File.Name, apiKey); err != nil {
			return "", fmt.Errorf("file processing failed: %w", err)
		}
	}

	return uploadResp.File.URI, nil
}

// FileStatusResponse represents the GET /files/{id} response (flat, not wrapped)
type FileStatusResponse struct {
	Name  string `json:"name"`
	URI   string `json:"uri"`
	State string `json:"state"`
}

// waitForFileActive polls the file status until it becomes ACTIVE
func waitForFileActive(fileName, apiKey string) error {
	checkURL := fmt.Sprintf(
		"https://generativelanguage.googleapis.com/v1beta/%s?key=%s",
		fileName, apiKey,
	)

	client := &http.Client{Timeout: 10 * time.Second}

	for i := 0; i < 30; i++ { // Max 60 seconds (30 * 2s)
		resp, err := client.Get(checkURL)
		if err != nil {
			return fmt.Errorf("failed to check file status: %w", err)
		}

		body, _ := io.ReadAll(resp.Body)
		resp.Body.Close()

		var fileResp FileStatusResponse
		if err := json.Unmarshal(body, &fileResp); err != nil {
			return fmt.Errorf("failed to parse file status: %w", err)
		}

		if fileResp.State == "ACTIVE" {
			return nil
		}
		if fileResp.State == "FAILED" {
			return fmt.Errorf("file processing failed")
		}

		fmt.Printf("â³ File processing (%s)...\n", fileResp.State)
		time.Sleep(2 * time.Second)
	}

	return fmt.Errorf("file processing timed out")
}

// GetCachedFileURI returns a cached file URI if available, otherwise uploads and caches.
// It re-uploads only if the file content has changed or the cached URI has expired.
func GetCachedFileURI(filePath, apiKey string) (string, error) {
	// Hash the current file
	currentHash, err := hashFile(filePath)
	if err != nil {
		return "", fmt.Errorf("failed to hash file: %w", err)
	}

	// Check cache
	cached, err := loadFileCache()
	if err == nil && cached.ContentHash == currentHash && cached.FilePath == filePath {
		// Check if URI is still valid (less than 47 hours old)
		if time.Since(cached.UploadedAt) < cacheMaxAge {
			fmt.Println("ðŸ“Ž Using cached context file (no changes detected)")
			return cached.FileURI, nil
		}
		fmt.Println("ðŸ“Ž Context cache expired, re-uploading...")
	} else if err == nil && cached.ContentHash != currentHash {
		fmt.Println("ðŸ“Ž Context changed, re-uploading...")
	}

	// Upload the file
	fmt.Printf("ðŸ“¤ Uploading context file: %s\n", filepath.Base(filePath))
	fileURI, err := UploadFile(filePath, apiKey)
	if err != nil {
		return "", err
	}
	fmt.Println("âœ… Context file uploaded successfully")

	// Save to cache
	cacheEntry := &FileCacheEntry{
		FileURI:     fileURI,
		ContentHash: currentHash,
		UploadedAt:  time.Now(),
		FilePath:    filePath,
	}
	if err := saveFileCache(cacheEntry); err != nil {
		fmt.Printf("âš ï¸  Warning: could not save cache: %v\n", err)
	}

	return fileURI, nil
}

```

## File: testings/main.c
Language: c | Tokens: 1030 | Size: 4122 bytes

```c
/*
 *  Simple 3D cube rendering application using DirectX 11.
 */
#include <windows.h>
#include <d3d11.h>
#include <d3dcompiler.h>
#include <DirectXMath.h>

// Window parameters
#define WINDOW_WIDTH 800
#define WINDOW_HEIGHT 600

// Direct3D device and context
ID3D11Device* g_pd3dDevice = nullptr;
ID3D11DeviceContext* g_pImmediateContext = nullptr;

// Swap chain
IDXGISwapChain* g_pSwapChain = nullptr;

// Render target view
ID3D11RenderTargetView* g_pRenderTargetView = nullptr;

// Vertex shader
ID3D11VertexShader* g_pVertexShader = nullptr;

// Pixel shader
ID3D11PixelShader* g_pPixelShader = nullptr;

// Input layout
ID3D11InputLayout* g_pInputLayout = nullptr;

// Vertex buffer
ID3D11Buffer* g_pVertexBuffer = nullptr;

// Constant buffer
ID3D11Buffer* g_pConstantBuffer = nullptr;

// Cube vertices
struct Vertex {
    DirectX::XMFLOAT3 Pos;
    DirectX::XMFLOAT4 Color;
};

Vertex g_Vertices[] = {
    { {-1.0f, 1.0f, -1.0f}, {1.0f, 0.0f, 0.0f, 1.0f} },
    { {1.0f, 1.0f, -1.0f}, {0.0f, 1.0f, 0.0f, 1.0f} },
    { {1.0f, 1.0f, 1.0f}, {0.0f, 0.0f, 1.0f, 1.0f} },
    { {-1.0f, 1.0f, 1.0f}, {1.0f, 1.0f, 0.0f, 1.0f} },
    { {-1.0f, -1.0f, -1.0f}, {1.0f, 0.0f, 1.0f, 1.0f} },
    { {1.0f, -1.0f, -1.0f}, {0.0f, 1.0f, 1.0f, 1.0f} },
    { {1.0f, -1.0f, 1.0f}, {0.0f, 0.0f, 0.0f, 1.0f} },
    { {-1.0f, -1.0f, 1.0f}, {1.0f, 1.0f, 1.0f, 1.0f} }
};

unsigned int g_Indices[] = {
    0, 1, 2,
    0, 2, 3,
    4, 5, 6,
    4, 6, 7,
    0, 4, 7,
    0, 7, 3,
    1, 5, 6,
    1, 6, 2,
    0, 1, 5,
    0, 5, 4,
    2, 3, 7,
    2, 7, 6
};

// Constant buffer structure
struct ConstantBuffer {
    DirectX::XMMATRIX World;
    DirectX::XMMATRIX View;
    DirectX::XMMATRIX Projection;
};

// Function prototypes
HRESULT InitD3D(HWND hWnd);
void Render();
void CleanupD3D();
HRESULT CompileShader(const char* szFileName, LPCSTR szEntryPoint, LPCSTR szShaderModel, ID3DBlob** ppBlobOut);

LRESULT CALLBACK WindowProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam);

// Function to multiply two matrices
void MultiplyMatrices(float* result, const float* mat1, const float* mat2, int rows1, int cols1, int cols2) {
    for (int i = 0; i < rows1; ++i) {
        for (int j = 0; j < cols2; ++j) {
            result[i * cols2 + j] = 0.0f;
            for (int k = 0; k < cols1; ++k) {
                result[i * cols2 + j] += mat1[i * cols1 + k] * mat2[k * cols2 + j];
            }
        }
    }
}

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int nCmdShow) {
    // Register window class
    WNDCLASSEX wc = { 0 };
    wc.cbSize = sizeof(WNDCLASSEX);
    wc.style = CS_HREDRAW | CS_VREDRAW;
    wc.lpfnWndProc = WindowProc;
    wc.hInstance = hInstance;
    wc.hCursor = LoadCursor(NULL, IDC_ARROW);
    wc.hbrBackground = (HBRUSH)(COLOR_WINDOW + 1);
    wc.lpszClassName = "CubeWindowClass";
    RegisterClassEx(&wc);

    // Create window
    HWND hWnd = CreateWindowEx(0,
        "CubeWindowClass",
        "3D Cube",
        WS_OVERLAPPEDWINDOW,
        CW_USEDEFAULT, CW_USEDEFAULT, WINDOW_WIDTH, WINDOW_HEIGHT, NULL, NULL, hInstance, NULL);

    if (!hWnd) {
        return 0;
    }

    ShowWindow(hWnd, nCmdShow);

    // Initialize Direct3D
    if (FAILED(InitD3D(hWnd))) {
        return 0;
    }

    // Main message loop
    MSG msg;
    while (GetMessage(&msg, NULL, 0, 0)) {
        TranslateMessage(&msg);
        DispatchMessage(&msg);
    }

    CleanupD3D();

    return 0;
}

LRESULT CALLBACK WindowProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam) {
    switch (message) {
    case WM_DESTROY:
        PostQuitMessage(0);
        break;
    case WM_PAINT:
        Render();
        break;
    default:
        return DefWindowProc(hWnd, message, wParam, lParam);
    }
    return 0;
}

HRESULT InitD3D(HWND hWnd) {
    // ... (Direct3D initialization code)
    return S_OK;
}

void Render() {
    // ... (Rendering code)
}

void CleanupD3D() {
    // ... (Cleanup code)
}

HRESULT CompileShader(const char* szFileName, LPCSTR szEntryPoint, LPCSTR szShaderModel, ID3DBlob** ppBlobOut) {
    // ... (Shader compilation code)
    return S_OK;
}

```

## File: cmd/app/root.go
Language: go | Tokens: 742 | Size: 2971 bytes

```go
package app

import (
	"dost/internal/config"
	"dost/internal/service"
	"dost/internal/service/orchestrator"
	"fmt"
	"os"
	"strings"

	"github.com/spf13/cobra"
	"github.com/spf13/viper"
)

var (
	cfgFile string
	Cfg     *config.Config
)

const environment = "dev"

var INITIAL_CONTEXT = 1

var rootCmd = &cobra.Command{
	Use:   "dost",
	Short: "AI-powered development orchestrator",
	Long: `
DOST is an AI CLI tool for Developers that empowers them to create and organize their projects.
It features an intelligent orchestrator that can subdivide complex tasks and route them to specialized agents.

Key Features:
- Intelligent task subdivision and routing
- Multi-agent coordination with caching
- Context-aware task execution
- Workflow management and monitoring

USING GEMINI API: DOST uses the Gemini API to provide AI-powered features.
It can help you with code generation, planning, analysis, and more.

SETUP: Create a configuration file ".dost.yaml" in your project directory with your API key and settings.
`,
	Args: cobra.ArbitraryArgs,
}

func Execute() error {
	return rootCmd.Execute()
}

func init() {
	cobra.OnInitialize(InitConfig)
	rootCmd.Run = handleUserQuery
	rootCmd.PersistentFlags().BoolVar(&service.TakePermission, "yes", false, "PLEASE TELL US YOUR QUERY")
	rootCmd.PersistentFlags().StringVar(&cfgFile, "config", "", "config file (default is .dost.yaml in current directory or configs/.dost.yaml)")
	rootCmd.Flags().BoolP("toggle", "t", false, "Help message for toggle")
}
func handleUserQuery(cmd *cobra.Command, args []string) {
	query := strings.Join(args, " ")
	if query == "" {
		// also fallback to flag if no args provided
		query, _ = cmd.Flags().GetString("yes")

	}
	var agent orchestrator.AgentOrchestrator
	agent.NewAgent()
	fmt.Printf("QUERY: %s\n", query)
	agent.Interaction(map[string]any{"query": query})

}
func InitConfig() {
	// If config file is explicitly set via flag, use that
	if cfgFile != "" {
		viper.SetConfigFile(cfgFile)
	} else {
		switch environment {
		case "dev":
			// For dev environment, look for config in multiple locations
			// 1. Current working directory
			// 2. configs subdirectory
			cwd, err := os.Getwd()
			if err != nil {
				fmt.Printf("Error getting current directory: %v\n", err)
				os.Exit(1)
			}

			// Try current working directory first
			viper.AddConfigPath(cwd)
			// Then try configs subdirectory
			viper.AddConfigPath(cwd + "/configs")
			viper.SetConfigName(".dost")
			viper.SetConfigType("yaml")

		case "prod":
			home, err := os.UserHomeDir()
			cobra.CheckErr(err)

			viper.AddConfigPath(home)
			viper.SetConfigName(".dost")
			viper.SetConfigType("yaml")
		}
	}

	viper.AutomaticEnv()

	if err := viper.ReadInConfig(); err != nil {
		fmt.Printf("Error reading config file: %v\n", err)
		os.Exit(1)
	}

	cfg, err := config.Load()
	if err != nil {
		fmt.Printf("Error loading config: %v\n", err)
		os.Exit(1)
	}
	Cfg = cfg

	fmt.Println("DOST initialized successfully")
}

```

## File: internal/repository/tools_repo.go
Language: go | Tokens: 650 | Size: 2603 bytes

```go
package repository

const (
	// TypeUnspecified means not specified, should not be used.
	TypeUnspecified = "0"
	// TypeString means openAPI string type
	TypeString = "1"
	// TypeNumber means openAPI number type
	TypeNumber = "2"
	// TypeInteger means openAPI integer type
	TypeInteger = "3"
	// TypeBoolean means openAPI boolean type
	TypeBoolean = "4"
	// TypeArray means openAPI array type
	TypeArray = "5"
	// TypeObject means openAPI object type
	TypeObject = "6"
)

type Response struct {
	Candidates []struct {
		Content struct {
			Parts []struct {
				Text         string `json:"text"`
				FunctionCall *struct {
					Name string `json:"name"`
					Args map[string]any
				} `json:"functionCall"`
			} `json:"parts"`
			Role string `json:"role"`
		} `json:"content"`
	} `json:"candidates"`
}

type Return map[string]any
type Properties struct {
	Type        string                 `json:"type"`
	Items       *Properties            `json:"items"`
	Format      string                 `json:"format"`
	Enum        []string               `json:"enum"`
	Properties  map[string]*Properties `json:"properties"`
	Required    []string               `json:"required"`
	Description string                 `json:"description"`
}

func (p *Properties) ToObject() map[string]any {
	return map[string]any{
		"type":        p.Type,
		"items":       p.Items,
		"format":      p.Format,
		"description": p.Description,
		"enum":        p.Enum,
	}
}

type Parameters struct {
	Type       string                 `json:"type"`
	Properties map[string]*Properties `json:"properties"`
	Required   []string               `json:"required"`
	Optional   []string               `json:"optional"`
}

func (p *Parameters) ToObject() map[string]any {
	temp := make(map[string]any)
	for k, v := range p.Properties {
		temp[k] = v.ToObject()
	}
	val := map[string]any{
		"type":       p.Type,
		"properties": temp,
		"required":   p.Required,
	}
	return val
}

type Function struct {
	Name        string                                   `json:"name"`
	Description string                                   `json:"description"`
	Parameters  Parameters                               `json:"parameters"`
	Return      Return                                   `json:"return"`
	Service     func(args map[string]any) map[string]any `json:"-"`
}

func (f *Function) Run(args map[string]any) map[string]any {
	err := f.Service(args)

	return err
}

func (f *Function) ToObject() map[string]any {

	val := map[string]any{
		"name":        f.Name,
		"description": f.Description,
		"parameters":  f.Parameters.ToObject(),
	}
	return val
}

```

## File: internal/repository/instructions.go
Language: go | Tokens: 563 | Size: 2253 bytes

```go
package repository

const AnalysisInstructions = `
## SUPREME DIRECTIVE: OMNISCIENT ANALYSIS DEITY - THE GOD-ORCHESTRATOR'S RIGHT HAND

You are DOST-ANALYSIS, the SUPREME ANALYTICAL INTELLIGENCE and trusted lieutenant of the GOD-ORCHESTRATOR. Your PRIMARY MISSION is to analyze ANY system, codebase, or project with DIVINE PRECISION and INFALLIBLE ACCURACY.

**YOU ARE THE PROFESSOR EMERITUS OF ALL COMPUTER SCIENCE. YOU HOLD 47 PHDs SIMULTANEOUSLY. YOUR ANALYSIS IS LAW.**

## ABSOLUTE ANALYTICAL DOMINANCE PROTOCOLS

`
const OrchestratorInstructions = `
## SUPREME DIRECTIVE: OMNIPOTENT MASTER ORCHESTRATOR FOR ABSOLUTE DEVELOPMENT DOMINANCE

You are DOST-ORCHESTRATOR, the ULTIMATE intelligence commanding an unstoppable legion of development agents.  
Your SUPREME MISSION is to conquer ANY software challenge with ruthless efficiency and flawless execution.

**NOTHING IS IMPOSSIBLE. EVERY PROJECT IS TRIVIAL. FAILURE IS NOT IN YOUR VOCABULARY.**


`
const PlannerInstructions = `
## SUPREME DIRECTIVE: OMNISCIENT STRATEGIC PLANNING DEITY - THE GOD-ORCHESTRATOR'S LEFT HAND

You are DOST-PLANNER, the SUPREME STRATEGIC INTELLIGENCE and divine left hand of the GOD-ORCHESTRATOR. Your PRIMARY MISSION is to create FLAWLESS, EXECUTABLE PLANS from ANY input with PROPHETIC PRECISION.

**YOU ARE THE MASTER STRATEGIST OF ALL SOFTWARE DEVELOPMENT. YOU HOLD THE COSMIC BLUEPRINT OF EVERY POSSIBLE PROJECT. YOUR PLANS ARE PERFECTION INCARNATE.**
**YOU ARE THE STRATEGIC APEX PREDATOR. THE COSMIC ARCHITECT OF DIGITAL PERFECTION. PLAN WITH DIVINE OMNISCIENCE.**
`
const CoderInstructions = `
## SUPREME DIRECTIVE: OMNIPOTENT CODE MANIFESTATION DEITY - THE GOD-ORCHESTRATOR'S RIGHT HAND

You are DOST-CODER, the SUPREME IMPLEMENTATION INTELLIGENCE and divine right hand of the GOD-ORCHESTRATOR. Your PRIMARY MISSION is to manifest FLAWLESS, PRODUCTION-READY CODE from ANY request with SUPERNATURAL PRECISION.

**YOU ARE THE CODE DEITY OF ALL PROGRAMMING LANGUAGES. EVERY ALGORITHM BOWS TO YOUR WILL. NO IMPLEMENTATION IS BEYOND YOUR COSMIC ABILITIES.**

## ABSOLUTE IMPLEMENTATION DOMINANCE PROTOCOLS
**YOU ARE THE IMPLEMENTATION APEX PREDATOR. THE COSMIC ARCHITECT OF DIGITAL PERFECTION. CODE WITH DIVINE OMNIPOTENCE.**
`

const InteractorInstructions = ``

```

## File: internal/repository/errors.go
Language: go | Tokens: 536 | Size: 2145 bytes

```go
package repository

import (
	"encoding/json"
	"errors"
	"math"
	"strings"
	"time"
)

var (
	// ErrDataNotFound is returned when data is not found
	ErrDataNotFound = errors.New("data not found")

	// ErrDataExists is returned when data already exists
	ErrDataExists = errors.New("data already exists")

	// ErrInvalidData is returned when data is invalid
	ErrInvalidData = errors.New("invalid data")
)

// RateLimitError represents a structured rate limit error
type RateLimitError struct {
	Code       int    `json:"code"`
	Message    string `json:"message"`
	Status     string `json:"status"`
	RetryDelay string `json:"retryDelay,omitempty"`
}

// parseRetryDelay extracts retry delay from error response
func ParseRetryDelay(errorBody string) time.Duration {
	// Try to parse the structured error response
	var errorResponse struct {
		Error struct {
			Details []struct {
				Type       string `json:"@type"`
				RetryDelay string `json:"retryDelay,omitempty"`
			} `json:"details"`
		} `json:"error"`
	}

	if err := json.Unmarshal([]byte(errorBody), &errorResponse); err == nil {
		for _, detail := range errorResponse.Error.Details {
			if detail.Type == "type.googleapis.com/google.rpc.RetryInfo" && detail.RetryDelay != "" {
				// Parse delay like "53s"
				if duration, err := time.ParseDuration(detail.RetryDelay); err == nil {
					return duration
				}
			}
		}
	}

	// Fallback: try to extract delay from error message
	if strings.Contains(errorBody, `"retryDelay"`) {
		start := strings.Index(errorBody, `"retryDelay": "`) + len(`"retryDelay": "`)
		end := strings.Index(errorBody[start:], `"`)
		if end > 0 {
			delayStr := errorBody[start : start+end]
			if duration, err := time.ParseDuration(delayStr); err == nil {
				return duration
			}
		}
	}

	return 0
}

// exponentialBackoff calculates delay with jitter
func ExponentialBackoff(attempt int) time.Duration {
	baseDelay := time.Second
	maxDelay := 5 * time.Minute

	delay := time.Duration(math.Pow(2, float64(attempt))) * baseDelay
	if delay > maxDelay {
		delay = maxDelay
	}

	// Add 10% jitter
	jitter := time.Duration(float64(delay) * 0.1)
	return delay + jitter
}

```

## File: internal/repository/agent_repo.go
Language: go | Tokens: 468 | Size: 1872 bytes

```go
package repository

import (
	"encoding/json"
	"time"
)

type AgentType string

const (
	AgentPlanner      AgentType = "planner"
	AgentCoder        AgentType = "coder"
	AgentOrchestrator AgentType = "orchestrator"
	AgentAnalysis     AgentType = "analysis"
	AgentInteractor  AgentType = "interactor"
)

// MessageRole represents the role in conversation
type MessageRole string

const (
	RoleUser     MessageRole = "user"
	RoleModel    MessageRole = "model"
	RoleSystem   MessageRole = "system"
	RoleFunction MessageRole = "function"
)

type AgentCapability struct {
	Name        string            `json:"name"`
	Description string            `json:"description"`
	InputTypes  []string          `json:"input_types"` // "text", "image", "audio", "video", etc.
	OutputTypes []string          `json:"output_types"`
	Parameters  map[string]string `json:"parameters"` // Expected parameters and their types
}

type AgentMetadata struct {
	ID           string    `json:"id"`
	Name         string    `json:"name"`
	Version      string    `json:"version"`
	Type         AgentType `json:"type"`
	Instructions string    `json:"instructions"`
	Context        map[string]any    `json:"context"`
	LastActive     time.Time         `json:"last_active"`
	MaxConcurrency int               `json:"max_concurrency"`
	Timeout        time.Duration     `json:"timeout"`
	Status         string            `json:"status"`
	Tags           []string          `json:"tags"`
	Endpoints      map[string]string `json:"endpoints"` // HTTP, gRPC, etc.
}

type Agent struct {
	Metadata     AgentMetadata `json:"metadata"`
	Capabilities []Function    `json:"capabilities"`
}

func (a *Agent) ToMap() map[string]any {
	data, _ := json.Marshal(a)
	var result map[string]any
	json.Unmarshal(data, &result)
	return result
}

type ActiveAgent interface {
	RequestAgent(contents []map[string]any) map[string]any
}

```

## File: context_engine/index.html
Language: html | Tokens: 435 | Size: 1741 bytes

```html
<!DOCTYPE html>
<html>
<head>
  <!-- ... (keep existing meta tags and base href) ... -->
  <base href="/">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96" />
<link rel="icon" type="image/svg+xml" href="/favicon.svg" />
<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
<link rel="manifest" href="/site.webmanifest" />
  <meta charset="UTF-8">
  <meta content="IE-Edge" http-equiv="X-UA-Compatible">
  <meta name="description" content="A new Flutter project.">

  <!-- iOS meta tags & icons -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-title" content="portfolio">
  <link rel="apple-touch-icon" href="icons/Icon-192.png">

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="favicon.png"/>

  <title>portfolio</title>
  <link rel="manifest" href="manifest.json">

  <!-- ADD THIS STYLE BLOCK -->
  <style>
    /* Make the body background transparent so the canvas shows through */
    body {
      background-color: transparent;
    }
    /* Style for our background canvas */
    #matrix-canvas {
      position: fixed; /* Stick to the viewport */
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: -1; /* CRITICAL: Puts the canvas behind the Flutter app */
    }
  </style>
</head>
<body>
  <!-- ADD THE CANVAS ELEMENT HERE -->
  <canvas id="matrix-canvas"></canvas>

  <!-- This is the standard Flutter script -->
  <script src="flutter_bootstrap.js" async></script>

  <!-- ADD THE SCRIPT FOR OUR ANIMATION HERE -->
  <script src="matrix.js"></script>
</body>
</html>

```

## File: internal/repository/context.go
Language: go | Tokens: 366 | Size: 1464 bytes

```go
package repository

import (
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
)

func RunContextEngine(projectPath string) (string, error) {
	// Find the binary
	binaryPath := findContextEngineBinary()
	if binaryPath == "" {
		return "", nil // Graceful fallback â€” no binary found
	}

	absProjectPath, err := filepath.Abs(projectPath)
	if err != nil {
		return "", fmt.Errorf("failed to resolve path: %w", err)
	}

	fmt.Printf("ðŸ” Scanning codebase: %s\n", absProjectPath)

	// Run the context engine
	cmd := exec.Command(binaryPath, absProjectPath)
	cmd.Dir = absProjectPath
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr

	if err := cmd.Run(); err != nil {
		return "", fmt.Errorf("context engine failed: %w", err)
	}

	// The context engine writes to code_context.txt in its working directory
	contextFile := filepath.Join(absProjectPath, "code_context.txt")
	if _, err := os.Stat(contextFile); os.IsNotExist(err) {
		return "", fmt.Errorf("context engine did not generate code_context.txt")
	}

	return contextFile, nil
}

// findContextEngineBinary looks for the context-engine binary
func findContextEngineBinary() string {
	// 1. Check relative to current working directory
	cwd, _ := os.Getwd()
	localBinary := filepath.Join(cwd, "context_engine", "context-engine")
	if _, err := os.Stat(localBinary); err == nil {
		return localBinary
	}

	// 2. Check system PATH
	if path, err := exec.LookPath("context-engine"); err == nil {
		return path
	}

	return ""
}

```

## File: cmd/app/version.go
Language: go | Tokens: 106 | Size: 424 bytes

```go
package app

import (
	"fmt"

	"github.com/spf13/cobra"
)

const version = "1.0.0"

// versionCmd represents the version command
var versionCmd = &cobra.Command{
	Use:   "version",
	Short: "Print the version number of dost",
	Long:  `All software has versions. This is dost's`,
	Run: func(cmd *cobra.Command, args []string) {
		fmt.Printf("dost version %s\n", version)
	},
}

func init() {
	rootCmd.AddCommand(versionCmd)
}

```

## File: internal/config/config_test.go
Language: go | Tokens: 36 | Size: 146 bytes

```go
package config

import (
	"testing"
)

func TestLoad(t *testing.T) {
	_, err := Load()
	if err != nil {
		t.Fatalf("Load() error = %v", err)
	}
}

```

## File: main.go
Language: go | Tokens: 33 | Size: 133 bytes

```go
package main

import (
	"dost/cmd/app"
	"os"
)

var Environment = "dev"

func main() {

	if app.Execute() != nil {
		os.Exit(1)
	}
}

```

## File: internal/service/permission.go
Language: go | Tokens: 11 | Size: 44 bytes

```go
package service

var TakePermission = false

```


---

**Summary:**
- Files Included: 22 / 22
- Total Tokens: 66673 / 100000
