{
  "039c07c6384f1d366ab69e7f42d1785f": {
    "path": "internal/service/interactor/interactor.go",
    "content": "package interactor\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"dost/internal/repository\"\n\t\"dost/internal/service/analysis\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/google/uuid\"\n\tgitignore \"github.com/sabhiram/go-gitignore\"\n\t\"github.com/spf13/viper\"\n)\n\nvar ignoreMatcher *gitignore.GitIgnore\nvar InteractorToolsFunc map[string]repository.Function = make(map[string]repository.Function)\nvar ChatHistory = make([]map[string]any, 0)\nvar defaultIgnore = map[string]bool{\n\t\".git\":         true,\n\t\"node_modules\": true,\n\t\"vendor\":       true,\n\t\".venv\":        true,\n\t\".env\":         true,\n\t\".idea\":        true,\n\t\".vscode\":      true,\n\t\"__pycache__\":  true,\n\t\".dost\":        true,\n}\n\ntype InitialContext struct {\n\tOS              string\n\tArch            string\n\tUser            string\n\tShell           string\n\tCWD             string\n\tGoVersion       string\n\tFolderStructure map[string]any\n\tInstalledTools  []string\n\tEnvVars         map[string]string\n\tProjectFiles    []string\n\tProjectType     string\n\tGitBranch       string\n\tInternetAccess  bool\n\tAgentRole       string\n\tCapabilities    []string\n\tTimezone        string\n\tSessionID       string\n}\ntype changeInfo struct {\n\tstartLine int\n\tstartCol  int\n\tendLine   int\n\tendCol    int\n\toperation string\n\tcontent   string\n\tvalid     bool\n}\n\nfunc GetInitialContext() InitialContext {\n\tctx := InitialContext{\n\t\tOS:              runtime.GOOS,\n\t\tArch:            runtime.GOARCH,\n\t\tUser:            os.Getenv(\"USERNAME\"),\n\t\tShell:           detectDefaultShell(),\n\t\tCWD:             mustGetWorkingDir(),\n\t\tFolderStructure: GetProjectStructure(map[string]any{\"path\": \"./\"}),\n\t\tGoVersion:       runtime.Version(),\n\t\tInstalledTools:  detectTools(),\n\t\tEnvVars:         getImportantEnvVars(),\n\t\tProjectFiles:    scanProjectFiles(),\n\t\tProjectType:     detectProjectType(),\n\t\tGitBranch:       getGitBranch(),\n\t\tInternetAccess:  checkInternet(),\n\t\tTimezone:        getLocalTimezone(),\n\t\tSessionID:       generateSessionID(),\n\t}\n\treturn ctx\n}\n\nfunc detectDefaultShell() string {\n\tif runtime.GOOS == \"windows\" {\n\t\t// prefer PowerShell if present\n\t\tif _, err := exec.LookPath(\"powershell\"); err == nil {\n\t\t\treturn \"powershell\"\n\t\t}\n\t\treturn \"cmd\"\n\t}\n\treturn os.Getenv(\"SHELL\")\n}\n\nfunc mustGetWorkingDir() string {\n\tdir, err := os.Getwd()\n\tif err != nil {\n\t\treturn \".\"\n\t}\n\treturn dir\n}\n\nfunc detectTools() []string {\n\tvar found []string\n\tval := os.Getenv(\"PATH\")\n\tfound = strings.Split(val, \";\")\n\treturn found\n}\n\nfunc getImportantEnvVars() map[string]string {\n\tkeys := []string{\"PATH\", \"GOROOT\", \"GOPATH\", \"JAVA_HOME\"}\n\tenv := make(map[string]string)\n\tfor _, k := range keys {\n\t\tif v := os.Getenv(k); v != \"\" {\n\t\t\tenv[k] = v\n\t\t}\n\t}\n\treturn env\n}\n\nfunc scanProjectFiles() []string {\n\tfiles := []string{}\n\tfilepath.Walk(\".\", func(path string, info os.FileInfo, err error) error {\n\t\tif err == nil \u0026\u0026 !info.IsDir() {\n\t\t\tif strings.HasSuffix(path, \".go\") ||\n\t\t\t\tpath == \"go.mod\" || path == \"package.json\" || path == \"requirements.txt\" ||\n\t\t\t\tpath == \"Dockerfile\" || path == \"README.md\" {\n\t\t\t\tfiles = append(files, path)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn files\n}\n\nfunc detectProjectType() string {\n\tif _, err := os.Stat(\"go.mod\"); err == nil {\n\t\treturn \"Go project\"\n\t}\n\tif _, err := os.Stat(\"package.json\"); err == nil {\n\t\treturn \"Node.js project\"\n\t}\n\tif _, err := os.Stat(\"requirements.txt\"); err == nil {\n\t\treturn \"Python project\"\n\t}\n\treturn \"Unknown\"\n}\n\nfunc getGitBranch() string {\n\tcmd := exec.Command(\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\")\n\tout, err := cmd.Output()\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\treturn strings.TrimSpace(string(out))\n}\n\nfunc checkInternet() bool {\n\tcmd := exec.Command(\"ping\", \"-c\", \"1\", \"8.8.8.8\")\n\tif runtime.GOOS == \"windows\" {\n\t\tcmd = exec.Command(\"ping\", \"-n\", \"1\", \"8.8.8.8\")\n\t}\n\tif err := cmd.Run(); err != nil {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc getLocalTimezone() string {\n\t_, tz := time.Now().Zone()\n\treturn fmt.Sprintf(\"%d min offset\", tz/60)\n}\n\nfunc generateSessionID() string {\n\treturn fmt.Sprintf(\"%d\", time.Now().UnixNano())\n}\n\nfunc formatFilesForInteractor(filesRead map[string]any) string {\n\tif len(filesRead) == 0 {\n\t\treturn \"\"\n\t}\n\n\tvar result strings.Builder\n\tresult.WriteString(\"=== FILES CONTENT ===\\n\\n\")\n\n\tfor fileName, fileData := range filesRead {\n\t\tresult.WriteString(fmt.Sprintf(\"FILE: %s\\n\", fileName))\n\t\tresult.WriteString(\"=\" + strings.Repeat(\"=\", len(fileName)+6) + \"\\n\")\n\n\t\tif chunks, ok := fileData.([]map[string]any); ok {\n\t\t\tfor _, chunk := range chunks {\n\t\t\t\tif content, exists := chunk[\"content\"].(string); exists {\n\t\t\t\t\tresult.WriteString(content)\n\t\t\t\t\tresult.WriteString(\"\\n\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tresult.WriteString(\"\\n\" + strings.Repeat(\"-\", 50) + \"\\n\\n\")\n\t}\n\n\treturn result.String()\n}\n\ntype AgentInteractor repository.Agent\n\nconst interactorName = \"Interactor\"\nconst interactorVersion = \"0.1.0\"\n\n// NewAgent creates and initializes a new AgentInteractor instance.\nfunc (c *AgentInteractor) NewAgent() {\n\tmodel := viper.GetString(\"INTERACTOR.MODEL\")\n\tif model == \"\" {\n\t\tmodel = \"gemini-1.5-pro\"\n\t}\n\tendPoints := fmt.Sprintf(\"https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse\", model)\n\tid := fmt.Sprintf(\"interactor-%s\", uuid.NewString())\n\n\tagentMetadata := repository.AgentMetadata{\n\t\tID:             id,\n\t\tName:           interactorName,\n\t\tVersion:        interactorVersion,\n\t\tType:           repository.AgentInteractor,\n\t\tInstructions:   repository.InteractorInstructions,\n\t\tMaxConcurrency: 5,\n\t\tTimeout:        10 * time.Minute,\n\t\tTags:           []string{\"interactor\", \"interaction\", \"user\", \"conversation\"},\n\t\tEndpoints:      map[string]string{\"http\": endPoints},\n\t\tContext:        make(map[string]any),\n\t\tStatus:         \"active\",\n\t\tLastActive:     time.Now(),\n\t}\n\n\tc.Metadata = agentMetadata\n\tc.Capabilities = InteractorCapabilities\n\n}\n\nfunc (p *AgentInteractor) Interaction(args map[string]any) map[string]any {\n\tInitialContext := GetInitialContext()\n\tInitialContextBytes, err := json.Marshal(InitialContext)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": \"Unable to get initial context\"}\n\t}\n\n\tvar userMessage strings.Builder\n\n\tfilesContent := formatFilesForInteractor(analysis.FilesRead)\n\tif filesContent != \"\" {\n\t\tuserMessage.WriteString(filesContent)\n\t\tuserMessage.WriteString(\"\\n\")\n\t}\n\n\t// Add initial context\n\tuserMessage.WriteString(\"=== INITIAL CONTEXT ===\\n\")\n\tuserMessage.WriteString(string(InitialContextBytes))\n\tuserMessage.WriteString(\"\\n\\n\")\n\n\t// Add query\n\tuserMessage.WriteString(\"=== QUERY ===\\n\")\n\tif query, ok := args[\"query\"].(string); ok {\n\t\tuserMessage.WriteString(query)\n\t}\n\tlog.Println(\"TEST: CODER:  \", userMessage.String()[0:20])\n\t// Push consolidated user message into ChatHistory\n\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\"role\": \"user\",\n\t\t\"parts\": []map[string]any{\n\t\t\t{\"text\": userMessage.String()},\n\t\t},\n\t})\n\n\tfor {\n\t\t// Ensure exit-process is always enforced\n\t\tif len(ChatHistory) \u003e 0 \u0026\u0026 ChatHistory[len(ChatHistory)-1][\"role\"] == \"model\" {\n\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\"role\": \"user\",\n\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t{\n\t\t\t\t\t\t\"text\": \"If you feel there is no task left and nothing to do, call exit-process. Because only that can stop you and finish the program. Don't respond with text, no text output should be there, call the exit-process. PERIOD\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\n\t\toutput := p.RequestAgent(ChatHistory)\n\n\t\tif output[\"error\"] != nil {\n\t\t\tfmt.Println(\"Error:\", output[\"error\"])\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\toutputData, ok := output[\"output\"].([]map[string]any)\n\t\tif !ok {\n\t\t\tfmt.Println(\"ERROR CONVERTING OUTPUT\")\n\t\t\treturn nil\n\t\t}\n\n\t\tif len(outputData) == 0 {\n\t\t\tfmt.Println(\"No output received\")\n\t\t\tcontinue\n\t\t}\n\n\t\t// Process each output part\n\t\tfor _, part := range outputData {\n\t\t\tpartType, hasType := part[\"type\"].(string)\n\t\t\tif !hasType {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tswitch partType {\n\t\t\tcase \"text\":\n\t\t\t\tif text, ok := part[\"data\"].(string); ok {\n\t\t\t\t\tfmt.Println(\"Agent:\", text)\n\t\t\t\t}\n\n\t\t\tcase \"functionCall\":\n\t\t\t\tname, nameOK := part[\"name\"].(string)\n\t\t\t\targsData, argsOK := part[\"args\"].(map[string]any)\n\n\t\t\t\tif !nameOK || !argsOK {\n\t\t\t\t\tfmt.Println(\"Error: invalid function call data\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tfmt.Println(\"Calling function:\", name)\n\n\t\t\t\t// Execute the function\n\t\t\t\tif function, exists := InteractorToolsFunc[name]; exists {\n\t\t\t\t\tresult := function.Run(argsData)\n\n\t\t\t\t\t// Check for exit condition\n\t\t\t\t\tif _, ok := result[\"exit\"].(bool); ok {\n\t\t\t\t\t\treturn map[string]any{\"coder-id\": result[\"output\"]}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Add function response back to chat history\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"functionResponse\": map[string]any{\n\t\t\t\t\t\t\t\t\t\"name\":     name,\n\t\t\t\t\t\t\t\t\t\"response\": result,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\n\t\t\t\t\tif outputStr, ok := result[\"output\"].(string); ok {\n\t\t\t\t\t\tfmt.Println(\"Result:\", outputStr)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfmt.Printf(\"Function %s not found\\n\", name)\n\n\t\t\t\t\t// Add error response into chat\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\"text\": fmt.Sprintf(\"Error: Function '%s' not found\", name)},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfmt.Println(\"---\")\n\t}\n}\n\nfunc (c *AgentInteractor) RequestAgent(contents []map[string]any) map[string]any {\n\tfmt.Printf(\"Processing request with Coder Agent: %s\\n\", c.Metadata.Name)\n\n\t// Build request payload\n\trequest := map[string]any{\n\t\t\"systemInstruction\": map[string]any{\n\t\t\t\"parts\": []map[string]any{\n\t\t\t\t{\"text\": c.Metadata.Instructions},\n\t\t\t},\n\t\t},\n\t\t\"toolConfig\": map[string]any{\n\t\t\t\"functionCallingConfig\": map[string]any{\n\t\t\t\t\"mode\": \"ANY\",\n\t\t\t},\n\t\t},\n\t\t\"contents\": contents,\n\t\t\"tools\": []map[string]any{\n\t\t\t{\"functionDeclarations\": GetInteractorCapabilitiesArrayMap()},\n\t\t},\n\t}\n\n\t// Marshal request body\n\tjsonBody, err := json.Marshal(request)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t}\n\n\t// Retry config\n\tconst maxRetries = 5\n\tconst maxWaitTime = 10 * time.Minute\n\n\tfor attempt := 0; attempt \u003c= maxRetries; attempt++ {\n\t\t// Create HTTP request\n\t\treq, err := http.NewRequestWithContext(\n\t\t\tcontext.Background(),\n\t\t\t\"POST\",\n\t\t\tc.Metadata.Endpoints[\"http\"],\n\t\t\tbytes.NewBuffer(jsonBody),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t}\n\n\t\treq.Header.Set(\"Content-Type\", \"application/json\")\n\t\treq.Header.Set(\"X-goog-api-key\", viper.GetString(\"CODER.API_KEY\"))\n\n\t\t// Execute request with timeout\n\t\tclient := repository.NewStreamingHTTPClient()\n\t\tresp, err := client.Do(req)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\t\tdefer resp.Body.Close()\n\n\t\t// Success case - parse streaming response\n\t\tif resp.StatusCode == http.StatusOK {\n\t\t\t// Parse SSE stream with real-time display\n\t\t\tstreamResp, err := repository.ParseSSEStream(resp.Body, true)\n\t\t\tif err != nil {\n\t\t\t\tif attempt == maxRetries {\n\t\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t\t}\n\t\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Convert to standard output format\n\t\t\toutput := repository.ConvertStreamResponseToOutput(streamResp)\n\n\t\t\t// Save chat history\n\t\t\thistoryEntry := repository.BuildChatHistoryFromStream(streamResp, \"interactor\")\n\t\t\tif historyEntry != nil {\n\t\t\t\tChatHistory = append(ChatHistory, historyEntry)\n\t\t\t}\n\n\t\t\tc.Metadata.LastActive = time.Now()\n\t\t\treturn map[string]any{\"error\": nil, \"output\": output}\n\t\t}\n\n\t\t// Read body for error cases\n\t\tbodyBytes, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Handle rate limits\n\t\tif resp.StatusCode == http.StatusTooManyRequests {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Rate limit exceeded after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\t\t\tretryDelay := repository.ParseRetryDelay(string(bodyBytes))\n\t\t\twaitTime := retryDelay\n\t\t\tif waitTime \u003c= 0 {\n\t\t\t\twaitTime = repository.ExponentialBackoff(attempt)\n\t\t\t}\n\t\t\tif waitTime \u003e maxWaitTime {\n\t\t\t\twaitTime = maxWaitTime\n\t\t\t}\n\t\t\tfmt.Printf(\"Rate limit hit (attempt %d/%d). Waiting %v before retry...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, waitTime)\n\t\t\ttime.Sleep(waitTime)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Retry on server errors\n\t\tif resp.StatusCode \u003e= 500 \u0026\u0026 resp.StatusCode \u003c 600 {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Server error after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Printf(\"Server error (attempt %d/%d). Waiting %v before retry...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, repository.ExponentialBackoff(attempt))\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Client errors (400‚Äì499) except 429 ‚Üí don't retry\n\t\treturn map[string]any{\n\t\t\t\"error\":  fmt.Sprintf(\"HTTP %d: %s\", resp.StatusCode, string(bodyBytes)),\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"error\":  fmt.Sprintf(\"Max retries (%d) exceeded\", maxRetries),\n\t\t\"output\": nil,\n\t}\n}\n\n// GetProjectStructure returns the project structure as a string, ignoring files and directories specified in .gitignore.\n// If a .gitignore file is not found, it uses a default ignore list.\n// It takes the project path as input.\nfunc GetProjectStructure(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\tfmt.Println(text)\n\t}\n\n\tloadGitIgnore()\n\tpath := args[\"path\"].(string)\n\tvar builder strings.Builder\n\tbuilder.WriteString(path + \"\\n\")\n\terr := getProjectStructureRecursive(path, \"\", \u0026builder)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err, \"output\": nil}\n\t}\n\n\tif builder.String() == \".\" || builder.String() == \"\" {\n\t\treturn map[string]any{\"error\": nil, \"output\": \"\u003cempty directory\u003e\"}\n\t}\n\treturn map[string]any{\"error\": nil, \"output\": builder.String()}\n}\n\nfunc getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {\n\tentries, err := os.ReadDir(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor i, entry := range entries {\n\t\tentryPath := filepath.Join(path, entry.Name())\n\n\t\t// skip ignored entries\n\t\tif ignoreMatcher != nil {\n\t\t\trelPath, _ := filepath.Rel(\".\", entryPath)\n\t\t\tif ignoreMatcher.MatchesPath(relPath) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tif defaultIgnore[entry.Name()] {\n\t\t\t// ‚úÖ Skip this directory and its contents completely\n\t\t\tif entry.IsDir() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// draw branch\n\t\tconnector := \"‚îú‚îÄ‚îÄ\"\n\t\tif i == len(entries)-1 {\n\t\t\tconnector = \"‚îî‚îÄ‚îÄ\"\n\t\t}\n\t\tbuilder.WriteString(prefix + connector + \" \" + entry.Name() + \"\\n\")\n\n\t\t// recursively descend\n\t\tif entry.IsDir() {\n\t\t\tsubPrefix := prefix\n\t\t\tif i == len(entries)-1 {\n\t\t\t\tsubPrefix += \"    \"\n\t\t\t} else {\n\t\t\t\tsubPrefix += \"‚îÇ   \"\n\t\t\t}\n\t\t\t// üö´ Don't go inside ignored directories\n\t\t\tif !defaultIgnore[entry.Name()] {\n\t\t\t\terr := getProjectStructureRecursive(entryPath, subPrefix, builder)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc loadGitIgnore() {\n\tif _, err := os.Stat(\".gitignore\"); err == nil {\n\t\tignoreMatcher, _ = gitignore.CompileIgnoreFile(\".gitignore\")\n\t}\n}\n\nvar InteractorCapabilities = []repository.Function{}\n\nfunc GetInteractorCapabilities() []repository.Function {\n\treturn InteractorCapabilities\n}\n\n// GetInteractorCapabilitiesArrayMap returns the capabilities as a list of maps for API use.\nfunc GetInteractorCapabilitiesArrayMap() []map[string]any {\n\tcoderMap := make([]map[string]any, 0)\n\tfor _, v := range InteractorCapabilities {\n\t\tcoderMap = append(coderMap, v.ToObject())\n\t}\n\treturn coderMap\n}\n\n// GetInteractorCapabilitiesMap returns the capabilities as a map for internal use.\nfunc GetInteractorCapabilitiesMap() map[string]repository.Function {\n\tcoderMap := make(map[string]repository.Function)\n\tfor _, v := range InteractorCapabilities {\n\t\tcoderMap[v.Name] = v\n\t}\n\treturn coderMap\n}\nfunc init() {\n\tfor _, v := range InteractorCapabilities {\n\t\tInteractorToolsFunc[v.Name] = v\n\t}\n}\n",
    "hash": "039c07c6384f1d366ab69e7f42d1785f",
    "size": 16273,
    "tokens": 4068,
    "modified_time": "2026-02-10T12:24:09.441992345+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "GetInitialContext",
      "detectDefaultShell",
      "mustGetWorkingDir",
      "detectTools",
      "getImportantEnvVars",
      "scanProjectFiles",
      "detectProjectType",
      "getGitBranch",
      "checkInternet",
      "getLocalTimezone",
      "generateSessionID",
      "formatFilesForInteractor",
      "GetProjectStructure",
      "getProjectStructureRecursive",
      "loadGitIgnore",
      "GetInteractorCapabilities",
      "GetInteractorCapabilitiesArrayMap",
      "GetInteractorCapabilitiesMap",
      "init"
    ]
  },
  "044af3fb9b2c173c7c8ca935683e71b3": {
    "path": "context_engine/main.go",
    "content": "package main\n\nimport (\n\t\"crypto/md5\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/fs\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"time\"\n)\n\n// Config holds engine configuration\ntype Config struct {\n\tMaxFileSize       int64    `json:\"max_file_size\"`\n\tMaxTotalTokens    int      `json:\"max_total_tokens\"`\n\tExcludePatterns   []string `json:\"exclude_patterns\"`\n\tIncludeExtensions []string `json:\"include_extensions\"`\n\tEnableSecurity    bool     `json:\"enable_security\"`\n\tUseGosec          bool     `json:\"use_gosec\"`\n\tUseBandit         bool     `json:\"use_bandit\"`     // Python\n\tUseESLint         bool     `json:\"use_eslint\"`     // JavaScript/TypeScript\n\tUseFlawfinder     bool     `json:\"use_flawfinder\"` // C/C++\n\tUsePhpStan        bool     `json:\"use_phpstan\"`    // PHP\n\tUseRubocop        bool     `json:\"use_rubocop\"`    // Ruby\n\tCacheEnabled      bool     `json:\"cache_enabled\"`\n\tCacheDir          string   `json:\"cache_dir\"`\n}\n\n// FileContext represents a processed file\ntype FileContext struct {\n\tPath         string          `json:\"path\"`\n\tContent      string          `json:\"content\"`\n\tHash         string          `json:\"hash\"`\n\tSize         int64           `json:\"size\"`\n\tTokens       int             `json:\"tokens\"`\n\tModifiedTime time.Time       `json:\"modified_time\"`\n\tLanguage     string          `json:\"language\"`\n\tImports      []string        `json:\"imports\"`\n\tFunctions    []string        `json:\"functions\"`\n\tSecurity     []SecurityIssue `json:\"security,omitempty\"`\n}\n\n// SecurityIssue represents a potential security threat\ntype SecurityIssue struct {\n\tSeverity    string `json:\"severity\"`\n\tType        string `json:\"type\"`\n\tDescription string `json:\"description\"`\n\tLine        int    `json:\"line\"`\n\tColumn      int    `json:\"column\"`\n\tCode        string `json:\"code\"`\n\tTool        string `json:\"tool\"`\n\tCWE         string `json:\"cwe,omitempty\"`\n\tConfidence  string `json:\"confidence,omitempty\"`\n}\n\n// Tool output structures\n\n// GosecIssue represents gosec JSON output\ntype GosecIssue struct {\n\tSeverity   string `json:\"severity\"`\n\tConfidence string `json:\"confidence\"`\n\tRuleID     string `json:\"rule_id\"`\n\tDetails    string `json:\"details\"`\n\tFile       string `json:\"file\"`\n\tCode       string `json:\"code\"`\n\tLine       string `json:\"line\"`\n\tColumn     string `json:\"column\"`\n\tCWE        struct {\n\t\tID string `json:\"id\"`\n\t} `json:\"cwe\"`\n}\n\ntype GosecOutput struct {\n\tIssues []GosecIssue `json:\"Issues\"`\n}\n\n// BanditResult represents bandit JSON output\ntype BanditResult struct {\n\tResults []struct {\n\t\tTestID          string `json:\"test_id\"`\n\t\tIssueConfidence string `json:\"issue_confidence\"`\n\t\tIssueSeverity   string `json:\"issue_severity\"`\n\t\tIssueText       string `json:\"issue_text\"`\n\t\tLineNumber      int    `json:\"line_number\"`\n\t\tCode            string `json:\"code\"`\n\t\tFilename        string `json:\"filename\"`\n\t\tCWE             struct {\n\t\t\tID int `json:\"id\"`\n\t\t} `json:\"cwe\"`\n\t} `json:\"results\"`\n}\n\n// ESLintResult represents eslint JSON output\ntype ESLintResult []struct {\n\tFilePath string `json:\"filePath\"`\n\tMessages []struct {\n\t\tRuleID   string `json:\"ruleId\"`\n\t\tSeverity int    `json:\"severity\"`\n\t\tMessage  string `json:\"message\"`\n\t\tLine     int    `json:\"line\"`\n\t\tColumn   int    `json:\"column\"`\n\t} `json:\"messages\"`\n}\n\n// FlawfinderResult represents flawfinder output\ntype FlawfinderHit struct {\n\tFile        string\n\tLine        int\n\tColumn      int\n\tLevel       int\n\tCategory    string\n\tName        string\n\tDescription string\n\tCode        string\n}\n\n// SecurityPattern defines regex-based security patterns\ntype SecurityPattern struct {\n\tPattern     *regexp.Regexp\n\tType        string\n\tSeverity    string\n\tDescription string\n\tLanguages   []string\n}\n\n// ContextEngine manages code context generation\ntype ContextEngine struct {\n\tConfig      Config\n\tFiles       []FileContext\n\tCache       map[string]FileContext\n\tSecurityDB  []SecurityPattern\n\tProjectPath string\n}\n\n// NewContextEngine initializes the engine\nfunc NewContextEngine(cfg Config) *ContextEngine {\n\tengine := \u0026ContextEngine{\n\t\tConfig:     cfg,\n\t\tFiles:      make([]FileContext, 0),\n\t\tCache:      make(map[string]FileContext),\n\t\tSecurityDB: initSecurityPatterns(),\n\t}\n\n\tif cfg.CacheEnabled {\n\t\tengine.loadCache()\n\t}\n\n\treturn engine\n}\n\n// initSecurityPatterns defines comprehensive multi-language patterns\nfunc initSecurityPatterns() []SecurityPattern {\n\tpatterns := []SecurityPattern{\n\t\t// Credentials - All languages\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(?i)(password|passwd|pwd|secret|api_key|apikey|token|private_key)\\s*=\\s*[\"'][^\"']{8,}[\"']`),\n\t\t\tType:        \"Hardcoded Credentials\",\n\t\t\tSeverity:    \"CRITICAL\",\n\t\t\tDescription: \"Hardcoded credentials detected\",\n\t\t\tLanguages:   []string{\"*\"},\n\t\t},\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(?i)(aws_access_key|aws_secret|AKIA[0-9A-Z]{16})`),\n\t\t\tType:        \"AWS Credentials\",\n\t\t\tSeverity:    \"CRITICAL\",\n\t\t\tDescription: \"AWS credentials exposed\",\n\t\t\tLanguages:   []string{\"*\"},\n\t\t},\n\t\t// SQL Injection - Multiple languages\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(execute|query|exec)\\s*\\([^)]*\\+|fmt\\.Sprintf.*SELECT|SELECT.*%s|\"SELECT.*\"\\s*\\+`),\n\t\t\tType:        \"SQL Injection\",\n\t\t\tSeverity:    \"CRITICAL\",\n\t\t\tDescription: \"Potential SQL injection vulnerability\",\n\t\t\tLanguages:   []string{\"go\", \"python\", \"javascript\", \"typescript\", \"php\", \"java\"},\n\t\t},\n\t\t// Command Injection\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(exec\\.Command|os\\.system|subprocess\\.call|eval|shell_exec|system)\\s*\\([^)]*\\+`),\n\t\t\tType:        \"Command Injection\",\n\t\t\tSeverity:    \"HIGH\",\n\t\t\tDescription: \"Dynamic command construction - potential command injection\",\n\t\t\tLanguages:   []string{\"go\", \"python\", \"javascript\", \"php\", \"ruby\"},\n\t\t},\n\t\t// XSS vulnerabilities\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`innerHTML\\s*=|document\\.write\\(|\\.html\\([^)]*\\+`),\n\t\t\tType:        \"XSS Vulnerability\",\n\t\t\tSeverity:    \"HIGH\",\n\t\t\tDescription: \"Potential XSS - dynamic HTML content\",\n\t\t\tLanguages:   []string{\"javascript\", \"typescript\"},\n\t\t},\n\t\t// Path Traversal\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(os\\.Open|ioutil\\.ReadFile|open\\(|file_get_contents|readFile)\\s*\\([^)]*\\+`),\n\t\t\tType:        \"Path Traversal\",\n\t\t\tSeverity:    \"HIGH\",\n\t\t\tDescription: \"Dynamic file path - potential path traversal\",\n\t\t\tLanguages:   []string{\"go\", \"python\", \"javascript\", \"php\", \"ruby\"},\n\t\t},\n\t\t// Weak Crypto\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(MD5|SHA1|DES|RC4|md5|sha1)\\s*\\(`),\n\t\t\tType:        \"Weak Cryptography\",\n\t\t\tSeverity:    \"MEDIUM\",\n\t\t\tDescription: \"Use of weak cryptographic algorithm\",\n\t\t\tLanguages:   []string{\"*\"},\n\t\t},\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`Math\\.random|rand\\(\\)|mt_rand\\(\\)`),\n\t\t\tType:        \"Weak Random\",\n\t\t\tSeverity:    \"MEDIUM\",\n\t\t\tDescription: \"Weak random number generator for security\",\n\t\t\tLanguages:   []string{\"javascript\", \"php\", \"c\", \"cpp\"},\n\t\t},\n\t\t// Deserialization\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(pickle\\.loads|yaml\\.load|unserialize|eval\\(|json\\.loads.*JSONDecoder)`),\n\t\t\tType:        \"Unsafe Deserialization\",\n\t\t\tSeverity:    \"HIGH\",\n\t\t\tDescription: \"Unsafe deserialization of untrusted data\",\n\t\t\tLanguages:   []string{\"python\", \"php\", \"javascript\", \"ruby\"},\n\t\t},\n\t\t// SSRF\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(http\\.Get|requests\\.get|fetch|curl_exec|Net::HTTP)\\s*\\([^)]*\\+`),\n\t\t\tType:        \"SSRF\",\n\t\t\tSeverity:    \"HIGH\",\n\t\t\tDescription: \"Server-Side Request Forgery risk\",\n\t\t\tLanguages:   []string{\"go\", \"python\", \"javascript\", \"php\", \"ruby\"},\n\t\t},\n\t\t// Code Injection\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`\\beval\\s*\\(|exec\\s*\\(|Function\\s*\\(`),\n\t\t\tType:        \"Code Injection\",\n\t\t\tSeverity:    \"CRITICAL\",\n\t\t\tDescription: \"Dynamic code execution\",\n\t\t\tLanguages:   []string{\"javascript\", \"python\", \"php\"},\n\t\t},\n\t\t// Buffer Overflow - C/C++\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`\\b(gets|strcpy|strcat|sprintf|vsprintf)\\s*\\(`),\n\t\t\tType:        \"Buffer Overflow\",\n\t\t\tSeverity:    \"CRITICAL\",\n\t\t\tDescription: \"Unsafe buffer function\",\n\t\t\tLanguages:   []string{\"c\", \"cpp\"},\n\t\t},\n\t\t// XXE - XML External Entity\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`XMLParser|parseXML|DocumentBuilder.*parse|simplexml_load`),\n\t\t\tType:        \"XXE Risk\",\n\t\t\tSeverity:    \"HIGH\",\n\t\t\tDescription: \"XML parser may be vulnerable to XXE\",\n\t\t\tLanguages:   []string{\"java\", \"php\", \"python\", \"javascript\"},\n\t\t},\n\t\t// Debug/Development code\n\t\t{\n\t\t\tPattern:     regexp.MustCompile(`(?i)(console\\.log|print\\(|var_dump|debug|TODO.*security|FIXME.*security)`),\n\t\t\tType:        \"Debug Code\",\n\t\t\tSeverity:    \"LOW\",\n\t\t\tDescription: \"Debug code or security TODO in production\",\n\t\t\tLanguages:   []string{\"*\"},\n\t\t},\n\t}\n\n\treturn patterns\n}\n\n// CheckToolsAvailable verifies required tools are installed\nfunc (e *ContextEngine) CheckToolsAvailable() {\n\ttools := map[string]*bool{\n\t\t\"gosec\":      \u0026e.Config.UseGosec,\n\t\t\"bandit\":     \u0026e.Config.UseBandit,\n\t\t\"eslint\":     \u0026e.Config.UseESLint,\n\t\t\"flawfinder\": \u0026e.Config.UseFlawfinder,\n\t\t\"phpstan\":    \u0026e.Config.UsePhpStan,\n\t\t\"rubocop\":    \u0026e.Config.UseRubocop,\n\t}\n\n\tfmt.Println(\"Checking available security tools:\")\n\tfor tool, enabled := range tools {\n\t\tif *enabled {\n\t\t\tif _, err := exec.LookPath(tool); err != nil {\n\t\t\t\tfmt.Printf(\"‚ö†Ô∏è  %s not found (disabled)\\n\", tool)\n\t\t\t\t*enabled = false\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"‚úì %s found\\n\", tool)\n\t\t\t}\n\t\t}\n\t}\n\tfmt.Println()\n}\n\n// RunGosec executes gosec on Go files\nfunc (e *ContextEngine) RunGosec() ([]SecurityIssue, error) {\n\tif !e.Config.UseGosec {\n\t\treturn nil, nil\n\t}\n\n\tfmt.Println(\"Running gosec analysis...\")\n\tcmd := exec.Command(\"gosec\", \"-fmt=json\", \"-quiet\", \"./...\")\n\tcmd.Dir = e.ProjectPath\n\n\toutput, _ := cmd.CombinedOutput()\n\tif len(output) == 0 {\n\t\treturn nil, nil\n\t}\n\n\tvar result GosecOutput\n\tif err := json.Unmarshal(output, \u0026result); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse gosec output: %v\", err)\n\t}\n\n\tissues := make([]SecurityIssue, 0)\n\tfor _, issue := range result.Issues {\n\t\tvar line int\n\t\tfmt.Sscanf(issue.Line, \"%d\", \u0026line)\n\n\t\tfilepath.Rel(e.ProjectPath, issue.File)\n\n\t\tissues = append(issues, SecurityIssue{\n\t\t\tSeverity:    strings.ToUpper(issue.Severity),\n\t\t\tType:        issue.RuleID,\n\t\t\tDescription: issue.Details,\n\t\t\tLine:        line,\n\t\t\tCode:        issue.Code,\n\t\t\tTool:        \"gosec\",\n\t\t\tCWE:         issue.CWE.ID,\n\t\t\tConfidence:  issue.Confidence,\n\t\t})\n\t}\n\n\tfmt.Printf(\"  Found %d issues with gosec\\n\", len(issues))\n\treturn issues, nil\n}\n\n// RunBandit executes bandit on Python files\nfunc (e *ContextEngine) RunBandit() ([]SecurityIssue, error) {\n\tif !e.Config.UseBandit {\n\t\treturn nil, nil\n\t}\n\n\tfmt.Println(\"Running bandit analysis...\")\n\tcmd := exec.Command(\"bandit\", \"-r\", \".\", \"-f\", \"json\", \"-q\")\n\tcmd.Dir = e.ProjectPath\n\n\toutput, _ := cmd.CombinedOutput()\n\tif len(output) == 0 {\n\t\treturn nil, nil\n\t}\n\n\tvar result BanditResult\n\tif err := json.Unmarshal(output, \u0026result); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse bandit output: %v\", err)\n\t}\n\n\tissues := make([]SecurityIssue, 0)\n\tfor _, finding := range result.Results {\n\t\tfilepath.Rel(e.ProjectPath, finding.Filename)\n\n\t\tseverity := strings.ToUpper(finding.IssueSeverity)\n\t\tif severity == \"UNDEFINED\" {\n\t\t\tseverity = \"MEDIUM\"\n\t\t}\n\n\t\tcwe := \"\"\n\t\tif finding.CWE.ID \u003e 0 {\n\t\t\tcwe = fmt.Sprintf(\"CWE-%d\", finding.CWE.ID)\n\t\t}\n\n\t\tissues = append(issues, SecurityIssue{\n\t\t\tSeverity:    severity,\n\t\t\tType:        finding.TestID,\n\t\t\tDescription: finding.IssueText,\n\t\t\tLine:        finding.LineNumber,\n\t\t\tCode:        finding.Code,\n\t\t\tTool:        \"bandit\",\n\t\t\tCWE:         cwe,\n\t\t\tConfidence:  finding.IssueConfidence,\n\t\t})\n\t}\n\n\tfmt.Printf(\"  Found %d issues with bandit\\n\", len(issues))\n\treturn issues, nil\n}\n\n// RunESLint executes eslint with security plugin\nfunc (e *ContextEngine) RunESLint() ([]SecurityIssue, error) {\n\tif !e.Config.UseESLint {\n\t\treturn nil, nil\n\t}\n\n\tfmt.Println(\"Running eslint analysis...\")\n\tcmd := exec.Command(\"eslint\", \".\", \"--ext\", \".js,.jsx,.ts,.tsx\", \"-f\", \"json\")\n\tcmd.Dir = e.ProjectPath\n\n\toutput, _ := cmd.CombinedOutput()\n\tif len(output) == 0 {\n\t\treturn nil, nil\n\t}\n\n\tvar result ESLintResult\n\tif err := json.Unmarshal(output, \u0026result); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse eslint output: %v\", err)\n\t}\n\n\tissues := make([]SecurityIssue, 0)\n\tfor _, file := range result {\n\t\tfilepath.Rel(e.ProjectPath, file.FilePath)\n\n\t\tfor _, msg := range file.Messages {\n\t\t\tif msg.RuleID == \"\" || msg.Severity \u003c 1 {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Only include security-related rules\n\t\t\tif !strings.Contains(msg.RuleID, \"security\") \u0026\u0026\n\t\t\t\t!strings.Contains(msg.RuleID, \"no-eval\") \u0026\u0026\n\t\t\t\t!strings.Contains(msg.RuleID, \"no-implied-eval\") {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tseverity := \"MEDIUM\"\n\t\t\tif msg.Severity == 2 {\n\t\t\t\tseverity = \"HIGH\"\n\t\t\t}\n\n\t\t\tissues = append(issues, SecurityIssue{\n\t\t\t\tSeverity:    severity,\n\t\t\t\tType:        msg.RuleID,\n\t\t\t\tDescription: msg.Message,\n\t\t\t\tLine:        msg.Line,\n\t\t\t\tColumn:      msg.Column,\n\t\t\t\tTool:        \"eslint\",\n\t\t\t})\n\t\t}\n\t}\n\n\tfmt.Printf(\"  Found %d issues with eslint\\n\", len(issues))\n\treturn issues, nil\n}\n\n// RunFlawfinder executes flawfinder on C/C++ files\nfunc (e *ContextEngine) RunFlawfinder() ([]SecurityIssue, error) {\n\tif !e.Config.UseFlawfinder {\n\t\treturn nil, nil\n\t}\n\n\tfmt.Println(\"Running flawfinder analysis...\")\n\tcmd := exec.Command(\"flawfinder\", \"--quiet\", \"--dataonly\", \".\")\n\tcmd.Dir = e.ProjectPath\n\n\toutput, _ := cmd.CombinedOutput()\n\tif len(output) == 0 {\n\t\treturn nil, nil\n\t}\n\n\tissues := make([]SecurityIssue, 0)\n\tlines := strings.Split(string(output), \"\\n\")\n\n\tfor _, line := range lines {\n\t\tif line == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Parse flawfinder output: file:line:column: [level] category: description\n\t\tre := regexp.MustCompile(`([^:]+):(\\d+):(\\d+):\\s*\\[(\\d+)\\]\\s*\\(([^)]+)\\)\\s*(.+)`)\n\t\tmatches := re.FindStringSubmatch(line)\n\n\t\tif len(matches) == 7 {\n\t\t\tvar lineNum, level int\n\t\t\tfmt.Sscanf(matches[2], \"%d\", \u0026lineNum)\n\t\t\tfmt.Sscanf(matches[4], \"%d\", \u0026level)\n\n\t\t\tseverity := \"LOW\"\n\t\t\tif level \u003e= 4 {\n\t\t\t\tseverity = \"HIGH\"\n\t\t\t} else if level \u003e= 2 {\n\t\t\t\tseverity = \"MEDIUM\"\n\t\t\t}\n\n\t\t\tfilepath.Rel(e.ProjectPath, matches[1])\n\n\t\t\tissues = append(issues, SecurityIssue{\n\t\t\t\tSeverity:    severity,\n\t\t\t\tType:        matches[5],\n\t\t\t\tDescription: matches[6],\n\t\t\t\tLine:        lineNum,\n\t\t\t\tTool:        \"flawfinder\",\n\t\t\t})\n\t\t}\n\t}\n\n\tfmt.Printf(\"  Found %d issues with flawfinder\\n\", len(issues))\n\treturn issues, nil\n}\n\n// ScanDirectory walks the directory and processes files\nfunc (e *ContextEngine) ScanDirectory(root string) error {\n\te.ProjectPath = root\n\n\t// Run security tools on entire project\n\tvar allSecurityIssues []SecurityIssue\n\n\tif e.Config.EnableSecurity {\n\t\ttools := []func() ([]SecurityIssue, error){\n\t\t\te.RunGosec,\n\t\t\te.RunBandit,\n\t\t\te.RunESLint,\n\t\t\te.RunFlawfinder,\n\t\t}\n\n\t\tfor _, tool := range tools {\n\t\t\tif issues, err := tool(); err != nil {\n\t\t\t\tfmt.Printf(\"Warning: %v\\n\", err)\n\t\t\t} else {\n\t\t\t\tallSecurityIssues = append(allSecurityIssues, issues...)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Create map for quick lookup of security issues by file\n\tsecurityByFile := make(map[string][]SecurityIssue)\n\tfor _, issue := range allSecurityIssues {\n\t\tsecurityByFile[issue.Type] = append(securityByFile[issue.Type], issue)\n\t}\n\n\t// Walk directory and process files\n\treturn filepath.WalkDir(root, func(path string, d fs.DirEntry, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif d.IsDir() {\n\t\t\tif e.shouldExclude(path) {\n\t\t\t\treturn filepath.SkipDir\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\n\t\tif !e.shouldInclude(path) {\n\t\t\treturn nil\n\t\t}\n\n\t\tinfo, err := d.Info()\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tif info.Size() \u003e e.Config.MaxFileSize {\n\t\t\treturn nil\n\t\t}\n\n\t\trelPath, _ := filepath.Rel(root, path)\n\t\treturn e.processFile(path, relPath, info, allSecurityIssues)\n\t})\n}\n\nfunc (e *ContextEngine) shouldExclude(path string) bool {\n\tfor _, pattern := range e.Config.ExcludePatterns {\n\t\tif strings.Contains(path, pattern) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (e *ContextEngine) shouldInclude(path string) bool {\n\text := filepath.Ext(path)\n\tfor _, validExt := range e.Config.IncludeExtensions {\n\t\tif ext == validExt {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (e *ContextEngine) processFile(path, relPath string, info fs.FileInfo, allIssues []SecurityIssue) error {\n\thash := e.getFileHash(path)\n\n\tif e.Config.CacheEnabled {\n\t\tif cached, exists := e.Cache[hash]; exists {\n\t\t\tif cached.ModifiedTime.Equal(info.ModTime()) {\n\t\t\t\te.Files = append(e.Files, cached)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\tcontent, err := os.ReadFile(path)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\tctx := FileContext{\n\t\tPath:         relPath,\n\t\tContent:      string(content),\n\t\tHash:         hash,\n\t\tSize:         info.Size(),\n\t\tTokens:       estimateTokens(string(content)),\n\t\tModifiedTime: info.ModTime(),\n\t\tLanguage:     detectLanguage(path),\n\t\tSecurity:     make([]SecurityIssue, 0),\n\t}\n\n\tctx.Imports = extractImports(ctx.Content, ctx.Language)\n\tctx.Functions = extractFunctions(ctx.Content, ctx.Language)\n\n\t// Match security issues to this file\n\tfor _, issue := range allIssues {\n\t\tif strings.Contains(issue.Code, relPath) || strings.HasSuffix(issue.Code, filepath.Base(path)) {\n\t\t\tctx.Security = append(ctx.Security, issue)\n\t\t}\n\t}\n\n\t// Add regex-based analysis\n\tif e.Config.EnableSecurity {\n\t\tregexIssues := e.analyzeSecurityThreatsRegex(ctx.Content, ctx.Language)\n\t\tctx.Security = append(ctx.Security, regexIssues...)\n\t}\n\n\te.Files = append(e.Files, ctx)\n\n\tif e.Config.CacheEnabled {\n\t\te.Cache[hash] = ctx\n\t}\n\n\treturn nil\n}\n\nfunc (e *ContextEngine) analyzeSecurityThreatsRegex(content, lang string) []SecurityIssue {\n\tissues := make([]SecurityIssue, 0)\n\tlines := strings.Split(content, \"\\n\")\n\n\tfor i, line := range lines {\n\t\tfor _, pattern := range e.SecurityDB {\n\t\t\t// Check if pattern applies to this language\n\t\t\tif !e.patternApplies(pattern, lang) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif pattern.Pattern.MatchString(line) {\n\t\t\t\tissues = append(issues, SecurityIssue{\n\t\t\t\t\tSeverity:    pattern.Severity,\n\t\t\t\t\tType:        pattern.Type,\n\t\t\t\t\tDescription: pattern.Description,\n\t\t\t\t\tLine:        i + 1,\n\t\t\t\t\tCode:        strings.TrimSpace(line),\n\t\t\t\t\tTool:        \"regex\",\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn issues\n}\n\nfunc (e *ContextEngine) patternApplies(pattern SecurityPattern, lang string) bool {\n\tfor _, l := range pattern.Languages {\n\t\tif l == \"*\" || l == lang {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (e *ContextEngine) GenerateContext() string {\n\tvar sb strings.Builder\n\ttotalTokens := 0\n\n\tsort.Slice(e.Files, func(i, j int) bool {\n\t\tif len(e.Files[i].Security) != len(e.Files[j].Security) {\n\t\t\treturn len(e.Files[i].Security) \u003e len(e.Files[j].Security)\n\t\t}\n\t\treturn e.Files[i].Tokens \u003e e.Files[j].Tokens\n\t})\n\n\tsb.WriteString(\"# Code Context Analysis\\n\\n\")\n\tsb.WriteString(fmt.Sprintf(\"Generated: %s\\n\", time.Now().Format(time.RFC3339)))\n\tsb.WriteString(fmt.Sprintf(\"Files Scanned: %d\\n\", len(e.Files)))\n\n\ttools := []string{\"regex\"}\n\tif e.Config.UseGosec {\n\t\ttools = append(tools, \"gosec\")\n\t}\n\tif e.Config.UseBandit {\n\t\ttools = append(tools, \"bandit\")\n\t}\n\tif e.Config.UseESLint {\n\t\ttools = append(tools, \"eslint\")\n\t}\n\tif e.Config.UseFlawfinder {\n\t\ttools = append(tools, \"flawfinder\")\n\t}\n\tsb.WriteString(fmt.Sprintf(\"Analysis Tools: %s\\n\\n\", strings.Join(tools, \", \")))\n\n\tif e.Config.EnableSecurity {\n\t\tsb.WriteString(\"## Security Summary\\n\\n\")\n\t\tcritical, high, medium, low := e.countSecurityIssues()\n\t\ttotal := critical + high + medium + low\n\n\t\tsb.WriteString(fmt.Sprintf(\"**Total Issues: %d**\\n\\n\", total))\n\t\tsb.WriteString(fmt.Sprintf(\"- üî¥ CRITICAL: %d\\n\", critical))\n\t\tsb.WriteString(fmt.Sprintf(\"- üü† HIGH: %d\\n\", high))\n\t\tsb.WriteString(fmt.Sprintf(\"- üü° MEDIUM: %d\\n\", medium))\n\t\tsb.WriteString(fmt.Sprintf(\"- üü¢ LOW: %d\\n\\n\", low))\n\n\t\ttoolCounts := e.countIssuesByTool()\n\t\tsb.WriteString(\"**Issues by Tool:**\\n\")\n\t\tfor tool, count := range toolCounts {\n\t\t\tif count \u003e 0 {\n\t\t\t\tsb.WriteString(fmt.Sprintf(\"- %s: %d\\n\", tool, count))\n\t\t\t}\n\t\t}\n\t\tsb.WriteString(\"\\n\")\n\t}\n\n\tsb.WriteString(\"---\\n\\n\")\n\n\tincludedCount := 0\n\tfor _, file := range e.Files {\n\t\tif totalTokens+file.Tokens \u003e e.Config.MaxTotalTokens {\n\t\t\tbreak\n\t\t}\n\n\t\tsb.WriteString(fmt.Sprintf(\"## File: %s\\n\", file.Path))\n\t\tsb.WriteString(fmt.Sprintf(\"Language: %s | Tokens: %d | Size: %d bytes\\n\\n\", file.Language, file.Tokens, file.Size))\n\n\t\tif len(file.Imports) \u003e 0 {\n\t\t\tsb.WriteString(\"**Imports:** \" + strings.Join(file.Imports, \", \") + \"\\n\\n\")\n\t\t}\n\n\t\tif len(file.Security) \u003e 0 {\n\t\t\tsb.WriteString(\"**‚ö†Ô∏è Security Issues:**\\n\\n\")\n\t\t\tfor _, issue := range file.Security {\n\t\t\t\temoji := getSeverityEmoji(issue.Severity)\n\t\t\t\tsb.WriteString(fmt.Sprintf(\"%s **[%s]** Line %d - %s\\n\", emoji, issue.Severity, issue.Line, issue.Type))\n\t\t\t\tsb.WriteString(fmt.Sprintf(\"   *%s*\\n\", issue.Description))\n\t\t\t\tsb.WriteString(fmt.Sprintf(\"   Tool: %s\", issue.Tool))\n\t\t\t\tif issue.Confidence != \"\" {\n\t\t\t\t\tsb.WriteString(fmt.Sprintf(\" | Confidence: %s\", issue.Confidence))\n\t\t\t\t}\n\t\t\t\tif issue.CWE != \"\" {\n\t\t\t\t\tsb.WriteString(fmt.Sprintf(\" | CWE: %s\", issue.CWE))\n\t\t\t\t}\n\t\t\t\tsb.WriteString(\"\\n\")\n\t\t\t\tif issue.Code != \"\" {\n\t\t\t\t\tsb.WriteString(fmt.Sprintf(\"   ```\\n   %s\\n   ```\\n\", issue.Code))\n\t\t\t\t}\n\t\t\t\tsb.WriteString(\"\\n\")\n\t\t\t}\n\t\t}\n\n\t\tsb.WriteString(\"```\" + file.Language + \"\\n\")\n\t\tsb.WriteString(file.Content)\n\t\tsb.WriteString(\"\\n```\\n\\n\")\n\n\t\ttotalTokens += file.Tokens\n\t\tincludedCount++\n\t}\n\n\tsb.WriteString(\"\\n---\\n\\n\")\n\tsb.WriteString(fmt.Sprintf(\"**Summary:**\\n\"))\n\tsb.WriteString(fmt.Sprintf(\"- Files Included: %d / %d\\n\", includedCount, len(e.Files)))\n\tsb.WriteString(fmt.Sprintf(\"- Total Tokens: %d / %d\\n\", totalTokens, e.Config.MaxTotalTokens))\n\n\treturn sb.String()\n}\n\nfunc getSeverityEmoji(severity string) string {\n\tswitch severity {\n\tcase \"CRITICAL\":\n\t\treturn \"üî¥\"\n\tcase \"HIGH\":\n\t\treturn \"üü†\"\n\tcase \"MEDIUM\":\n\t\treturn \"üü°\"\n\tcase \"LOW\":\n\t\treturn \"üü¢\"\n\tdefault:\n\t\treturn \"‚ö™\"\n\t}\n}\n\nfunc (e *ContextEngine) countSecurityIssues() (critical, high, medium, low int) {\n\tfor _, file := range e.Files {\n\t\tfor _, issue := range file.Security {\n\t\t\tswitch issue.Severity {\n\t\t\tcase \"CRITICAL\":\n\t\t\t\tcritical++\n\t\t\tcase \"HIGH\":\n\t\t\t\thigh++\n\t\t\tcase \"MEDIUM\":\n\t\t\t\tmedium++\n\t\t\tcase \"LOW\":\n\t\t\t\tlow++\n\t\t\t}\n\t\t}\n\t}\n\treturn\n}\n\nfunc (e *ContextEngine) countIssuesByTool() map[string]int {\n\tcounts := make(map[string]int)\n\tfor _, file := range e.Files {\n\t\tfor _, issue := range file.Security {\n\t\t\tcounts[issue.Tool]++\n\t\t}\n\t}\n\treturn counts\n}\n\nfunc (e *ContextEngine) getFileHash(path string) string {\n\tdata := []byte(path)\n\treturn fmt.Sprintf(\"%x\", md5.Sum(data))\n}\n\nfunc estimateTokens(content string) int {\n\treturn len(content) / 4\n}\n\nfunc detectLanguage(path string) string {\n\text := filepath.Ext(path)\n\tlangMap := map[string]string{\n\t\t\".go\": \"go\", \".js\": \"javascript\", \".ts\": \"typescript\",\n\t\t\".py\": \"python\", \".java\": \"java\", \".rs\": \"rust\",\n\t\t\".c\": \"c\", \".cpp\": \"cpp\", \".h\": \"c\", \".hpp\": \"cpp\",\n\t\t\".html\": \"html\", \".css\": \"css\", \".rb\": \"ruby\", \".php\": \"php\",\n\t\t\".dart\": \"dart\", \".mjs\": \"javascript\",\n\t}\n\tif lang, ok := langMap[ext]; ok {\n\t\treturn lang\n\t}\n\treturn \"text\"\n}\n\nfunc extractImports(content, lang string) []string {\n\timports := make([]string, 0)\n\tswitch lang {\n\tcase \"go\":\n\t\tre := regexp.MustCompile(`import\\s+(?:\"([^\"]+)\"|([a-zA-Z0-9_/]+))`)\n\t\tmatches := re.FindAllStringSubmatch(content, -1)\n\t\tfor _, m := range matches {\n\t\t\tif m[1] != \"\" {\n\t\t\t\timports = append(imports, m[1])\n\t\t\t}\n\t\t}\n\tcase \"python\":\n\t\tre := regexp.MustCompile(`(?:from\\s+(\\S+)|import\\s+(\\S+))`)\n\t\tmatches := re.FindAllStringSubmatch(content, -1)\n\t\tfor _, m := range matches {\n\t\t\tif m[1] != \"\" {\n\t\t\t\timports = append(imports, m[1])\n\t\t\t} else if m[2] != \"\" {\n\t\t\t\timports = append(imports, m[2])\n\t\t\t}\n\t\t}\n\tcase \"javascript\", \"typescript\":\n\t\tre := regexp.MustCompile(`import\\s+.*?from\\s+['\"]([^'\"]+)['\"]`)\n\t\tmatches := re.FindAllStringSubmatch(content, -1)\n\t\tfor _, m := range matches {\n\t\t\timports = append(imports, m[1])\n\t\t}\n\t}\n\treturn imports\n}\n\nfunc extractFunctions(content, lang string) []string {\n\tfunctions := make([]string, 0)\n\tswitch lang {\n\tcase \"go\":\n\t\tre := regexp.MustCompile(`func\\s+(\\w+)\\s*\\(`)\n\t\tmatches := re.FindAllStringSubmatch(content, -1)\n\t\tfor _, m := range matches {\n\t\t\tfunctions = append(functions, m[1])\n\t\t}\n\tcase \"python\":\n\t\tre := regexp.MustCompile(`def\\s+(\\w+)\\s*\\(`)\n\t\tmatches := re.FindAllStringSubmatch(content, -1)\n\t\tfor _, m := range matches {\n\t\t\tfunctions = append(functions, m[1])\n\t\t}\n\tcase \"javascript\", \"typescript\":\n\t\tre := regexp.MustCompile(`function\\s+(\\w+)\\s*\\(|const\\s+(\\w+)\\s*=\\s*\\([^)]*\\)\\s*=\u003e`)\n\t\tmatches := re.FindAllStringSubmatch(content, -1)\n\t\tfor _, m := range matches {\n\t\t\tif m[1] != \"\" {\n\t\t\t\tfunctions = append(functions, m[1])\n\t\t\t} else if m[2] != \"\" {\n\t\t\t\tfunctions = append(functions, m[2])\n\t\t\t}\n\t\t}\n\t}\n\treturn functions\n}\n\nfunc (e *ContextEngine) loadCache() {\n\tif e.Config.CacheDir == \"\" {\n\t\treturn\n\t}\n\tcachePath := filepath.Join(e.Config.CacheDir, \"context_cache.json\")\n\tdata, err := os.ReadFile(cachePath)\n\tif err != nil {\n\t\treturn\n\t}\n\tjson.Unmarshal(data, \u0026e.Cache)\n}\n\nfunc (e *ContextEngine) saveCache() error {\n\tif !e.Config.CacheEnabled || e.Config.CacheDir == \"\" {\n\t\treturn nil\n\t}\n\tos.MkdirAll(e.Config.CacheDir, 0755)\n\tcachePath := filepath.Join(e.Config.CacheDir, \"context_cache.json\")\n\tdata, err := json.MarshalIndent(e.Cache, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.WriteFile(cachePath, data, 0644)\n}\n\nfunc main() {\n\tconfig := Config{\n\t\tMaxFileSize:    100 * 1024,\n\t\tMaxTotalTokens: 100000,\n\t\tExcludePatterns: []string{\n\t\t\t\"node_modules\", \"vendor\", \".git\", \"dist\", \"build\",\n\t\t\t\"__pycache__\", \".pytest_cache\", \"target\", \".next\",\n\t\t\t\"venv\",\n\t\t},\n\t\tIncludeExtensions: []string{\n\t\t\t\".go\", \".js\", \".ts\", \".py\", \".java\", \".rs\",\n\t\t\t\".c\", \".cpp\", \".h\", \".css\", \".html\", \".rb\", \".php\", \".dart\", \".mjs\",\n\t\t},\n\t\tEnableSecurity: true,\n\t\tUseGosec:       true,\n\t\tUseBandit:      true,\n\t\tUseESLint:      true,\n\t\tUseFlawfinder:  true,\n\t\tUsePhpStan:     false,\n\t\tUseRubocop:     false,\n\t\tCacheEnabled:   true,\n\t\tCacheDir:       \".context_cache\",\n\t}\n\n\tengine := NewContextEngine(config)\n\tengine.CheckToolsAvailable()\n\n\tscanPath := \".\"\n\tif len(os.Args) \u003e 1 {\n\t\tscanPath = os.Args[1]\n\t}\n\n\tabsPath, _ := filepath.Abs(scanPath)\n\tfmt.Printf(\"\\nüîç Scanning directory: %s\\n\\n\", absPath)\n\n\tif err := engine.ScanDirectory(absPath); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Error scanning: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tfmt.Printf(\"\\n‚úì Processed %d files\\n\\n\", len(engine.Files))\n\n\tcontext := engine.GenerateContext()\n\n\toutputFile := \"code_context.txt\"\n\tif err := os.WriteFile(outputFile, []byte(context), 0644); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Error writing output: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tif err := engine.saveCache(); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Warning: could not save cache: %v\\n\", err)\n\t}\n\n\tfmt.Printf(\"üìÑ Context written to %s\\n\\n\", outputFile)\n\n\tif config.EnableSecurity {\n\t\tcritical, high, medium, low := engine.countSecurityIssues()\n\t\ttotal := critical + high + medium + low\n\t\tif total \u003e 0 {\n\t\t\tfmt.Printf(\"‚ö†Ô∏è  Security Issues Found: %d\\n\", total)\n\t\t\tfmt.Printf(\"   üî¥ CRITICAL: %d | üü† HIGH: %d | üü° MEDIUM: %d | üü¢ LOW: %d\\n\\n\", critical, high, medium, low)\n\n\t\t\ttoolCounts := engine.countIssuesByTool()\n\t\t\tfmt.Printf(\"üìä Detection Tool Breakdown:\\n\")\n\t\t\tfor tool, count := range toolCounts {\n\t\t\t\tif count \u003e 0 {\n\t\t\t\t\tfmt.Printf(\"   - %s: %d issues\\n\", tool, count)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tfmt.Println(\"‚úÖ No security issues detected!\")\n\t\t}\n\t}\n}\n",
    "hash": "044af3fb9b2c173c7c8ca935683e71b3",
    "size": 27142,
    "tokens": 6785,
    "modified_time": "2026-02-10T19:52:50.321798447+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "NewContextEngine",
      "initSecurityPatterns",
      "getSeverityEmoji",
      "estimateTokens",
      "detectLanguage",
      "extractImports",
      "extractFunctions",
      "main"
    ],
    "security": [
      {
        "severity": "CRITICAL",
        "type": "AWS Credentials",
        "description": "AWS credentials exposed",
        "line": 168,
        "column": 0,
        "code": "Pattern:     regexp.MustCompile(`(?i)(aws_access_key|aws_secret|AKIA[0-9A-Z]{16})`),",
        "tool": "regex"
      },
      {
        "severity": "CRITICAL",
        "type": "SQL Injection",
        "description": "Potential SQL injection vulnerability",
        "line": 176,
        "column": 0,
        "code": "Pattern:     regexp.MustCompile(`(execute|query|exec)\\s*\\([^)]*\\+|fmt\\.Sprintf.*SELECT|SELECT.*%s|\"SELECT.*\"\\s*\\+`),",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 261,
        "column": 0,
        "code": "// Debug/Development code",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 263,
        "column": 0,
        "code": "Pattern:     regexp.MustCompile(`(?i)(console\\.log|print\\(|var_dump|debug|TODO.*security|FIXME.*security)`),",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 264,
        "column": 0,
        "code": "Type:        \"Debug Code\",",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 266,
        "column": 0,
        "code": "Description: \"Debug code or security TODO in production\",",
        "tool": "regex"
      }
    ]
  },
  "19a1c706e86bd97eef026420aa0ebe34": {
    "path": "internal/service/permission.go",
    "content": "package service\n\nvar TakePermission = false\n",
    "hash": "19a1c706e86bd97eef026420aa0ebe34",
    "size": 44,
    "tokens": 11,
    "modified_time": "2025-12-28T22:01:44.42680601+05:30",
    "language": "go",
    "imports": [],
    "functions": []
  },
  "2e9d7f37f22f8df22d472602f458fff0": {
    "path": "internal/repository/context.go",
    "content": "package repository\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n)\n\nfunc RunContextEngine(projectPath string) (string, error) {\n\t// Find the binary\n\tbinaryPath := findContextEngineBinary()\n\tif binaryPath == \"\" {\n\t\treturn \"\", nil // Graceful fallback ‚Äî no binary found\n\t}\n\n\tabsProjectPath, err := filepath.Abs(projectPath)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to resolve path: %w\", err)\n\t}\n\n\tfmt.Printf(\"üîç Scanning codebase: %s\\n\", absProjectPath)\n\n\t// Run the context engine\n\tcmd := exec.Command(binaryPath, absProjectPath)\n\tcmd.Dir = absProjectPath\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\n\tif err := cmd.Run(); err != nil {\n\t\treturn \"\", fmt.Errorf(\"context engine failed: %w\", err)\n\t}\n\n\t// The context engine writes to code_context.txt in its working directory\n\tcontextFile := filepath.Join(absProjectPath, \"code_context.txt\")\n\tif _, err := os.Stat(contextFile); os.IsNotExist(err) {\n\t\treturn \"\", fmt.Errorf(\"context engine did not generate code_context.txt\")\n\t}\n\n\treturn contextFile, nil\n}\n\n// findContextEngineBinary looks for the context-engine binary\nfunc findContextEngineBinary() string {\n\t// 1. Check relative to current working directory\n\tcwd, _ := os.Getwd()\n\tlocalBinary := filepath.Join(cwd, \"context_engine\", \"context-engine\")\n\tif _, err := os.Stat(localBinary); err == nil {\n\t\treturn localBinary\n\t}\n\n\t// 2. Check system PATH\n\tif path, err := exec.LookPath(\"context-engine\"); err == nil {\n\t\treturn path\n\t}\n\n\treturn \"\"\n}\n",
    "hash": "2e9d7f37f22f8df22d472602f458fff0",
    "size": 1464,
    "tokens": 366,
    "modified_time": "2026-02-10T20:13:45.79737154+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "RunContextEngine",
      "findContextEngineBinary"
    ]
  },
  "3288286f3f8cb4d5b35964a2f06a37d8": {
    "path": "internal/service/orchestrator/orchestrator.go",
    "content": "package orchestrator\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"context\"\n\t\"dost/internal/repository\"\n\t\"dost/internal/service\"\n\t\"dost/internal/service/analysis\"\n\t\"dost/internal/service/interactor\"\n\n\t\"dost/internal/service/coder\"\n\t\"dost/internal/service/planner\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strings\"\n\t\"time\"\n\n\tgitignore \"github.com/sabhiram/go-gitignore\"\n\n\t\"github.com/spf13/viper\"\n)\n\ntype TaskStatus string\n\nvar OrchestratortoolsFunc map[string]repository.Function = make(map[string]repository.Function)\n\nvar TaskMap = make(map[string]Task)\n\nvar ChatHistory = make([]map[string]any, 0)\n\nconst (\n\tTaskPending   TaskStatus = \"pending\"\n\tTaskRunning   TaskStatus = \"running\"\n\tTaskCompleted TaskStatus = \"completed\"\n\tTaskFailed    TaskStatus = \"failed\"\n)\n\nvar ignoreMatcher *gitignore.GitIgnore\n\ntype Task struct {\n\tID           string            `json:\"id\"`\n\tDescription  string            `json:\"description\"`\n\tAgentID      string            `json:\"agent_id\"`\n\tInputs       map[string]any    `json:\"inputs\"`\n\tOutputs      map[string]any    `json:\"outputs\"`\n\tStatus       TaskStatus        `json:\"status\"`\n\tCreatedAt    time.Time         `json:\"created_at\"`\n\tUpdatedAt    time.Time         `json:\"updated_at\"`\n\tDependencies []string          `json:\"dependencies\"`\n\tMetadata     map[string]string `json:\"metadata\"`\n}\n\ntype AgentOrchestrator repository.Agent\n\ntype InitialContext struct {\n\tOS              string\n\tArch            string\n\tUser            string\n\tShell           string\n\tCWD             string\n\tGoVersion       string\n\tFolderStructure map[string]any\n\tInstalledTools  []string\n\tEnvVars         map[string]string\n\tProjectFiles    []string\n\tProjectType     string\n\tGitBranch       string\n\tInternetAccess  bool\n\tAgentRole       string\n\tCapabilities    []string\n\tTimezone        string\n\tSessionID       string\n}\n\nvar defaultIgnore = map[string]bool{\n\t\".git\":         true,\n\t\"node_modules\": true,\n\t\"vendor\":       true,\n\t\".venv\":        true,\n\t\".env\":         true,\n\t\".idea\":        true,\n\t\".vscode\":      true,\n\t\"__pycache__\":  true,\n\t\".dost\":        true,\n}\n\nfunc GetInitialContext() InitialContext {\n\tctx := InitialContext{\n\t\tOS:              runtime.GOOS,\n\t\tArch:            runtime.GOARCH,\n\t\tUser:            os.Getenv(\"USERNAME\"),\n\t\tShell:           detectDefaultShell(),\n\t\tCWD:             mustGetWorkingDir(),\n\t\tFolderStructure: GetProjectStructure(map[string]any{\"path\": \"./\"}),\n\t\tGoVersion:       runtime.Version(),\n\t\tInstalledTools:  detectTools(),\n\t\tEnvVars:         getImportantEnvVars(),\n\t\tProjectFiles:    scanProjectFiles(),\n\t\tProjectType:     detectProjectType(),\n\t\tGitBranch:       getGitBranch(),\n\t\tInternetAccess:  checkInternet(),\n\t\tTimezone:        getLocalTimezone(),\n\t\tSessionID:       generateSessionID(),\n\t}\n\treturn ctx\n}\n\nfunc detectDefaultShell() string {\n\tif runtime.GOOS == \"windows\" {\n\t\t// prefer PowerShell if present\n\t\tif _, err := exec.LookPath(\"powershell\"); err == nil {\n\t\t\treturn \"powershell\"\n\t\t}\n\t\treturn \"cmd\"\n\t}\n\treturn os.Getenv(\"SHELL\")\n}\n\nfunc mustGetWorkingDir() string {\n\tdir, err := os.Getwd()\n\tif err != nil {\n\t\treturn \".\"\n\t}\n\treturn dir\n}\n\nfunc detectTools() []string {\n\tvar found []string\n\tval := os.Getenv(\"PATH\")\n\tfound = strings.Split(val, \";\")\n\treturn found\n}\n\nfunc getImportantEnvVars() map[string]string {\n\tkeys := []string{\"PATH\", \"GOROOT\", \"GOPATH\", \"JAVA_HOME\"}\n\tenv := make(map[string]string)\n\tfor _, k := range keys {\n\t\tif v := os.Getenv(k); v != \"\" {\n\t\t\tenv[k] = v\n\t\t}\n\t}\n\treturn env\n}\n\nfunc scanProjectFiles() []string {\n\tfiles := []string{}\n\tfilepath.Walk(\".\", func(path string, info os.FileInfo, err error) error {\n\t\tif err == nil \u0026\u0026 !info.IsDir() {\n\t\t\tif strings.HasSuffix(path, \".go\") ||\n\t\t\t\tpath == \"go.mod\" || path == \"package.json\" || path == \"requirements.txt\" ||\n\t\t\t\tpath == \"Dockerfile\" || path == \"README.md\" {\n\t\t\t\tfiles = append(files, path)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn files\n}\n\nfunc detectProjectType() string {\n\tif _, err := os.Stat(\"go.mod\"); err == nil {\n\t\treturn \"Go project\"\n\t}\n\tif _, err := os.Stat(\"package.json\"); err == nil {\n\t\treturn \"Node.js project\"\n\t}\n\tif _, err := os.Stat(\"requirements.txt\"); err == nil {\n\t\treturn \"Python project\"\n\t}\n\treturn \"Unknown\"\n}\n\nfunc getGitBranch() string {\n\tcmd := exec.Command(\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\")\n\tout, err := cmd.Output()\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\treturn strings.TrimSpace(string(out))\n}\n\nfunc checkInternet() bool {\n\tcmd := exec.Command(\"ping\", \"-c\", \"1\", \"8.8.8.8\")\n\tif runtime.GOOS == \"windows\" {\n\t\tcmd = exec.Command(\"ping\", \"-n\", \"1\", \"8.8.8.8\")\n\t}\n\tif err := cmd.Run(); err != nil {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc getLocalTimezone() string {\n\t_, tz := time.Now().Zone()\n\treturn fmt.Sprintf(\"%d min offset\", tz/60)\n}\n\nfunc generateSessionID() string {\n\treturn fmt.Sprintf(\"%d\", time.Now().UnixNano())\n}\n\n// Helper function to format files for Orchestrator\nfunc formatFilesForOrchestrator(filesRead map[string]any) string {\n\tif len(filesRead) == 0 {\n\t\treturn \"\"\n\t}\n\n\tvar result strings.Builder\n\tresult.WriteString(\"=== FILES CONTENT ===\\n\\n\")\n\n\tfor fileName, fileData := range filesRead {\n\t\tresult.WriteString(fmt.Sprintf(\"FILE: %s\\n\", fileName))\n\t\tresult.WriteString(\"=\" + strings.Repeat(\"=\", len(fileName)+6) + \"\\n\")\n\n\t\tif chunks, ok := fileData.([]map[string]any); ok {\n\t\t\tfor _, chunk := range chunks {\n\t\t\t\tif content, exists := chunk[\"content\"].(string); exists {\n\t\t\t\t\tresult.WriteString(content)\n\t\t\t\t\tresult.WriteString(\"\\n\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tresult.WriteString(\"\\n\" + strings.Repeat(\"-\", 50) + \"\\n\\n\")\n\t}\n\n\treturn result.String()\n}\n\nfunc (p *AgentOrchestrator) Interaction(args map[string]any) map[string]any {\n\tInitialContext := GetInitialContext()\n\tInitialContextBytes, err := json.Marshal(InitialContext)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": \"Unable to get initial context\"}\n\t}\n\n\t// --- Context Engine: generate codebase context ---\n\tvar codeContext string\n\tcwd, _ := os.Getwd()\n\tcontextFilePath, err := repository.RunContextEngine(cwd)\n\tif err != nil {\n\t\tfmt.Printf(\"‚ö†Ô∏è  Context engine error: %v\\n\", err)\n\t} else if contextFilePath != \"\" {\n\t\tcontextBytes, err := os.ReadFile(contextFilePath)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"‚ö†Ô∏è  Failed to read context file: %v\\n\", err)\n\t\t} else {\n\t\t\tcodeContext = string(contextBytes)\n\t\t\tfmt.Printf(\"üìé Loaded codebase context (%d bytes)\\n\", len(codeContext))\n\t\t}\n\t}\n\n\t// Build consolidated user message\n\tvar userMessage strings.Builder\n\n\t// Add files content (from analysis)\n\tfilesContent := formatFilesForOrchestrator(analysis.FilesRead)\n\tif filesContent != \"\" {\n\t\tuserMessage.WriteString(filesContent)\n\t\tuserMessage.WriteString(\"\\n\")\n\t}\n\n\t// Add initial context\n\tuserMessage.WriteString(\"=== INITIAL CONTEXT ===\\n\")\n\tuserMessage.WriteString(string(InitialContextBytes))\n\tuserMessage.WriteString(\"\\n\\n\")\n\n\t// Add query\n\tuserMessage.WriteString(\"=== QUERY ===\\n\")\n\tif query, ok := args[\"query\"].(string); ok {\n\t\tuserMessage.WriteString(query)\n\t}\n\tlog.Println(\"TEST: ORCHESTRATOR:  \", userMessage.String()[0:20])\n\n\t// Build parts for the first user message\n\tparts := []map[string]any{}\n\n\t// Include codebase context as inline text (compatible with all models)\n\tif codeContext != \"\" {\n\t\tparts = append(parts, map[string]any{\n\t\t\t\"text\": \"=== CODEBASE CONTEXT ===\\n\" + codeContext + \"\\n=== END CODEBASE CONTEXT ===\\n\",\n\t\t})\n\t}\n\n\t// Add the main text part\n\tparts = append(parts, map[string]any{\"text\": userMessage.String()})\n\n\t// Push consolidated user message into ChatHistory\n\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\"role\":  \"user\",\n\t\t\"parts\": parts,\n\t})\n\n\tfor {\n\t\t// Check if last model response requires exit instruction\n\t\tif len(ChatHistory) \u003e 0 \u0026\u0026 ChatHistory[len(ChatHistory)-1][\"role\"] == \"model\" {\n\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\"role\": \"user\",\n\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t{\n\t\t\t\t\t\t\"text\": \"If there are no more tasks to do, you can either respond with a final text message directly, or call exit-process with the final text. For simple conversational responses, prefer responding with text directly. For task completions, call exit-process.\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\n\t\toutput := p.RequestAgent(ChatHistory)\n\n\t\tif output[\"error\"] != nil {\n\t\t\tfmt.Println(\"Error:\", output[\"error\"])\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\toutputData, ok := output[\"output\"].([]map[string]any)\n\t\tif !ok {\n\t\t\tfmt.Println(\"ERROR CONVERTING OUTPUT\")\n\t\t\treturn nil\n\t\t}\n\n\t\tif len(outputData) == 0 {\n\t\t\tfmt.Println(\"No output received\")\n\t\t\tcontinue\n\t\t}\n\n\t\t// Process each output part\n\t\thasFunctionCall := false\n\t\thasTextOutput := false\n\t\tfor _, part := range outputData {\n\t\t\tpartType, hasType := part[\"type\"].(string)\n\t\t\tif !hasType {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tswitch partType {\n\t\t\tcase \"text\":\n\t\t\t\t// Text was already streamed in real-time by ParseSSEStream.\n\t\t\t\t// Nothing to do here ‚Äî it's already displayed.\n\t\t\t\thasTextOutput = true\n\n\t\t\tcase \"functionCall\":\n\t\t\t\thasFunctionCall = true\n\t\t\t\tname, nameOK := part[\"name\"].(string)\n\t\t\t\targsData, argsOK := part[\"args\"].(map[string]any)\n\t\t\t\tif !nameOK || !argsOK {\n\t\t\t\t\tfmt.Println(\"Error: invalid function call data\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tfmt.Println(\"Calling function:\", name)\n\t\t\t\tif function, exists := OrchestratortoolsFunc[name]; exists {\n\t\t\t\t\tresult := function.Run(argsData)\n\n\t\t\t\t\t// Check for exit condition\n\t\t\t\t\tif _, ok := result[\"exit\"].(bool); ok {\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t}\n\n\t\t\t\t\t// Add function response to chat history\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"functionResponse\": map[string]any{\n\t\t\t\t\t\t\t\t\t\"name\":     name,\n\t\t\t\t\t\t\t\t\t\"response\": result,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\n\t\t\t\t\tif outputStr, ok := result[\"output\"].(string); ok {\n\t\t\t\t\t\tfmt.Println(\"Result:\", outputStr)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfmt.Printf(\"Function %s not found\\n\", name)\n\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\"text\": fmt.Sprintf(\"Error: Function '%s' not found\", name)},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// If the model responded with only text (no function calls),\n\t\t// treat it as the final response and exit the loop.\n\t\tif hasTextOutput \u0026\u0026 !hasFunctionCall {\n\t\t\treturn nil\n\t\t}\n\n\t\tfmt.Println(\"---\")\n\t}\n}\n\nfunc (p *AgentOrchestrator) NewAgent() {\n\tmodel := viper.GetString(\"ORCHESTRATOR.MODEL\")\n\tif model == \"\" {\n\t\tmodel = \"gemini-1.5-pro\"\n\t}\n\tendPoints := fmt.Sprintf(\"https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse\", model)\n\n\tanalysisAgentMeta := repository.AgentMetadata{\n\t\tID:             \"Orchestrator-agent-v1\",\n\t\tName:           \"Orchestrator Agent\",\n\t\tVersion:        \"1.0.0\",\n\t\tType:           repository.AgentType(repository.AgentOrchestrator),\n\t\tInstructions:   repository.OrchestratorInstructions,\n\t\tLastActive:     time.Now(),\n\t\tMaxConcurrency: 5,\n\t\tTimeout:        30 * time.Second,\n\t\tStatus:         \"active\",\n\t\tTags:           []string{\"analysis\", \"constraints\", \"inputs\", \"outputs\", \"validation\"},\n\t\tEndpoints: map[string]string{\n\t\t\t\"http\": endPoints,\n\t\t},\n\t}\n\tp.Metadata = analysisAgentMeta\n\tp.Capabilities = OrchestratorCapabilities\n}\nfunc AskAnAgent(args map[string]any) map[string]any {\n\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Println(text)\n\t}\n\n\tagentID, ok := args[\"agent_id\"].(string)\n\tif !ok || agentID == \"\" {\n\t\treturn map[string]any{\n\t\t\t\"error\":  \"missing or invalid agent_id\",\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\ttask, ok := args[\"task\"].(string)\n\tif !ok {\n\t\treturn map[string]any{\n\t\t\t\"error\":  \"missing or invalid task\",\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\tvar result map[string]any\n\n\tswitch agentID {\n\t// case \"analysis\":\n\n\t// \tanaAgent := analysis.AgentAnalysis{}\n\t// \tanaAgent.NewAgent()\n\t// \tquery := map[string]any{\n\t// \t\t\"query\": fmt.Sprintf(\"Here is the Task run an analysis for this task: \\\" %s\\\", \", task),\n\t// \t}\n\t// \tfmt.Println(query[\"query\"])\n\t// \tanalysisOutPut := anaAgent.Interaction(query)[\"analysis-id\"]\n\t// \tanalysisOutPutStr, ok := analysisOutPut.(string)\n\t// \tif ok {\n\t// \t\tanalysisResult := analysis.AnalysisMap[analysisOutPutStr]\n\t// \t\tjsonBytes, err := json.MarshalIndent(analysisResult, \"\", \"  \")\n\t// \t\tif err != nil {\n\t// \t\t\tfmt.Println(\"X Error marshalling JSON:\", err)\n\t// \t\t\treturn nil\n\t// \t\t}\n\t// \t\tresult = map[string]any{\"analysis\": string(jsonBytes)}\n\t// \t} else {\n\t// \t\tresult = map[string]any{\"analysis\": analysisOutPut}\n\t// \t}\n\n\tcase \"planner\":\n\t\tplanAgent := planner.AgentPlanner{}\n\t\tplanAgent.NewAgent()\n\t\tplanAgent.Interaction(map[string]any{\n\t\t\t\"query\": fmt.Sprintf(\"Here is the Task do a detail planning for this task: \\\" %s\\\", \", task),\n\t\t})\n\tcase \"coder\":\n\t\t// Enhanced version with proper analysis checking and query enhancement\n\t\tanalysis_id, hasAnalysisId := args[\"analysis-id\"].(string)\n\t\ttask, hasTask := args[\"task\"].(string)\n\n\t\tif !hasTask {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  \"missing task parameter\",\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\n\t\tvar query map[string]any\n\t\tanaAgent := coder.AgentCoder{}\n\t\tanaAgent.NewAgent()\n\n\t\t// Check if analysis ID is provided and valid\n\t\tif hasAnalysisId \u0026\u0026 analysis_id != \"\" {\n\t\t\tprevAnalysis, analysisExists := analysis.AnalysisMap[analysis_id]\n\n\t\t\tif analysisExists {\n\t\t\t\t// Analysis found - include it in the query\n\t\t\t\tanalysisForCoder, err := json.Marshal(prevAnalysis)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn map[string]any{\n\t\t\t\t\t\t\"error\": \"Error marshaling analysis data\",\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Enhanced query with analysis context\n\t\t\t\tquery = map[string]any{\n\t\t\t\t\t\"query\": fmt.Sprintf(`CONTEXT: Previous Analysis Available\n=====================================\n%s\n\nCURRENT TASK\n=============\n%s\n\nINSTRUCTIONS\n============\n- Use the above analysis as context to inform your approach\n- Build upon the insights from the previous analysis\n- Ensure consistency with previous findings where applicable\n- If the analysis contradicts the current task, prioritize the task requirements\n- Provide detailed reasoning for your implementation decisions\n- Do not hallucinate or make assumptions not supported by the analysis or task requirements`,\n\t\t\t\t\t\tstring(analysisForCoder), task),\n\t\t\t\t}\n\n\t\t\t\tfmt.Printf(\"Using existing analysis (ID: %s) for enhanced query\\n\", analysis_id)\n\t\t\t} else {\n\t\t\t\t// Analysis ID provided but not found - log warning and proceed with basic query\n\t\t\t\tfmt.Printf(\"Warning: Analysis ID '%s' not found in AnalysisMap, proceeding with basic query\\n\", analysis_id)\n\n\t\t\t\tquery = map[string]any{\n\t\t\t\t\t\"query\": fmt.Sprintf(`TASK\n=====\n%s\n\nINSTRUCTIONS\n============\n- Analyze the task requirements thoroughly\n- Provide a comprehensive implementation approach\n- Consider edge cases and potential issues\n- Ensure code quality and best practices\n- Do not hallucinate or make unfounded assumptions`, task),\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// No analysis ID provided - use enhanced basic query\n\t\t\tfmt.Println(\"No analysis ID provided, using enhanced basic query\")\n\n\t\t\tquery = map[string]any{\n\t\t\t\t\"query\": fmt.Sprintf(`TASK\n=====\n%s\n\nINSTRUCTIONS\n============\n- Perform thorough analysis of the task requirements\n- Break down complex requirements into manageable components\n- Consider potential challenges and solutions\n- Provide clear implementation strategy\n- Follow coding best practices and standards\n- Ensure comprehensive error handling\n- Do not make assumptions beyond what's explicitly stated`, task),\n\t\t\t}\n\t\t}\n\n\t\tfmt.Printf(\"Generated Query:\\n%s\\n\", query[\"query\"])\n\n\t\t// Execute the agent interaction\n\t\tcoderid := anaAgent.Interaction(query)[\"coder-id\"].(string)\n\t\tresult = map[string]any{\n\t\t\t\"coder\": coderid,\n\t\t}\n\tcase \"interactor\":\n\t\tinterAgent := interactor.AgentInteractor{}\n\t\tinterAgent.NewAgent()\n\t\tquery := map[string]any{\"query\": \" Here is the Task do the task: \\\" \" + task + \"\\\",. Make sure to use the analysis-id and coder-id if provided in args.\"}\n\t\tinteractorid := interAgent.Interaction(query)[\"interactor-id\"].(string)\n\t\tresult = map[string]any{\n\t\t\t\"interactor\": interactorid,\n\t\t}\n\tdefault:\n\t\treturn map[string]any{\n\t\t\t\"error\":  fmt.Sprintf(\"unknown agent: %s\", agentID),\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\tfmt.Println(result)\n\n\treturn map[string]any{\n\t\t\"error\":  nil,\n\t\t\"output\": result,\n\t}\n}\n\nfunc CreateTasks(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Println(text)\n\t}\n\trawTasks, ok := args[\"tasks\"].([]interface{})\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"missing or invalid 'tasks' (must be array)\", \"output\": nil}\n\t}\n\n\tvar createdTasks []Task\n\n\tfor _, t := range rawTasks {\n\t\ttaskArgs, ok := t.(map[string]any)\n\t\tif !ok {\n\t\t\treturn map[string]any{\"error\": \"each task must be an object\", \"output\": nil}\n\t\t}\n\n\t\tid, ok := taskArgs[\"id\"].(string)\n\t\tif !ok || id == \"\" {\n\t\t\treturn map[string]any{\"error\": \"each task must have a valid 'id'\", \"output\": nil}\n\t\t}\n\n\t\tdescription, _ := taskArgs[\"description\"].(string)\n\t\tagentID, _ := taskArgs[\"agent_id\"].(string)\n\n\t\ttask := Task{\n\t\t\tID:          id,\n\t\t\tDescription: description,\n\t\t\tAgentID:     agentID,\n\t\t\tInputs:      make(map[string]any),\n\t\t\tOutputs:     make(map[string]any),\n\t\t\tStatus:      TaskPending,\n\t\t\tCreatedAt:   time.Now(),\n\t\t\tUpdatedAt:   time.Now(),\n\t\t}\n\n\t\t// Optional fields\n\t\tif inputs, ok := taskArgs[\"inputs\"].(map[string]any); ok {\n\t\t\ttask.Inputs = inputs\n\t\t}\n\t\tif deps, ok := taskArgs[\"dependencies\"].([]string); ok {\n\t\t\ttask.Dependencies = deps\n\t\t}\n\t\tif meta, ok := taskArgs[\"metadata\"].(map[string]string); ok {\n\t\t\ttask.Metadata = meta\n\t\t}\n\n\t\t// Save in TaskMap\n\t\tTaskMap[task.ID] = task\n\t\tcreatedTasks = append(createdTasks, task)\n\n\t\tfmt.Printf(\"‚úÖ Created Task: %s (%s)\\n\", task.ID, task.Description)\n\t}\n\n\treturn map[string]any{\n\t\t\"error\":  nil,\n\t\t\"output\": createdTasks,\n\t}\n}\n\nfunc TakeInputFromTerminal(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"No Text Provided\"}\n\t}\n\tfmt.Println(text)\n\n\trequirements, ok := args[\"requirements\"].([]any)\n\treader := bufio.NewReader(os.Stdin)\n\n\t// Case 1: No requirements -\u003e just take a single input\n\tif !ok || len(requirements) == 0 {\n\t\tfmt.Print(\"dost\u003e \")\n\t\tinput, err := reader.ReadString('\\n')\n\t\tif err != nil {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  fmt.Sprintf(\"Error reading input: %v\", err),\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\t\tinput = strings.TrimSpace(input)\n\t\tif input == \"\" {\n\t\t\treturn map[string]any{\"error\": nil, \"output\": \"\u003cno input provided\u003e\"}\n\t\t}\n\t\treturn map[string]any{\"error\": nil, \"output\": input}\n\t}\n\n\t// Case 2: Requirements exist -\u003e ask each question\n\tresults := make(map[string]string)\n\tfor _, req := range requirements {\n\t\tquestion, ok := req.(string)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tfmt.Printf(\"dost\u003e %s: \", question)\n\t\tinput, err := reader.ReadString('\\n')\n\t\tif err != nil {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  fmt.Sprintf(\"Error reading input: %v\", err),\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\n\t\tinput = strings.TrimSpace(input)\n\t\tif input == \"\" {\n\t\t\tresults[question] = \"\u003cno input provided\u003e\"\n\t\t} else {\n\t\t\tresults[question] = input\n\t\t}\n\t}\n\n\treturn map[string]any{\"error\": nil, \"output\": results}\n}\n\nfunc ExitProcess(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\trepository.StreamText(text)\n\t}\n\n\tfmt.Println(\"--- Task completed successfully! Exiting...\")\n\treturn map[string]any{\"error\": nil, \"output\": \"Process exited successfully\", \"exit\": true}\n\n}\n\nfunc ReadFiles(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Printf(\"ORCHESTRATOR: %s\", text)\n\t}\n\n\tfileNames, ok := args[\"file_names\"].([]interface{})\n\tif !ok {\n\t\treturn map[string]any{\n\t\t\t\"error\":  \"Invalid arguments: 'file_names' must be a slice of strings\",\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\tvar stringFileNames []string\n\tfor _, v := range fileNames {\n\t\ts, ok := v.(string)\n\t\tif !ok {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  \"Invalid argument: 'file_names' contains non-string values\",\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\t\tstringFileNames = append(stringFileNames, s)\n\t}\n\n\treadFiles := make(map[string]any)\n\tvar notFoundFiles []string\n\n\tfor _, fileName := range stringFileNames {\n\t\tfile, err := os.Open(fileName)\n\t\tif err != nil {\n\t\t\tnotFoundFiles = append(notFoundFiles, fileName)\n\t\t\tcontinue\n\t\t}\n\t\tdefer file.Close()\n\n\t\t// Read all lines, skipping empty ones\n\t\tscanner := bufio.NewScanner(file)\n\t\tvar lines []string\n\t\tlineNumber := 1\n\t\tfor scanner.Scan() {\n\t\t\tline := scanner.Text()\n\t\t\t// Skip empty lines but track line numbers\n\t\t\tif strings.TrimSpace(line) != \"\" {\n\t\t\t\t// Add line number prefix to non-empty lines\n\t\t\t\tnumberedLine := fmt.Sprintf(\"%d: %s\", lineNumber, line)\n\t\t\t\tlines = append(lines, numberedLine)\n\t\t\t}\n\t\t\tlineNumber++\n\t\t}\n\n\t\tif err := scanner.Err(); err != nil {\n\t\t\treadFiles[fileName] = fmt.Sprintf(\"Error reading file: %v\", err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create proper chunks (non-overlapping)\n\t\tchunks := []map[string]any{}\n\t\tchunkSize := 40\n\t\tif len(lines) \u003c 100 {\n\t\t\tchunks = []map[string]any{{\n\t\t\t\t\"start\":   1,\n\t\t\t\t\"end\":     len(lines),\n\t\t\t\t\"content\": strings.Join(lines, \"\\n\"),\n\t\t\t}}\n\t\t} else {\n\t\t\tfor i := 0; i \u003c len(lines); i += chunkSize {\n\t\t\t\tend := i + chunkSize\n\t\t\t\tif end \u003e len(lines) {\n\t\t\t\t\tend = len(lines)\n\t\t\t\t}\n\n\t\t\t\t// Build chunk content\n\t\t\t\tvar chunkContent strings.Builder\n\t\t\t\tfor j := i; j \u003c end; j++ {\n\t\t\t\t\tchunkContent.WriteString(lines[j])\n\t\t\t\t\tif j \u003c end-1 { // Don't add newline after last line in chunk\n\t\t\t\t\t\tchunkContent.WriteString(\"\\n\")\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tchunks = append(chunks, map[string]any{\n\t\t\t\t\t\"start\":   i + 1,\n\t\t\t\t\t\"end\":     end,\n\t\t\t\t\t\"content\": chunkContent.String(),\n\t\t\t\t})\n\t\t\t}\n\n\t\t\t// Handle empty file edge case (all lines were empty)\n\t\t\tif len(lines) == 0 {\n\t\t\t\tchunks = append(chunks, map[string]any{\n\t\t\t\t\t\"start\":   1,\n\t\t\t\t\t\"end\":     0,\n\t\t\t\t\t\"content\": \"\",\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\treadFiles[fileName] = chunks\n\t\t// Also append to the global FilesRead map\n\t\tanalysis.FilesRead[fileName] = chunks\n\t\tfmt.Printf(\"Read file: %s (%d non-empty lines, %d chunks)\\n\", fileName, len(lines), len(chunks))\n\t}\n\n\tif len(notFoundFiles) \u003e 0 {\n\t\tfmt.Printf(\"Files not found: %v\\n\", notFoundFiles)\n\t}\n\n\treturn map[string]any{\"error\": nil, \"output\": readFiles}\n}\n\nfunc WriteFile(args map[string]any) map[string]any {\n\t/*\n\t\targs : {\n\t\t\tfile_names : [ \"test.txt\" ],\n\t\t\tcontents : [ \"hello world\" ],\n\t\t\toffsets: [ 0 ]\n\t\t}\n\t*/\n\tfileNames, hasFileNames := args[\"file_names\"]\n\tcontents, hasContents := args[\"contents\"]\n\toffsets, hasOffsets := args[\"offsets\"]\n\n\tif !hasFileNames || !hasContents {\n\t\treturn map[string]any{\"error\": \"Invalid arguments: file_names and contents required\", \"output\": nil}\n\t}\n\n\t// Type assertions\n\tfileNamesSlice, ok1 := fileNames.([]interface{})\n\tcontentsSlice, ok2 := contents.([]interface{})\n\toffsetsSlice, _ := offsets.([]interface{})\n\n\tif !ok1 || !ok2 {\n\t\treturn map[string]any{\"error\": \"Invalid arguments: file_names and contents must be slices\", \"output\": nil}\n\t}\n\t// Check if offsets are provided and if the length matches\n\tif hasOffsets \u0026\u0026 len(offsetsSlice) != len(fileNamesSlice) {\n\t\treturn map[string]any{\"error\": \"Invalid arguments: offsets must have the same length as file_names\", \"output\": nil}\n\t}\n\n\tif len(fileNamesSlice) != len(contentsSlice) {\n\t\treturn map[string]any{\"error\": \"Invalid arguments: file_names and contents must have the same length\", \"output\": nil}\n\t}\n\n\tvar errors []error\n\tvar modifiedFiles []string\n\n\tfor i, v := range fileNamesSlice {\n\t\tfileName := v.(string)\n\t\tif isCodingFile(fileName) {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\": fmt.Sprintf(\"OPERATION BLOCKED: '%s' appears to be a programming/coding file. This function is restricted to text-only files (.txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex) to prevent accidental modification of source code.\", fileName),\n\t\t\t}\n\t\t}\n\n\t\t// SECURITY CHECK: Verify this is an allowed text file type\n\t\tif !isAllowedTextFile(fileName) {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\": fmt.Sprintf(\"OPERATION BLOCKED: '%s' file type is not allowed. Only text files (.txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex) can be edited by this function.\", fileName),\n\t\t\t}\n\t\t}\n\t\tcontent := contentsSlice[i].(string)\n\n\t\t// Determine the offset for the current file\n\t\tvar offset int64\n\t\tif hasOffsets {\n\t\t\toffset = int64(offsetsSlice[i].(float64))\n\t\t\tif offset \u003c 0 {\n\t\t\t\terrors = append(errors, fmt.Errorf(\"invalid offset for file %s: offset must be non-negative\", fileName))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// Check if file exists. If not, open it to create it.\n\t\tfile, err := os.OpenFile(fileName, os.O_WRONLY|os.O_CREATE, 0644)\n\t\tif err != nil {\n\t\t\terrors = append(errors, fmt.Errorf(\"failed to open/create file %s: %v\", fileName, err))\n\t\t\tcontinue\n\t\t}\n\t\tdefer file.Close()\n\n\t\t// Seek to the specified offset before writing\n\t\t_, err = file.Seek(offset, os.SEEK_SET)\n\t\tif err != nil {\n\t\t\terrors = append(errors, fmt.Errorf(\"failed to seek to offset for file %s: %v\", fileName, err))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Write the content to the file\n\t\t_, err = file.WriteString(content)\n\t\tif err != nil {\n\t\t\terrors = append(errors, fmt.Errorf(\"failed to write to file %s: %v\", fileName, err))\n\t\t\tcontinue\n\t\t}\n\n\t\tfmt.Printf(\"Modified file: %s at offset %d\\n\", fileName, offset)\n\t\tmodifiedFiles = append(modifiedFiles, fileName)\n\t}\n\n\tif len(errors) \u003e 0 {\n\t\treturn map[string]any{\n\t\t\t\"error\":  fmt.Sprintf(\"Errors: %v\", errors),\n\t\t\t\"output\": fmt.Sprintf(\"Partially completed. Modified files: %v\", modifiedFiles),\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"error\":  nil,\n\t\t\"output\": fmt.Sprintf(\"Files modified successfully: %v\", modifiedFiles),\n\t}\n}\nfunc (p *AgentOrchestrator) RequestAgent(contents []map[string]any) map[string]any {\n\tfmt.Printf(\"Processing request with Orchestrator Agent: %s\\n\", p.Metadata.Name)\n\n\t// Build request payload\n\trequest := map[string]any{\n\t\t\"systemInstruction\": map[string]any{\n\t\t\t\"parts\": []map[string]any{\n\t\t\t\t{\"text\": p.Metadata.Instructions},\n\t\t\t},\n\t\t},\n\t\t\"toolConfig\": map[string]any{\n\t\t\t\"functionCallingConfig\": map[string]any{\n\t\t\t\t\"mode\": \"AUTO\",\n\t\t\t},\n\t\t},\n\t\t\"contents\": contents,\n\t\t\"tools\": []map[string]any{\n\t\t\t{\"functionDeclarations\": GetOrchestratorToolsMap()},\n\t\t},\n\t}\n\n\t// Marshal request\n\tjsonBody, err := json.Marshal(request)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t}\n\n\t// Retry configuration\n\tconst maxRetries = 5\n\tconst maxWaitTime = 10 * time.Minute\n\n\tfor attempt := 0; attempt \u003c= maxRetries; attempt++ {\n\t\t// Create HTTP request\n\t\treq, err := http.NewRequestWithContext(\n\t\t\tcontext.Background(),\n\t\t\t\"POST\",\n\t\t\tp.Metadata.Endpoints[\"http\"],\n\t\t\tbytes.NewBuffer(jsonBody),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t}\n\n\t\treq.Header.Set(\"Content-Type\", \"application/json\")\n\t\treq.Header.Set(\"X-goog-api-key\", viper.GetString(\"ORCHESTRATOR.API_KEY\"))\n\n\t\t// Execute request with streaming-optimized client\n\t\tclient := repository.NewStreamingHTTPClient()\n\t\tresp, err := client.Do(req)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\t\tdefer resp.Body.Close()\n\n\t\t// Success case - parse streaming response\n\t\tif resp.StatusCode == http.StatusOK {\n\t\t\t// Parse SSE stream with real-time display\n\t\t\tstreamResp, err := repository.ParseSSEStream(resp.Body, true)\n\t\t\tif err != nil {\n\t\t\t\tif attempt == maxRetries {\n\t\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t\t}\n\t\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Convert to standard output format\n\t\t\toutput := repository.ConvertStreamResponseToOutput(streamResp)\n\n\t\t\t// Save chat history\n\t\t\thistoryEntry := repository.BuildChatHistoryFromStream(streamResp, \"orchestrator\")\n\t\t\tif historyEntry != nil {\n\t\t\t\tChatHistory = append(ChatHistory, historyEntry)\n\t\t\t}\n\n\t\t\tp.Metadata.LastActive = time.Now()\n\t\t\treturn map[string]any{\"error\": nil, \"output\": output}\n\t\t}\n\n\t\t// Read body for error cases\n\t\tbodyBytes, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Handle 429 Too Many Requests\n\t\tif resp.StatusCode == http.StatusTooManyRequests {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Rate limit exceeded after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\t\t\tretryDelay := repository.ParseRetryDelay(string(bodyBytes))\n\t\t\twaitTime := retryDelay\n\t\t\tif waitTime \u003c= 0 {\n\t\t\t\twaitTime = repository.ExponentialBackoff(attempt)\n\t\t\t}\n\t\t\tif waitTime \u003e maxWaitTime {\n\t\t\t\twaitTime = maxWaitTime\n\t\t\t}\n\t\t\tfmt.Printf(\"Orchestrator rate limit hit (attempt %d/%d). Waiting %v...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, waitTime)\n\t\t\ttime.Sleep(waitTime)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Retry 5xx server errors\n\t\tif resp.StatusCode \u003e= 500 \u0026\u0026 resp.StatusCode \u003c 600 {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Server error after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Printf(\"Orchestrator server error (attempt %d/%d). Retrying...\\n\",\n\t\t\t\tattempt+1, maxRetries+1)\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Fail fast on other 4xx\n\t\treturn map[string]any{\n\t\t\t\"error\":  fmt.Sprintf(\"HTTP %d: %s\", resp.StatusCode, string(bodyBytes)),\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"error\":  fmt.Sprintf(\"Max retries (%d) exceeded\", maxRetries),\n\t\t\"output\": nil,\n\t}\n}\n\nfunc ExecuteCommands(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Println(text)\n\t}\n\n\t// Get current working directory\n\twd, err := os.Getwd()\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error()}\n\t}\n\n\t// Extract command\n\tcmdStr, ok := args[\"command\"].(string)\n\tif !ok || cmdStr == \"\" {\n\t\treturn map[string]any{\"error\": \"Invalid command\"}\n\t}\n\n\t// Extract arguments (as array instead of a single string)\n\tvar argList []string\n\tif rawArgs, ok := args[\"arguments\"]; ok {\n\t\tswitch v := rawArgs.(type) {\n\t\tcase string:\n\t\t\t// split on spaces if user passed a string\n\t\t\tif v != \"\" {\n\t\t\t\targList = strings.Fields(v)\n\t\t\t}\n\t\tcase []any:\n\t\t\tfor _, a := range v {\n\t\t\t\tif s, ok := a.(string); ok {\n\t\t\t\t\targList = append(argList, s)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfmt.Println(\"\u003eDOST\\\\\")\n\tfmt.Printf(\"%s %v\", cmdStr, argList)\n\tif !service.TakePermission {\n\t\tfmt.Printf(\"\\nAbout to run command in %s:\\n\u003e %s\\nPress ENTER to continue or Ctrl+C to cancel...\", wd, argList)\n\t\tbufio.NewReader(os.Stdin).ReadBytes('\\n') // wait for Enter\n\t}\n\t// Handle `cd` separately\n\tif cmdStr == \"cd\" {\n\t\tif len(argList) == 0 {\n\t\t\treturn map[string]any{\"error\": \"cd requires a path\"}\n\t\t}\n\t\tnewDir := argList[0]\n\t\tif !filepath.IsAbs(newDir) {\n\t\t\tnewDir = filepath.Join(wd, newDir)\n\t\t}\n\t\tif err := os.Chdir(newDir); err != nil {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"failed to change directory: %v\", err)}\n\t\t}\n\t\treturn map[string]any{\"message\": fmt.Sprintf(\"Changed directory to %s\", newDir)}\n\t}\n\n\t// Build command properly\n\tcmd := exec.Command(cmdStr, argList...)\n\tcmd.Dir = wd\n\tvar stdoutBuf, stderrBuf bytes.Buffer\n\tcmd.Stdin = os.Stdin\n\tcmd.Stdout = io.MultiWriter(os.Stdout, \u0026stdoutBuf)\n\tcmd.Stderr = io.MultiWriter(os.Stderr, \u0026stderrBuf)\n\n\tlog.Default().Printf(\"Running command in %s: %s %v\\n\", wd, cmdStr, argList)\n\n\terr = cmd.Run()\n\tif err != nil {\n\t\treturn map[string]any{\n\t\t\t\"error\": fmt.Sprintf(\"command failed: [%s %v] %v || CONSOLE/TERMINAL:%v\",\n\t\t\t\tcmdStr, argList, err, stderrBuf.String()),\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"message\": \"Command executed successfully\",\n\t\t\"output\":  stdoutBuf.String(),\n\t}\n}\nfunc EditFile(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Printf(\"ORCHESTRATOR: %s\\n\", text)\n\t}\n\n\tfilepathInput, ok := args[\"file_path\"].(string)\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"ERROR READING PATH\"}\n\t}\n\n\t// SECURITY CHECK: Verify this is not a coding file\n\tif isCodingFile(filepathInput) {\n\t\treturn map[string]any{\n\t\t\t\"error\": fmt.Sprintf(\"OPERATION BLOCKED: '%s' appears to be a programming/coding file. This function is restricted to text-only files (.txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex) to prevent accidental modification of source code.\", filepathInput),\n\t\t}\n\t}\n\n\t// SECURITY CHECK: Verify this is an allowed text file type\n\tif !isAllowedTextFile(filepathInput) {\n\t\treturn map[string]any{\n\t\t\t\"error\": fmt.Sprintf(\"OPERATION BLOCKED: '%s' file type is not allowed. Only text files (.txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex) can be edited by this function.\", filepathInput),\n\t\t}\n\t}\n\n\tchanges, ok := args[\"changes\"].([]interface{})\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"REQUIRED CHANGES MAP\"}\n\t}\n\n\t// Convert changes into structured format\n\ttype changeInfo struct {\n\t\tstartLine int\n\t\tstartCol  int\n\t\tendLine   int\n\t\tendCol    int\n\t\toperation string\n\t\tcontent   string\n\t}\n\n\ttoInt := func(v any) (int, bool) {\n\t\tswitch val := v.(type) {\n\t\tcase float64:\n\t\t\treturn int(val), true\n\t\tcase int:\n\t\t\treturn val, true\n\t\tdefault:\n\t\t\treturn 0, false\n\t\t}\n\t}\n\n\tvar processedChanges []changeInfo\n\tfor _, c := range changes {\n\t\tch, ok := c.(map[string]any)\n\t\tif !ok {\n\t\t\treturn map[string]any{\"error\": \"INVALID CHANGE FORMAT\"}\n\t\t}\n\n\t\tstartLine, _ := toInt(ch[\"start_line_number\"])\n\t\tstartCol, _ := toInt(ch[\"start_line_col\"])\n\t\tendLine, _ := toInt(ch[\"end_line_number\"])\n\t\tendCol, _ := toInt(ch[\"end_line_col\"])\n\t\toperation, _ := ch[\"operation\"].(string)\n\t\tcontent, _ := ch[\"content\"].(string)\n\n\t\tprocessedChanges = append(processedChanges, changeInfo{\n\t\t\tstartLine: startLine,\n\t\t\tstartCol:  startCol,\n\t\t\tendLine:   endLine,\n\t\t\tendCol:    endCol,\n\t\t\toperation: operation,\n\t\t\tcontent:   content,\n\t\t})\n\t}\n\n\t// Sort changes by start line \u0026 col (descending to avoid position conflicts)\n\tsort.Slice(processedChanges, func(i, j int) bool {\n\t\tif processedChanges[i].startLine == processedChanges[j].startLine {\n\t\t\treturn processedChanges[i].startCol \u003e processedChanges[j].startCol\n\t\t}\n\t\treturn processedChanges[i].startLine \u003e processedChanges[j].startLine\n\t})\n\n\t// Read entire file into memory first\n\tfileContent, err := os.ReadFile(filepathInput)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": \"CANNOT READ INPUT FILE: \" + err.Error()}\n\t}\n\n\tlines := strings.Split(string(fileContent), \"\\n\")\n\n\t// Apply changes from last to first (to maintain line numbers)\n\tfor _, change := range processedChanges {\n\t\tswitch change.operation {\n\t\tcase \"delete\":\n\t\t\tif change.startLine \u003e 0 \u0026\u0026 change.endLine \u003c= len(lines) {\n\t\t\t\t// Delete lines (1-indexed to 0-indexed)\n\t\t\t\tstart := change.startLine - 1\n\t\t\t\tend := change.endLine\n\t\t\t\tif end \u003e len(lines) {\n\t\t\t\t\tend = len(lines)\n\t\t\t\t}\n\t\t\t\tlines = append(lines[:start], lines[end:]...)\n\t\t\t}\n\n\t\tcase \"replace\":\n\t\t\tif change.startLine \u003e 0 \u0026\u0026 change.startLine \u003c= len(lines) {\n\t\t\t\tlineIdx := change.startLine - 1\n\t\t\t\tif lineIdx \u003c len(lines) {\n\t\t\t\t\tline := lines[lineIdx]\n\t\t\t\t\tif change.startCol \u003c= len(line) \u0026\u0026 change.endCol \u003c= len(line) {\n\t\t\t\t\t\tnewLine := line[:change.startCol] + change.content + line[change.endCol:]\n\t\t\t\t\t\tlines[lineIdx] = newLine\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase \"write\":\n\t\t\tif change.startLine \u003e 0 \u0026\u0026 change.startLine \u003c= len(lines) {\n\t\t\t\tlineIdx := change.startLine - 1\n\t\t\t\tif lineIdx \u003c len(lines) {\n\t\t\t\t\tline := lines[lineIdx]\n\t\t\t\t\tif change.startCol \u003c= len(line) {\n\t\t\t\t\t\tnewLine := line[:change.startCol] + change.content + line[change.startCol:]\n\t\t\t\t\t\tlines[lineIdx] = newLine\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Write back to original file\n\tnewContent := strings.Join(lines, \"\\n\")\n\terr = os.WriteFile(filepathInput, []byte(newContent), 0644)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": \"CANNOT WRITE TO FILE: \" + err.Error()}\n\t}\n\n\treturn map[string]any{\n\t\t\"output\": fmt.Sprintf(\"Successfully edited text file: %s\", filepathInput),\n\t}\n}\nfunc GetProjectStructure(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\tfmt.Println(text)\n\t}\n\n\tloadGitIgnore()\n\tpath := args[\"path\"].(string)\n\tvar builder strings.Builder\n\tbuilder.WriteString(path + \"\\n\")\n\terr := getProjectStructureRecursive(path, \"\", \u0026builder)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err, \"output\": nil}\n\t}\n\n\tif builder.String() == \".\" || builder.String() == \"\" {\n\t\treturn map[string]any{\"error\": nil, \"output\": \"\u003cempty directory\u003e\"}\n\t}\n\treturn map[string]any{\"error\": nil, \"output\": builder.String()}\n}\nfunc loadGitIgnore() {\n\tif _, err := os.Stat(\".gitignore\"); err == nil {\n\t\tignoreMatcher, _ = gitignore.CompileIgnoreFile(\".gitignore\")\n\t}\n}\nfunc getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {\n\tentries, err := os.ReadDir(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor i, entry := range entries {\n\t\tentryPath := filepath.Join(path, entry.Name())\n\n\t\t// skip ignored entries\n\t\tif ignoreMatcher != nil {\n\t\t\trelPath, _ := filepath.Rel(\".\", entryPath)\n\t\t\tif ignoreMatcher.MatchesPath(relPath) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tif defaultIgnore[entry.Name()] {\n\t\t\t// ‚úÖ Skip this directory and its contents completely\n\t\t\tif entry.IsDir() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// draw branch\n\t\tconnector := \"‚îú‚îÄ‚îÄ\"\n\t\tif i == len(entries)-1 {\n\t\t\tconnector = \"‚îî‚îÄ‚îÄ\"\n\t\t}\n\t\tbuilder.WriteString(prefix + connector + \" \" + entry.Name() + \"\\n\")\n\n\t\t// recursively descend\n\t\tif entry.IsDir() {\n\t\t\tsubPrefix := prefix\n\t\t\tif i == len(entries)-1 {\n\t\t\t\tsubPrefix += \"    \"\n\t\t\t} else {\n\t\t\t\tsubPrefix += \"‚îÇ   \"\n\t\t\t}\n\t\t\t// üö´ Don't go inside ignored directories\n\t\t\tif !defaultIgnore[entry.Name()] {\n\t\t\t\terr := getProjectStructureRecursive(entryPath, subPrefix, builder)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\nfunc isAllowedTextFile(filePath string) bool {\n\t// Get file extension and convert to lowercase\n\text := strings.ToLower(filepath.Ext(filePath))\n\n\t// Define allowed text file extensions\n\tallowedExtensions := map[string]bool{\n\t\t\".txt\":  true, // Plain text files\n\t\t\".md\":   true, // Markdown files\n\t\t\".rst\":  true, // reStructuredText files\n\t\t\".log\":  true, // Log files\n\t\t\".csv\":  true, // Comma-separated values\n\t\t\".json\": true, // JSON data files\n\t\t\".xml\":  true, // XML files\n\t\t\".yaml\": true, // YAML files\n\t\t\".yml\":  true, // YAML files (alternate extension)\n\t\t\".html\": true, // HTML markup (content files, not code)\n\t\t\".css\":  true, // CSS stylesheets (content files, not code)\n\t\t\".ini\":  true, // Configuration files\n\t\t\".cfg\":  true, // Configuration files\n\t\t\".conf\": true, // Configuration files\n\t\t\".rtf\":  true, // Rich Text Format\n\t\t\".tex\":  true, // LaTeX files\n\t\t\"\":      true, // Files without extension (often text files)\n\t}\n\n\treturn allowedExtensions[ext]\n}\n\n// isCodingFile checks if the file extension belongs to programming/coding files\nfunc isCodingFile(filePath string) bool {\n\text := strings.ToLower(filepath.Ext(filePath))\n\n\tcodingExtensions := map[string]bool{\n\n\t\t\".go\":    true, // Go\n\t\t\".py\":    true, // Python\n\t\t\".js\":    true, // JavaScript\n\t\t\".ts\":    true, // TypeScript\n\t\t\".jsx\":   true, // React JSX\n\t\t\".tsx\":   true, // TypeScript JSX\n\t\t\".java\":  true, // Java\n\t\t\".c\":     true, // C\n\t\t\".cpp\":   true, // C++\n\t\t\".cc\":    true, // C++\n\t\t\".cxx\":   true, // C++\n\t\t\".h\":     true, // C/C++ headers\n\t\t\".hpp\":   true, // C++ headers\n\t\t\".php\":   true, // PHP\n\t\t\".rb\":    true, // Ruby\n\t\t\".swift\": true, // Swift\n\t\t\".kt\":    true, // Kotlin\n\t\t\".rs\":    true, // Rust\n\t\t\".vue\":   true, // Vue.js\n\t\t\".scala\": true, // Scala\n\t\t\".r\":     true, // R\n\t\t\".m\":     true, // Objective-C/MATLAB\n\t\t\".pl\":    true, // Perl\n\t\t\".lua\":   true, // Lua\n\t\t\".dart\":  true, // Dart\n\t\t\".elm\":   true, // Elm\n\t\t\".clj\":   true, // Clojure\n\t\t\".hs\":    true, // Haskell\n\t\t\".f90\":   true, // Fortran\n\t\t\".pas\":   true, // Pascal\n\t\t\".asm\":   true, // Assembly\n\n\t\t\".sh\":   true, // Shell scripts\n\t\t\".bash\": true, // Bash scripts\n\t\t\".zsh\":  true, // Zsh scripts\n\t\t\".fish\": true, // Fish scripts\n\t\t\".bat\":  true, // Windows batch files\n\t\t\".cmd\":  true, // Windows command files\n\t\t\".ps1\":  true, // PowerShell scripts\n\n\t\t\".sql\": true, // SQL files\n\n\t\t\".makefile\":   true, // Makefiles\n\t\t\".dockerfile\": true, // Docker files\n\t\t\".gradle\":     true, // Gradle build files\n\t\t\".maven\":      true, // Maven files\n\t\t\".cmake\":      true, // CMake files\n\t}\n\n\treturn codingExtensions[ext]\n}\n\nvar OrchestratorCapabilities = []repository.Function{{\n\tName: \"execute-command-in-terminal\",\n\tDescription: `Run any valid shell/terminal command in the current working directory. \nUse for:\n- File operations (create, delete, list, copy files, move files, rename files)\n- Navigation (cd, ls)\n- Package management (npm, pip, go, dart, flutter, etc.)\n- Build tools (make, go build, flutter build, etc.)\n- Executing programs, checking versions, inspecting system state\n- Git operations (status, diff, add, commit, push, pull, log, branch, etc.)\n\nAlways provide the command and arguments separately.\nExample: { \"command\": \"git\", \"arguments\": [\"commit\", \"-m\", \"testing through this tool\"] }`,\n\n\tParameters: repository.Parameters{\n\t\tType: repository.TypeObject,\n\t\tProperties: map[string]*repository.Properties{\n\t\t\t\"command\": {\n\t\t\t\tType:        repository.TypeString,\n\t\t\t\tDescription: \"Base command to execute (e.g., git, go, npm, python, ls)\",\n\t\t\t},\n\t\t\t\"arguments\": {\n\t\t\t\tType: repository.TypeArray,\n\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Each argument passed separately (e.g., [\\\"commit\\\", \\\"-m\\\", \\\"msg\\\"])\",\n\t\t\t\t},\n\t\t\t\tDescription: \"Optional arguments for the command as an array\",\n\t\t\t},\n\t\t},\n\t\tRequired: []string{\"command\"},\n\t\tOptional: []string{\"arguments\"},\n\t},\n\n\tService: ExecuteCommands,\n\n\tReturn: repository.Return{\n\t\t\"error\":  \"string\",\n\t\t\"output\": \"string\",\n\t},\n},\n\t{\n\t\tName:        \"edit-file\",\n\t\tDescription: \"Edits ONLY text-based files (txt, md, rst, log, csv, json, xml, yaml, yml, html, css, ini, cfg, conf, rtf, tex) at a given path by applying specified changes. This function is STRICTLY RESTRICTED to non-coding files to prevent accidental modification of source code. Programming files (.go, .py, .js, .java, .c, .cpp, .h, .php, .rb, .swift, .kt, .rs, .ts, .jsx, .tsx, .vue, .scala, .sh, .bat, .ps1, .sql, .r, .m, .pl, .lua, .dart, .elm, .clj, .hs, .f90, .pas, .asm, etc.) are explicitly blocked for safety.\",\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Additional context or instructions provided by the AI for the edit operation.\",\n\t\t\t\t},\n\t\t\t\t\"file_path\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"The path of the TEXT FILE to edit (only .txt, .md, .rst, .log, .csv, .json, .xml, .yaml, .yml, .html, .css, .ini, .cfg, .conf, .rtf, .tex files allowed). Example: './folder/document.txt' or './notes.md'. Programming files are blocked.\",\n\t\t\t\t},\n\t\t\t\t\"changes\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"A list of changes to apply to the text file, with each change specifying a selection and an operation.\",\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType:        repository.TypeObject,\n\t\t\t\t\t\tDescription: \"Operation Meta data\",\n\t\t\t\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\t\t\t\"start_line_number\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeInteger,\n\t\t\t\t\t\t\t\tDescription: \"The starting line number (1-based) of the change range.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"start_line_col\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeInteger,\n\t\t\t\t\t\t\t\tDescription: \"The starting column number (0-based) of the change range.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"end_line_number\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeInteger,\n\t\t\t\t\t\t\t\tDescription: \"The ending line number (1-based) of the change range.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"end_line_col\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeInteger,\n\t\t\t\t\t\t\t\tDescription: \"The ending column number (0-based) of the change range.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"operation\": {\n\t\t\t\t\t\t\t\tEnum:        []string{\"delete\", \"replace\", \"write\"},\n\t\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\t\tDescription: \"The operation to perform on the selected range. Options: 'delete' (remove text), 'replace' (replace text with new content), or 'write' (insert new content at start).\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"content\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\t\tDescription: \"The replacement or insertion text to apply. Required for 'replace' and 'write' operations.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRequired: []string{\"start_line_number\", \"start_line_col\", \"end_line_number\", \"end_line_col\", \"operation\", \"content\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"text\", \"file_path\", \"changes\"},\n\t\t},\n\t\tService: EditFile,\n\t},\n\t{\n\t\tName: \"take-input-from-terminal\",\n\t\tDescription: `Prompts the user in the terminal for multiple required inputs.\nUse this whenever you are missing essential details, such as:\n- File names\n- Function parameters\n- Configuration values\n- User choices`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"requirements\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"A list of questions or keys to ask the user for input\",\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType: \"string\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"A text which you want to say to user, instead of returning text output give it in this parameter\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"requirements\", \"text\"},\n\t\t},\n\t\tService: TakeInputFromTerminal,\n\t\tReturn:  repository.Return{\"error\": \"string\", \"output\": \"object\"},\n\t},\n\t{\n\t\tName: \"exit-process\",\n\t\tDescription: `When you feel that the task is fully completed, always call this function to exit the process.\n‚ö†Ô∏è Important:\n- Before calling, make sure all steps are done, bugs are fixed, and the user is satisfied.\n- Instead of just returning raw text, always compile everything (final output, explanations, summaries, code, results, etc.) into a single clear text message.\n- Put that final compiled text inside the \"text\" parameter. This is what the user will see as the final answer.`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"The final compiled text output for the user (summary, results, explanations, etc.)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"text\"},\n\t\t},\n\t\tService: ExitProcess,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string\",\n\t\t\t\"output\": \"string\",\n\t\t},\n\t},\n\t{\n\t\tName: \"write-file\",\n\t\tDescription: `Write or overwrite file contents with precise control over offsets and data placement.  \nThis tool provides COMPLETE file manipulation capabilities, enabling:\n\nüìù BASIC FILE OPERATIONS:\n- Full overwrite: Replace the entire content of an existing file with new data.\n- Append mode: Add content at the end of the file by setting offset equal to file size.\n- Partial overwrite: Modify specific portions of a file without affecting the rest.\n- Sparse file creation: Insert padding/zero-bytes automatically when offset exceeds file size.\n\nüìÇ USE CASES:\n- Create or update configuration files (e.g., .env, config.json, settings.yaml).\n- Maintain logs, append new entries without altering existing data.\n- Replace corrupted sections of a binary/text file.\n- Write test fixtures or datasets programmatically.\n- Manage source code updates while preserving line/byte positions.\n\n‚öôÔ∏è ADVANCED FEATURES:\n- Multi-file support: Operate on multiple files in one call.\n- Precise byte-level control: Offsets allow low-level file manipulations.\n- Data replacement: Insert/overwrite any part of a file with new content slices.\n- Sparse handling: Automatically generates empty byte padding for large jumps in offset.\n- Integration: Always call 'read_files' first to load current file state before modification.\n\nüö´ SAFETY \u0026 USAGE NOTES:\n- ‚ö†Ô∏è Be careful when overwriting: it PERMANENTLY replaces existing file content.\n- Always confirm offsets and file names to avoid unintentional data loss.\n- Ensure file extensions match expected format (.txt, .json, .go, .py, etc.).\n- Using offsets incorrectly can corrupt structured files (e.g., JSON, XML).\n- Use sparse file creation only if downstream systems can handle them properly.\n\nüìä COMMON PATTERNS:\n- Full overwrite:\n  { \"file_names\": [\"config.json\"], \"contents\": [\"{ \\\"debug\\\": true }\"], \"offsets\": [0] }\n\n- Append to file:\n  { \"file_names\": [\"log.txt\"], \"contents\": [\"New log entry\"], \"offsets\": [\u003ccurrent_file_size\u003e] }\n\n- Overwrite at position:\n  { \"file_names\": [\"data.bin\"], \"contents\": [\"FF00AA\"], \"offsets\": [128] }\n\n- Create sparse file:\n  { \"file_names\": [\"huge.dat\"], \"contents\": [\"End Marker\"], \"offsets\": [1000000000] }\n\nüñ•Ô∏è EXAMPLES:\n- Replace entire README.md with new content.\n- Append a new migration entry into a SQL file.\n- Patch a corrupted section of a binary executable.\n- Programmatically generate structured text/data files.\n- ONLY text-based files (txt, md, rst, log, csv, json, xml, yaml, yml, html, css, ini, cfg, conf, rtf, tex) at a given path by applying specified changes. This function is STRICTLY RESTRICTED to non-coding files to prevent accidental modification of source code. Programming files (.go, .py, .js, .java, .c, .cpp, .h, .php, .rb, .swift, .kt, .rs, .ts, .jsx, .tsx, .vue, .scala, .sh, .bat, .ps1, .sql, .r, .m, .pl, .lua, .dart, .elm, .clj, .hs, .f90, .pas, .asm, etc.) are explicitly blocked for safety.\nThis tool is your gateway to precise file manipulation and content management. Use it to create, append, overwrite, and manage files across any project lifecycle with full byte-level control.`,\n\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"file_names\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\tDescription: \"List of file names (with extensions) where operations will be performed. Each file corresponds to matching index of 'contents' and 'offsets'.\",\n\t\t\t\t},\n\t\t\t\t\"contents\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\tDescription: \"Full content strings to write into files. Each entry aligns with 'file_names' and 'offsets'.\",\n\t\t\t\t},\n\t\t\t\t\"offsets\": {\n\t\t\t\t\tType:  repository.TypeArray,\n\t\t\t\t\tItems: \u0026repository.Properties{Type: repository.TypeNumber},\n\t\t\t\t\tDescription: `Array of byte offsets controlling write position for each file:\n- Omit or set 0 ‚Üí Overwrite entire file from beginning.\n- Equal to file size ‚Üí Append new content at the end.\n- Within file size ‚Üí Overwrite content starting from that offset.\n- Beyond file size ‚Üí Create sparse file with zero-padding.`,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"file_names\", \"contents\", \"offsets\"},\n\t\t},\n\n\t\tService: WriteFile,\n\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string // Error details if write fails (invalid path, permissions, etc.).\",\n\t\t\t\"output\": \"string // Confirmation details such as bytes written, offsets applied, and file names affected.\",\n\t\t},\n\t},\n\n\t{\n\t\tName: \"ask-an-agent\",\n\t\tDescription: `Route a task to a specific agent for processing.\nAvailable agents:\n- analysis: Performs task analysis and validation\n- planning: Creates execution plans\n- execution: Executes planned tasks`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"A text which you want to say to user, instead of returning text output give it in this parameter\",\n\t\t\t\t},\n\t\t\t\t\"agent_id\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"The ID of the agent to route the task to (analysis, planning, execution)\",\n\t\t\t\t\tEnum:        []string{\"analysis\", \"coder\", \"planner\", \"interactor\"},\n\t\t\t\t},\n\t\t\t\t\"task\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"The task which is to be processed by the agent, if nothing available just give the proper detailed query\",\n\t\t\t\t},\n\t\t\t\t\"analysis-id\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"The Analysis which you got from analysis agent keep it simple and detailed with each and every analysis and bullet points. Since coder agent will also need it so make sure to give it.\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"agent_id\", \"task\", \"analysis-id\"},\n\t\t},\n\t\tService: AskAnAgent,\n\t\tReturn:  repository.Return{\"error\": \"string\", \"output\": \"object\"},\n\t},\n\t{\n\t\tName: \"create-tasks\",\n\t\tDescription: `Create multiple tasks and store them in the TaskMap.\nEach task must have an ID and can have optional description, agent_id, inputs, dependencies, outputs, and metadata.`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"A text which you want to say to user, instead of returning text output give it in this parameter\",\n\t\t\t\t},\n\t\t\t\t\"tasks\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"Array of task objects to create\",\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType: repository.TypeObject,\n\t\t\t\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\t\t\t\"id\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\t\tDescription: \"Unique identifier for the task (required)\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"description\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\t\tDescription: \"Optional description of the task\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"agent_id\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\t\tDescription: \"Agent assigned to this task (optional)\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"inputs\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeObject,\n\t\t\t\t\t\t\t\tDescription: \"Input parameters required for the task\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"outputs\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeObject,\n\t\t\t\t\t\t\t\tDescription: \"Expected or generated outputs for the task\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"dependencies\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\t\t\t\tDescription: \"IDs of tasks this task depends on\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"metadata\": {\n\t\t\t\t\t\t\t\tType: repository.TypeObject,\n\t\t\t\t\t\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\t\t\t\t\t\"key\": {Type: repository.TypeString},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tDescription: \"Custom metadata key-value pairs\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRequired: []string{\"id\", \"description\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"tasks\"},\n\t\t},\n\t\tService: CreateTasks,\n\t\tReturn:  repository.Return{\"error\": \"string\", \"output\": \"array\"},\n\t},\n\n\t{\n\t\tName: \"read-files\",\n\t\tDescription: `Read and analyze multiple files efficiently in a single operation. \n\t\n\tIMPORTANT: This function can read MULTIPLE files simultaneously - pass ALL file paths you need in the file_names array rather than calling this function multiple times for individual files.\n\t\n\tKey features:\n\t- Reads multiple files in one call (more efficient than multiple separate calls)\n\t- Automatically skips empty lines to save tokens and improve clarity\n\t- Adds line numbers to each line for precise reference and debugging\n\t- Chunks large files automatically for better processing\n\t- Stores read files globally for reuse across the session\n\t\n\tBest practices:\n\t- Pass ALL required file paths in a single call: [\"file1.go\", \"file2.md\", \"file3.txt\"]\n\t- Use when you need to analyze code structure, configuration files, documentation, or any text-based content\n\t- Ideal for cross-file analysis, dependency checking, or comprehensive codebase review\n\t\n\tExample usage scenarios:\n\t- Code analysis: [\"main.go\", \"utils.go\", \"config.yaml\"]\n\t- Documentation review: [\"README.md\", \"CHANGELOG.md\", \"API.md\"]\n\t- Configuration audit: [\"docker-compose.yml\", \".env\", \"nginx.conf\"]\n\t\n\tThe function returns structured data with line numbers, making it easy to reference specific parts of files in subsequent analysis.`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Optional message to display to the user explaining what files you're reading and why, instead of just returning output silently\",\n\t\t\t\t},\n\t\t\t\t\"file_names\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"Array of file paths to read simultaneously. IMPORTANT: Include ALL files you need in this single array rather than making multiple function calls. Examples: ['main.go', 'config.yaml'], ['src/app.js', 'package.json', 'README.md']\",\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType: \"string\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"file_names\"},\n\t\t},\n\t\tService: ReadFiles,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string - null if successful, error message if failed\",\n\t\t\t\"output\": \"object - map of filename to chunks with line numbers and content\",\n\t\t},\n\t},\n}\n\nfunc init() {\n\tfor _, v := range OrchestratorCapabilities {\n\t\tOrchestratortoolsFunc[v.Name] = v\n\t}\n}\n\nfunc OrchestratorTools() map[string]repository.Function {\n\treturn OrchestratortoolsFunc\n}\n\nfunc GetOrchestratorTools() []repository.Function {\n\treturn OrchestratorCapabilities\n}\n\nfunc GetOrchestratorToolsMap() []map[string]any {\n\tarrayOfMap := make([]map[string]any, 0)\n\tfor _, v := range OrchestratorCapabilities {\n\t\tarrayOfMap = append(arrayOfMap, v.ToObject())\n\t}\n\treturn arrayOfMap\n}\n",
    "hash": "3288286f3f8cb4d5b35964a2f06a37d8",
    "size": 57331,
    "tokens": 14332,
    "modified_time": "2026-02-10T21:10:38.755631395+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "GetInitialContext",
      "detectDefaultShell",
      "mustGetWorkingDir",
      "detectTools",
      "getImportantEnvVars",
      "scanProjectFiles",
      "detectProjectType",
      "getGitBranch",
      "checkInternet",
      "getLocalTimezone",
      "generateSessionID",
      "formatFilesForOrchestrator",
      "AskAnAgent",
      "CreateTasks",
      "TakeInputFromTerminal",
      "ExitProcess",
      "ReadFiles",
      "WriteFile",
      "ExecuteCommands",
      "EditFile",
      "GetProjectStructure",
      "loadGitIgnore",
      "getProjectStructureRecursive",
      "isAllowedTextFile",
      "isCodingFile",
      "init",
      "OrchestratorTools",
      "GetOrchestratorTools",
      "GetOrchestratorToolsMap"
    ],
    "security": [
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 676,
        "column": 0,
        "code": "fmt.Print(\"dost\u003e \")",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 1649,
        "column": 0,
        "code": "{ \"file_names\": [\"config.json\"], \"contents\": [\"{ \\\"debug\\\": true }\"], \"offsets\": [0] }",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 1804,
        "column": 0,
        "code": "- Adds line numbers to each line for precise reference and debugging",
        "tool": "regex"
      }
    ]
  },
  "375ffbddadffa8530302a3cd6470e8a1": {
    "path": "internal/repository/tools_repo.go",
    "content": "package repository\n\nconst (\n\t// TypeUnspecified means not specified, should not be used.\n\tTypeUnspecified = \"0\"\n\t// TypeString means openAPI string type\n\tTypeString = \"1\"\n\t// TypeNumber means openAPI number type\n\tTypeNumber = \"2\"\n\t// TypeInteger means openAPI integer type\n\tTypeInteger = \"3\"\n\t// TypeBoolean means openAPI boolean type\n\tTypeBoolean = \"4\"\n\t// TypeArray means openAPI array type\n\tTypeArray = \"5\"\n\t// TypeObject means openAPI object type\n\tTypeObject = \"6\"\n)\n\ntype Response struct {\n\tCandidates []struct {\n\t\tContent struct {\n\t\t\tParts []struct {\n\t\t\t\tText         string `json:\"text\"`\n\t\t\t\tFunctionCall *struct {\n\t\t\t\t\tName string `json:\"name\"`\n\t\t\t\t\tArgs map[string]any\n\t\t\t\t} `json:\"functionCall\"`\n\t\t\t} `json:\"parts\"`\n\t\t\tRole string `json:\"role\"`\n\t\t} `json:\"content\"`\n\t} `json:\"candidates\"`\n}\n\ntype Return map[string]any\ntype Properties struct {\n\tType        string                 `json:\"type\"`\n\tItems       *Properties            `json:\"items\"`\n\tFormat      string                 `json:\"format\"`\n\tEnum        []string               `json:\"enum\"`\n\tProperties  map[string]*Properties `json:\"properties\"`\n\tRequired    []string               `json:\"required\"`\n\tDescription string                 `json:\"description\"`\n}\n\nfunc (p *Properties) ToObject() map[string]any {\n\treturn map[string]any{\n\t\t\"type\":        p.Type,\n\t\t\"items\":       p.Items,\n\t\t\"format\":      p.Format,\n\t\t\"description\": p.Description,\n\t\t\"enum\":        p.Enum,\n\t}\n}\n\ntype Parameters struct {\n\tType       string                 `json:\"type\"`\n\tProperties map[string]*Properties `json:\"properties\"`\n\tRequired   []string               `json:\"required\"`\n\tOptional   []string               `json:\"optional\"`\n}\n\nfunc (p *Parameters) ToObject() map[string]any {\n\ttemp := make(map[string]any)\n\tfor k, v := range p.Properties {\n\t\ttemp[k] = v.ToObject()\n\t}\n\tval := map[string]any{\n\t\t\"type\":       p.Type,\n\t\t\"properties\": temp,\n\t\t\"required\":   p.Required,\n\t}\n\treturn val\n}\n\ntype Function struct {\n\tName        string                                   `json:\"name\"`\n\tDescription string                                   `json:\"description\"`\n\tParameters  Parameters                               `json:\"parameters\"`\n\tReturn      Return                                   `json:\"return\"`\n\tService     func(args map[string]any) map[string]any `json:\"-\"`\n}\n\nfunc (f *Function) Run(args map[string]any) map[string]any {\n\terr := f.Service(args)\n\n\treturn err\n}\n\nfunc (f *Function) ToObject() map[string]any {\n\n\tval := map[string]any{\n\t\t\"name\":        f.Name,\n\t\t\"description\": f.Description,\n\t\t\"parameters\":  f.Parameters.ToObject(),\n\t}\n\treturn val\n}\n",
    "hash": "375ffbddadffa8530302a3cd6470e8a1",
    "size": 2603,
    "tokens": 650,
    "modified_time": "2025-12-28T22:01:44.422806036+05:30",
    "language": "go",
    "imports": [],
    "functions": []
  },
  "50fc392c4575ab75717bab2c41f7ce4a": {
    "path": "internal/repository/tasks.go",
    "content": "package repository\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype TaskStatus string\n\nconst (\n\tStatusPending    TaskStatus = \"pending\"\n\tStatusInProgress TaskStatus = \"in_progress\"\n\tStatusCompleted  TaskStatus = \"completed\"\n\tStatusFailed     TaskStatus = \"failed\"\n\tStatusStuck      TaskStatus = \"stuck\"\n)\n\ntype TaskTracker struct {\n\t// Core Task Info\n\tTaskID    string     `json:\"taskId\"`\n\tTitle     string     `json:\"title\"`\n\tStatus    TaskStatus `json:\"status\"`\n\tPriority  int        `json:\"priority\"` // 1-5, 5 being highest\n\tCreatedBy string     `json:\"createdBy\"`\n\n\t// Progress Tracking\n\tCurrentPhase   string   `json:\"currentPhase\"`\n\tCompletedSteps []string `json:\"completedSteps\"`\n\tPendingSteps   []string `json:\"pendingSteps\"`\n\n\t// File Operations\n\tFilesCreated  []string `json:\"filesCreated\"`\n\tFilesModified []string `json:\"filesModified\"`\n\n\t// Command Execution\n\tCommandsRun           []string `json:\"commandsRun\"`\n\tFailedCommands        []string `json:\"failedCommands\"`\n\tLastSuccessfulCommand string   `json:\"lastSuccessfulCommand\"`\n\n\t// AI Interaction\n\tLastAIResponse       string         `json:\"lastAiResponse\"`\n\tLastFunctionCall     string         `json:\"lastFunctionCall\"`\n\tLastFunctionResponse map[string]any `json:\"lastFunctionResponse\"`\n\n\t// Iteration \u0026 Loop Prevention\n\tIteration                  int `json:\"iteration\"`\n\tConsecutiveReadCalls       int `json:\"consecutiveReadCalls\"`\n\tConsecutiveSameCommands    int `json:\"consecutiveSameCommands\"`\n\tFunctionCallsThisIteration int `json:\"functionCallsThisIteration\"`\n\tEmptyResponseCount         int `json:\"emptyResponseCount\"`\n\n\t// Error Handling\n\tLastError           string   `json:\"lastError\"`\n\tErrorCount          int      `json:\"errorCount\"`\n\tDependencyErrors    []string `json:\"dependencyErrors\"`\n\tConsecutiveFailures int      `json:\"consecutiveFailures\"`\n\n\t// State Flags\n\tTaskCompleted             bool `json:\"taskCompleted\"`\n\tErrorsFound               bool `json:\"errorsFound\"`\n\tBuildAttempted            bool `json:\"buildAttempted\"`\n\tRequiresFixing            bool `json:\"requiresFixing\"`\n\tProjectStructureRetrieved bool `json:\"projectStructureRetrieved\"`\n\n\t// Advanced Tracking\n\tLastActionType         string `json:\"lastActionType\"`\n\tConversationResetCount int    `json:\"conversationResetCount\"`\n\n\t// Timing\n\tStartTime        time.Time      `json:\"startTime\"`\n\tLastSuccessTime  time.Time      `json:\"lastSuccessTime\"`\n\tMaxExecutionTime time.Duration  `json:\"maxExecutionTime\"`\n\tIdleTime         time.Duration  `json:\"idleTime\"`\n\tPlanningComplete bool           `json:\"planningComplete\"`\n\tExecutionPlan    map[string]any `json:\"executionPlan\"`\n\tNextStep         string         `json:\"nextStep\"`\n}\n\nfunc (T *TaskTracker) ToObject() map[string]any {\n\n\t// Convert struct to JSON\n\tjsonData, err := json.Marshal(T)\n\tif err != nil {\n\t\tfmt.Println(\"Error marshaling JSON:\", err)\n\t\treturn nil\n\t}\n\n\t// Unmarshal JSON into a map[string]any\n\tvar taskMap map[string]any\n\terr = json.Unmarshal(jsonData, \u0026taskMap)\n\tif err != nil {\n\t\tfmt.Println(\"Error unmarshaling JSON:\", err)\n\t\treturn nil\n\t}\n\treturn taskMap\n}\nfunc NewTask(params map[string]any) map[string]any {\n\ttitle, _ := params[\"title\"].(string)\n\tcreatedBy, _ := params[\"createdBy\"].(string)\n\tstatus, _ := params[\"status\"].(TaskStatus)\n\n\t// Extract planning data if provided\n\tplanningComplete, _ := params[\"planningComplete\"].(bool)\n\texecutionPlan, _ := params[\"executionPlan\"].(map[string]any)\n\tnextStep, _ := params[\"nextStep\"].(string)\n\n\ttracker := TaskTracker{\n\t\tTaskID:               generateTaskID(),\n\t\tTitle:                title,\n\t\tStatus:               status,\n\t\tPriority:             3, // Default medium priority\n\t\tCreatedBy:            createdBy,\n\t\tCurrentPhase:         \"initialization\",\n\t\tCompletedSteps:       make([]string, 0),\n\t\tPendingSteps:         make([]string, 0),\n\t\tFilesCreated:         make([]string, 0),\n\t\tFilesModified:        make([]string, 0),\n\t\tCommandsRun:          make([]string, 0),\n\t\tFailedCommands:       make([]string, 0),\n\t\tDependencyErrors:     make([]string, 0),\n\t\tStartTime:            time.Now(),\n\t\tLastSuccessTime:      time.Now(),\n\t\tMaxExecutionTime:     30 * time.Minute,\n\t\tLastFunctionResponse: make(map[string]any),\n\t\tPlanningComplete:     planningComplete,\n\t\tExecutionPlan:        executionPlan,\n\t\tNextStep:             nextStep,\n\t}\n\n\treturn map[string]any{\n\t\t\"error\":  nil,\n\t\t\"output\": tracker.ToObject(),\n\t}\n}\n\n// Helper function to generate unique task ID\nfunc generateTaskID() string {\n\treturn fmt.Sprintf(\"task_%d\", time.Now().UnixNano())\n}\nfunc ShouldTerminate(tracker *TaskTracker) bool {\n\t// Time-based termination\n\tif time.Since(tracker.StartTime) \u003e tracker.MaxExecutionTime {\n\t\tfmt.Printf(\"‚è∞ Maximum execution time (%v) reached\\n\", tracker.MaxExecutionTime)\n\t\treturn true\n\t}\n\n\t// Task explicitly completed\n\tif tracker.TaskCompleted {\n\t\treturn true\n\t}\n\n\t// Too many empty responses\n\tif tracker.EmptyResponseCount \u003e 10 {\n\t\tfmt.Printf(\"üîá Too many empty AI responses (%d)\\n\", tracker.EmptyResponseCount)\n\t\treturn true\n\t}\n\n\t// Too many conversation resets\n\tif tracker.ConversationResetCount \u003e 5 {\n\t\tfmt.Printf(\"üîÑ Too many conversation resets (%d)\\n\", tracker.ConversationResetCount)\n\t\treturn true\n\t}\n\n\t// Excessive errors without progress\n\tif tracker.ErrorCount \u003e 20 \u0026\u0026 len(tracker.FilesCreated) == 0 \u0026\u0026 len(tracker.CommandsRun) == 0 {\n\t\tfmt.Printf(\"üí• Too many errors (%d) with no tangible progress\\n\", tracker.ErrorCount)\n\t\treturn true\n\t}\n\n\t// Long idle time without meaningful actions\n\tif tracker.IdleTime \u003e 3*time.Minute {\n\t\tfmt.Printf(\"üò¥ No meaningful progress for %v\\n\", tracker.IdleTime)\n\t\treturn true\n\t}\n\n\t// Successful completion indicators\n\tif IsTaskLikelyComplete(tracker) {\n\t\tfmt.Printf(\"üéØ Task appears to be complete based on heuristics\\n\")\n\t\ttracker.TaskCompleted = true\n\t\treturn true\n\t}\n\n\treturn false\n}\n\n// Check if task is likely complete based on heuristics\nfunc IsTaskLikelyComplete(tracker *TaskTracker) bool {\n\t// Basic success patterns\n\tif len(tracker.FilesCreated) \u003e 0 \u0026\u0026 len(tracker.CommandsRun) \u003e 0 \u0026\u0026 tracker.ErrorCount \u003c 3 {\n\t\treturn true\n\t}\n\n\t// Hello world type tasks\n\ttaskLower := strings.ToLower(tracker.Title)\n\tif strings.Contains(taskLower, \"hello\") \u0026\u0026 strings.Contains(taskLower, \"world\") {\n\t\treturn len(tracker.FilesCreated) \u003e 0 || len(tracker.FilesModified) \u003e 0\n\t}\n\n\t// Simple file creation tasks\n\tif strings.Contains(taskLower, \"create\") \u0026\u0026 strings.Contains(taskLower, \"file\") {\n\t\treturn len(tracker.FilesCreated) \u003e 0\n\t}\n\n\t// Build/compile tasks that succeeded\n\tif (strings.Contains(taskLower, \"build\") || strings.Contains(taskLower, \"compile\")) \u0026\u0026 tracker.BuildAttempted {\n\t\treturn len(tracker.FailedCommands) == 0 || tracker.LastSuccessfulCommand != \"\"\n\t}\n\n\treturn false\n}\n\n// Check if we should pause for user input\nfunc ShouldPauseForUserInput(tracker *TaskTracker) bool {\n\t// Don't pause too early\n\tif tracker.Iteration \u003c 5 {\n\t\treturn false\n\t}\n\n\t// Pause if too many dependency errors\n\tif len(tracker.DependencyErrors) \u003e 3 {\n\t\treturn true\n\t}\n\n\t// Pause after many iterations without clear progress\n\tif tracker.Iteration \u003e 15 \u0026\u0026 len(tracker.FilesCreated) == 0 \u0026\u0026 len(tracker.CommandsRun) == 0 {\n\t\treturn true\n\t}\n\n\treturn false\n}\n\nfunc EvaluateTaskCompletionWithErrorAnalysis(tracker *TaskTracker, returns map[string]any, originalTask string) bool {\n\tif tracker.TaskCompleted {\n\t\treturn true\n\t}\n\n\tif tracker.ErrorCount \u003e 10 \u0026\u0026 len(tracker.FilesCreated) \u003e 1 {\n\t\tfmt.Printf(\"‚ö†Ô∏è Too many errors, but files were created. Marking as complete.\\n\")\n\t\treturn true\n\t}\n\n\t// Simple task completion for basic tasks like \"hello world\"\n\ttaskLower := strings.ToLower(originalTask)\n\tif strings.Contains(taskLower, \"hello\") \u0026\u0026 strings.Contains(taskLower, \"world\") {\n\t\tif len(tracker.FilesCreated) \u003e 0 || len(tracker.FilesModified) \u003e 0 {\n\t\t\tfmt.Printf(\"‚úÖ Hello world task complete: file created/modified\\n\")\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif len(tracker.FilesCreated) \u003e= 1 \u0026\u0026 len(tracker.CommandsRun) \u003e 0 {\n\t\tfmt.Printf(\"üóÇÔ∏è Task appears complete: files created and commands executed\\n\")\n\t\treturn true\n\t}\n\n\tif tracker.Iteration \u003e 20 \u0026\u0026 len(tracker.FilesCreated) \u003e 0 \u0026\u0026 len(tracker.CompletedSteps) \u003e 3 {\n\t\tfmt.Printf(\"üî• Auto-completing task due to iteration limit with progress\\n\")\n\t\treturn true\n\t}\n\n\t// Check if AI explicitly marked as complete\n\toutputs, ok := returns[\"output\"].([]map[string]any)\n\tif ok {\n\t\tfor _, output := range outputs {\n\t\t\tif text, ok := output[\"text\"].(string); ok {\n\t\t\t\ttextUpper := strings.ToUpper(text)\n\t\t\t\tif strings.Contains(textUpper, \"TASK_COMPLETE\") ||\n\t\t\t\t\tstrings.Contains(textUpper, \"TASK COMPLETED\") ||\n\t\t\t\t\tstrings.Contains(textUpper, \"SUCCESSFULLY COMPLETED\") {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n",
    "hash": "50fc392c4575ab75717bab2c41f7ce4a",
    "size": 8678,
    "tokens": 2169,
    "modified_time": "2025-12-28T22:01:44.422604741+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "NewTask",
      "generateTaskID",
      "ShouldTerminate",
      "IsTaskLikelyComplete",
      "ShouldPauseForUserInput",
      "EvaluateTaskCompletionWithErrorAnalysis"
    ]
  },
  "6127a5a2ed2ebbd80a412061b2e4ac0d": {
    "path": "internal/repository/agent_repo.go",
    "content": "package repository\n\nimport (\n\t\"encoding/json\"\n\t\"time\"\n)\n\ntype AgentType string\n\nconst (\n\tAgentPlanner      AgentType = \"planner\"\n\tAgentCoder        AgentType = \"coder\"\n\tAgentOrchestrator AgentType = \"orchestrator\"\n\tAgentAnalysis     AgentType = \"analysis\"\n\tAgentInteractor  AgentType = \"interactor\"\n)\n\n// MessageRole represents the role in conversation\ntype MessageRole string\n\nconst (\n\tRoleUser     MessageRole = \"user\"\n\tRoleModel    MessageRole = \"model\"\n\tRoleSystem   MessageRole = \"system\"\n\tRoleFunction MessageRole = \"function\"\n)\n\ntype AgentCapability struct {\n\tName        string            `json:\"name\"`\n\tDescription string            `json:\"description\"`\n\tInputTypes  []string          `json:\"input_types\"` // \"text\", \"image\", \"audio\", \"video\", etc.\n\tOutputTypes []string          `json:\"output_types\"`\n\tParameters  map[string]string `json:\"parameters\"` // Expected parameters and their types\n}\n\ntype AgentMetadata struct {\n\tID           string    `json:\"id\"`\n\tName         string    `json:\"name\"`\n\tVersion      string    `json:\"version\"`\n\tType         AgentType `json:\"type\"`\n\tInstructions string    `json:\"instructions\"`\n\tContext        map[string]any    `json:\"context\"`\n\tLastActive     time.Time         `json:\"last_active\"`\n\tMaxConcurrency int               `json:\"max_concurrency\"`\n\tTimeout        time.Duration     `json:\"timeout\"`\n\tStatus         string            `json:\"status\"`\n\tTags           []string          `json:\"tags\"`\n\tEndpoints      map[string]string `json:\"endpoints\"` // HTTP, gRPC, etc.\n}\n\ntype Agent struct {\n\tMetadata     AgentMetadata `json:\"metadata\"`\n\tCapabilities []Function    `json:\"capabilities\"`\n}\n\nfunc (a *Agent) ToMap() map[string]any {\n\tdata, _ := json.Marshal(a)\n\tvar result map[string]any\n\tjson.Unmarshal(data, \u0026result)\n\treturn result\n}\n\ntype ActiveAgent interface {\n\tRequestAgent(contents []map[string]any) map[string]any\n}\n",
    "hash": "6127a5a2ed2ebbd80a412061b2e4ac0d",
    "size": 1872,
    "tokens": 468,
    "modified_time": "2025-12-28T22:01:44.422469253+05:30",
    "language": "go",
    "imports": [],
    "functions": []
  },
  "8ee2eecbdc4eb8942e8cdae9a3f6c698": {
    "path": "internal/repository/file_upload.go",
    "content": "package repository\n\nimport (\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"mime\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"time\"\n)\n\n// FileUploadResponse represents the Gemini File API response\ntype FileUploadResponse struct {\n\tFile struct {\n\t\tName        string `json:\"name\"`\n\t\tDisplayName string `json:\"displayName\"`\n\t\tMimeType    string `json:\"mimeType\"`\n\t\tSizeBytes   string `json:\"sizeBytes\"`\n\t\tCreateTime  string `json:\"createTime\"`\n\t\tUpdateTime  string `json:\"updateTime\"`\n\t\tURI         string `json:\"uri\"`\n\t\tState       string `json:\"state\"`\n\t} `json:\"file\"`\n}\n\n// FileCacheEntry stores cached file upload info\ntype FileCacheEntry struct {\n\tFileURI     string    `json:\"file_uri\"`\n\tContentHash string    `json:\"content_hash\"`\n\tUploadedAt  time.Time `json:\"uploaded_at\"`\n\tFilePath    string    `json:\"file_path\"`\n}\n\nconst cacheDir = \".dost_cache\"\nconst cacheFile = \"file_cache.json\"\nconst cacheMaxAge = 47 * time.Hour // Gemini keeps files for 48h, refresh at 47h\n\n// hashFile computes SHA-256 hash of a file\nfunc hashFile(path string) (string, error) {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tdefer f.Close()\n\n\th := sha256.New()\n\tif _, err := io.Copy(h, f); err != nil {\n\t\treturn \"\", err\n\t}\n\treturn hex.EncodeToString(h.Sum(nil)), nil\n}\n\n// loadCache reads the local file cache\nfunc loadFileCache() (*FileCacheEntry, error) {\n\tdata, err := os.ReadFile(filepath.Join(cacheDir, cacheFile))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar entry FileCacheEntry\n\tif err := json.Unmarshal(data, \u0026entry); err != nil {\n\t\treturn nil, err\n\t}\n\treturn \u0026entry, nil\n}\n\n// saveCache writes the local file cache\nfunc saveFileCache(entry *FileCacheEntry) error {\n\tos.MkdirAll(cacheDir, 0755)\n\tdata, err := json.MarshalIndent(entry, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.WriteFile(filepath.Join(cacheDir, cacheFile), data, 0644)\n}\n\n// UploadFile uploads a file to the Gemini File API and returns the file URI.\nfunc UploadFile(filePath, apiKey string) (string, error) {\n\tfile, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to open file: %w\", err)\n\t}\n\tdefer file.Close()\n\n\t// Detect MIME type\n\text := filepath.Ext(filePath)\n\tmimeType := mime.TypeByExtension(ext)\n\tif mimeType == \"\" {\n\t\tmimeType = \"text/plain\"\n\t}\n\n\t// Build the upload URL\n\tuploadURL := fmt.Sprintf(\n\t\t\"https://generativelanguage.googleapis.com/upload/v1beta/files?key=%s\",\n\t\tapiKey,\n\t)\n\n\t// Create multipart request ‚Äî Gemini expects raw file body with metadata headers\n\treq, err := http.NewRequest(\"POST\", uploadURL, file)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to create request: %w\", err)\n\t}\n\n\tdisplayName := filepath.Base(filePath)\n\treq.Header.Set(\"Content-Type\", mimeType)\n\treq.Header.Set(\"X-Goog-Upload-Protocol\", \"raw\")\n\treq.Header.Set(\"X-Goog-Upload-Display-Name\", displayName)\n\n\tclient := \u0026http.Client{Timeout: 60 * time.Second}\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"upload request failed: %w\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\tbody, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to read response: %w\", err)\n\t}\n\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn \"\", fmt.Errorf(\"upload failed (HTTP %d): %s\", resp.StatusCode, string(body))\n\t}\n\n\tvar uploadResp FileUploadResponse\n\tif err := json.Unmarshal(body, \u0026uploadResp); err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to parse response: %w\", err)\n\t}\n\n\tif uploadResp.File.URI == \"\" {\n\t\treturn \"\", fmt.Errorf(\"no file URI in response: %s\", string(body))\n\t}\n\n\t// Check if already ACTIVE (small files are often ACTIVE immediately)\n\tif uploadResp.File.State != \"ACTIVE\" \u0026\u0026 uploadResp.File.Name != \"\" {\n\t\tif err := waitForFileActive(uploadResp.File.Name, apiKey); err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"file processing failed: %w\", err)\n\t\t}\n\t}\n\n\treturn uploadResp.File.URI, nil\n}\n\n// FileStatusResponse represents the GET /files/{id} response (flat, not wrapped)\ntype FileStatusResponse struct {\n\tName  string `json:\"name\"`\n\tURI   string `json:\"uri\"`\n\tState string `json:\"state\"`\n}\n\n// waitForFileActive polls the file status until it becomes ACTIVE\nfunc waitForFileActive(fileName, apiKey string) error {\n\tcheckURL := fmt.Sprintf(\n\t\t\"https://generativelanguage.googleapis.com/v1beta/%s?key=%s\",\n\t\tfileName, apiKey,\n\t)\n\n\tclient := \u0026http.Client{Timeout: 10 * time.Second}\n\n\tfor i := 0; i \u003c 30; i++ { // Max 60 seconds (30 * 2s)\n\t\tresp, err := client.Get(checkURL)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to check file status: %w\", err)\n\t\t}\n\n\t\tbody, _ := io.ReadAll(resp.Body)\n\t\tresp.Body.Close()\n\n\t\tvar fileResp FileStatusResponse\n\t\tif err := json.Unmarshal(body, \u0026fileResp); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to parse file status: %w\", err)\n\t\t}\n\n\t\tif fileResp.State == \"ACTIVE\" {\n\t\t\treturn nil\n\t\t}\n\t\tif fileResp.State == \"FAILED\" {\n\t\t\treturn fmt.Errorf(\"file processing failed\")\n\t\t}\n\n\t\tfmt.Printf(\"‚è≥ File processing (%s)...\\n\", fileResp.State)\n\t\ttime.Sleep(2 * time.Second)\n\t}\n\n\treturn fmt.Errorf(\"file processing timed out\")\n}\n\n// GetCachedFileURI returns a cached file URI if available, otherwise uploads and caches.\n// It re-uploads only if the file content has changed or the cached URI has expired.\nfunc GetCachedFileURI(filePath, apiKey string) (string, error) {\n\t// Hash the current file\n\tcurrentHash, err := hashFile(filePath)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to hash file: %w\", err)\n\t}\n\n\t// Check cache\n\tcached, err := loadFileCache()\n\tif err == nil \u0026\u0026 cached.ContentHash == currentHash \u0026\u0026 cached.FilePath == filePath {\n\t\t// Check if URI is still valid (less than 47 hours old)\n\t\tif time.Since(cached.UploadedAt) \u003c cacheMaxAge {\n\t\t\tfmt.Println(\"üìé Using cached context file (no changes detected)\")\n\t\t\treturn cached.FileURI, nil\n\t\t}\n\t\tfmt.Println(\"üìé Context cache expired, re-uploading...\")\n\t} else if err == nil \u0026\u0026 cached.ContentHash != currentHash {\n\t\tfmt.Println(\"üìé Context changed, re-uploading...\")\n\t}\n\n\t// Upload the file\n\tfmt.Printf(\"üì§ Uploading context file: %s\\n\", filepath.Base(filePath))\n\tfileURI, err := UploadFile(filePath, apiKey)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tfmt.Println(\"‚úÖ Context file uploaded successfully\")\n\n\t// Save to cache\n\tcacheEntry := \u0026FileCacheEntry{\n\t\tFileURI:     fileURI,\n\t\tContentHash: currentHash,\n\t\tUploadedAt:  time.Now(),\n\t\tFilePath:    filePath,\n\t}\n\tif err := saveFileCache(cacheEntry); err != nil {\n\t\tfmt.Printf(\"‚ö†Ô∏è  Warning: could not save cache: %v\\n\", err)\n\t}\n\n\treturn fileURI, nil\n}\n",
    "hash": "8ee2eecbdc4eb8942e8cdae9a3f6c698",
    "size": 6451,
    "tokens": 1612,
    "modified_time": "2026-02-10T20:27:09.571489876+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "hashFile",
      "loadFileCache",
      "saveFileCache",
      "UploadFile",
      "waitForFileActive",
      "GetCachedFileURI"
    ]
  },
  "b677dd8ed10b15b8a7a68eb42ac0713c": {
    "path": "testings/main.c",
    "content": "/*\n *  Simple 3D cube rendering application using DirectX 11.\n */\n#include \u003cwindows.h\u003e\n#include \u003cd3d11.h\u003e\n#include \u003cd3dcompiler.h\u003e\n#include \u003cDirectXMath.h\u003e\n\n// Window parameters\n#define WINDOW_WIDTH 800\n#define WINDOW_HEIGHT 600\n\n// Direct3D device and context\nID3D11Device* g_pd3dDevice = nullptr;\nID3D11DeviceContext* g_pImmediateContext = nullptr;\n\n// Swap chain\nIDXGISwapChain* g_pSwapChain = nullptr;\n\n// Render target view\nID3D11RenderTargetView* g_pRenderTargetView = nullptr;\n\n// Vertex shader\nID3D11VertexShader* g_pVertexShader = nullptr;\n\n// Pixel shader\nID3D11PixelShader* g_pPixelShader = nullptr;\n\n// Input layout\nID3D11InputLayout* g_pInputLayout = nullptr;\n\n// Vertex buffer\nID3D11Buffer* g_pVertexBuffer = nullptr;\n\n// Constant buffer\nID3D11Buffer* g_pConstantBuffer = nullptr;\n\n// Cube vertices\nstruct Vertex {\n    DirectX::XMFLOAT3 Pos;\n    DirectX::XMFLOAT4 Color;\n};\n\nVertex g_Vertices[] = {\n    { {-1.0f, 1.0f, -1.0f}, {1.0f, 0.0f, 0.0f, 1.0f} },\n    { {1.0f, 1.0f, -1.0f}, {0.0f, 1.0f, 0.0f, 1.0f} },\n    { {1.0f, 1.0f, 1.0f}, {0.0f, 0.0f, 1.0f, 1.0f} },\n    { {-1.0f, 1.0f, 1.0f}, {1.0f, 1.0f, 0.0f, 1.0f} },\n    { {-1.0f, -1.0f, -1.0f}, {1.0f, 0.0f, 1.0f, 1.0f} },\n    { {1.0f, -1.0f, -1.0f}, {0.0f, 1.0f, 1.0f, 1.0f} },\n    { {1.0f, -1.0f, 1.0f}, {0.0f, 0.0f, 0.0f, 1.0f} },\n    { {-1.0f, -1.0f, 1.0f}, {1.0f, 1.0f, 1.0f, 1.0f} }\n};\n\nunsigned int g_Indices[] = {\n    0, 1, 2,\n    0, 2, 3,\n    4, 5, 6,\n    4, 6, 7,\n    0, 4, 7,\n    0, 7, 3,\n    1, 5, 6,\n    1, 6, 2,\n    0, 1, 5,\n    0, 5, 4,\n    2, 3, 7,\n    2, 7, 6\n};\n\n// Constant buffer structure\nstruct ConstantBuffer {\n    DirectX::XMMATRIX World;\n    DirectX::XMMATRIX View;\n    DirectX::XMMATRIX Projection;\n};\n\n// Function prototypes\nHRESULT InitD3D(HWND hWnd);\nvoid Render();\nvoid CleanupD3D();\nHRESULT CompileShader(const char* szFileName, LPCSTR szEntryPoint, LPCSTR szShaderModel, ID3DBlob** ppBlobOut);\n\nLRESULT CALLBACK WindowProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam);\n\n// Function to multiply two matrices\nvoid MultiplyMatrices(float* result, const float* mat1, const float* mat2, int rows1, int cols1, int cols2) {\n    for (int i = 0; i \u003c rows1; ++i) {\n        for (int j = 0; j \u003c cols2; ++j) {\n            result[i * cols2 + j] = 0.0f;\n            for (int k = 0; k \u003c cols1; ++k) {\n                result[i * cols2 + j] += mat1[i * cols1 + k] * mat2[k * cols2 + j];\n            }\n        }\n    }\n}\n\nint WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int nCmdShow) {\n    // Register window class\n    WNDCLASSEX wc = { 0 };\n    wc.cbSize = sizeof(WNDCLASSEX);\n    wc.style = CS_HREDRAW | CS_VREDRAW;\n    wc.lpfnWndProc = WindowProc;\n    wc.hInstance = hInstance;\n    wc.hCursor = LoadCursor(NULL, IDC_ARROW);\n    wc.hbrBackground = (HBRUSH)(COLOR_WINDOW + 1);\n    wc.lpszClassName = \"CubeWindowClass\";\n    RegisterClassEx(\u0026wc);\n\n    // Create window\n    HWND hWnd = CreateWindowEx(0,\n        \"CubeWindowClass\",\n        \"3D Cube\",\n        WS_OVERLAPPEDWINDOW,\n        CW_USEDEFAULT, CW_USEDEFAULT, WINDOW_WIDTH, WINDOW_HEIGHT, NULL, NULL, hInstance, NULL);\n\n    if (!hWnd) {\n        return 0;\n    }\n\n    ShowWindow(hWnd, nCmdShow);\n\n    // Initialize Direct3D\n    if (FAILED(InitD3D(hWnd))) {\n        return 0;\n    }\n\n    // Main message loop\n    MSG msg;\n    while (GetMessage(\u0026msg, NULL, 0, 0)) {\n        TranslateMessage(\u0026msg);\n        DispatchMessage(\u0026msg);\n    }\n\n    CleanupD3D();\n\n    return 0;\n}\n\nLRESULT CALLBACK WindowProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam) {\n    switch (message) {\n    case WM_DESTROY:\n        PostQuitMessage(0);\n        break;\n    case WM_PAINT:\n        Render();\n        break;\n    default:\n        return DefWindowProc(hWnd, message, wParam, lParam);\n    }\n    return 0;\n}\n\nHRESULT InitD3D(HWND hWnd) {\n    // ... (Direct3D initialization code)\n    return S_OK;\n}\n\nvoid Render() {\n    // ... (Rendering code)\n}\n\nvoid CleanupD3D() {\n    // ... (Cleanup code)\n}\n\nHRESULT CompileShader(const char* szFileName, LPCSTR szEntryPoint, LPCSTR szShaderModel, ID3DBlob** ppBlobOut) {\n    // ... (Shader compilation code)\n    return S_OK;\n}\n",
    "hash": "b677dd8ed10b15b8a7a68eb42ac0713c",
    "size": 4122,
    "tokens": 1030,
    "modified_time": "2025-12-28T23:23:15.656868138+05:30",
    "language": "c",
    "imports": [],
    "functions": []
  },
  "ca1cd77199dd74f5750c153160b5d55c": {
    "path": "internal/service/planner/planner.go",
    "content": "package planner\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"context\"\n\t\"dost/internal/repository\"\n\t\"dost/internal/service/analysis\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"time\"\n\n\tgitignore \"github.com/sabhiram/go-gitignore\"\n\n\t\"github.com/spf13/viper\"\n)\n\nvar ignoreMatcher *gitignore.GitIgnore\nvar PlannertoolsFunc map[string]repository.Function = make(map[string]repository.Function)\n\nvar ChatHistory = make([]map[string]any, 0)\nvar defaultIgnore = map[string]bool{\n\t\".git\":         true,\n\t\"node_modules\": true,\n\t\"vendor\":       true,\n\t\".venv\":        true,\n\t\".env\":         true,\n\t\".idea\":        true,\n\t\".vscode\":      true,\n\t\"__pycache__\":  true,\n\t\".dost\":        true,\n}\n\ntype Plans struct {\n\tPlanID          string   `json:\"planId\"`\n\tTitle           string   `json:\"title\"`\n\tObjective       string   `json:\"objective\"`\n\tAssumptions     []string `json:\"assumptions\"`\n\tSteps           []Step   `json:\"steps\"`\n\tSuccessCriteria []string `json:\"successCriteria\"`\n\tFallbacks       []string `json:\"fallbacks\"`\n}\n\n// Step represents an individual step in the plan.\ntype Step struct {\n\tID           int      `json:\"id\"`\n\tDescription  string   `json:\"description\"`\n\tAgent        string   `json:\"agent\"`\n\tInputs       []string `json:\"inputs\"`\n\tOutputs      []string `json:\"outputs\"`\n\tDependencies []int    `json:\"dependencies\"`\n}\n\n// Global storage for plans\nvar PlansMap = make(map[string]Plans, 0)\n\ntype AgentPlanner repository.Agent\n\ntype InitialContext struct {\n\tOS              string\n\tArch            string\n\tUser            string\n\tShell           string\n\tCWD             string\n\tGoVersion       string\n\tFolderStructure map[string]any\n\tInstalledTools  []string\n\tEnvVars         map[string]string\n\tProjectFiles    []string\n\tProjectType     string\n\tGitBranch       string\n\tInternetAccess  bool\n\tAgentRole       string\n\tCapabilities    []string\n\tTimezone        string\n\tSessionID       string\n}\n\nfunc GetInitialContext() InitialContext {\n\tctx := InitialContext{\n\t\tOS:              runtime.GOOS,\n\t\tArch:            runtime.GOARCH,\n\t\tUser:            os.Getenv(\"USERNAME\"),\n\t\tShell:           detectDefaultShell(),\n\t\tCWD:             mustGetWorkingDir(),\n\t\tFolderStructure: GetProjectStructure(map[string]any{\"path\": \"./\"}),\n\t\tGoVersion:       runtime.Version(),\n\t\tInstalledTools:  detectTools(),\n\t\tEnvVars:         getImportantEnvVars(),\n\t\tProjectFiles:    scanProjectFiles(),\n\t\tProjectType:     detectProjectType(),\n\t\tGitBranch:       getGitBranch(),\n\t\tInternetAccess:  checkInternet(),\n\t\tTimezone:        getLocalTimezone(),\n\t\tSessionID:       generateSessionID(),\n\t}\n\treturn ctx\n}\nfunc GetProjectStructure(args map[string]any) map[string]any {\n\tloadGitIgnore()\n\tpath := args[\"path\"].(string)\n\tvar builder strings.Builder\n\tbuilder.WriteString(path + \"\\n\")\n\terr := getProjectStructureRecursive(path, \"\", \u0026builder)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err, \"output\": nil}\n\t}\n\n\tif builder.String() == \".\" || builder.String() == \"\" {\n\t\treturn map[string]any{\"error\": nil, \"output\": \"\u003cempty directory\u003e\"}\n\t}\n\treturn map[string]any{\"error\": nil, \"output\": builder.String()}\n}\nfunc getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {\n\tentries, err := os.ReadDir(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor i, entry := range entries {\n\t\tentryPath := filepath.Join(path, entry.Name())\n\n\t\t// skip ignored entries\n\t\tif ignoreMatcher != nil {\n\t\t\trelPath, _ := filepath.Rel(\".\", entryPath)\n\t\t\tif ignoreMatcher.MatchesPath(relPath) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t} else if defaultIgnore[entry.Name()] {\n\t\t\tcontinue\n\t\t}\n\n\t\t// draw branch\n\t\tconnector := \"‚îú‚îÄ‚îÄ\"\n\t\tif i == len(entries)-1 {\n\t\t\tconnector = \"‚îî‚îÄ‚îÄ\"\n\t\t}\n\t\tbuilder.WriteString(prefix + connector + \" \" + entry.Name() + \"\\n\")\n\n\t\t// recursively descend\n\t\tif entry.IsDir() {\n\t\t\tsubPrefix := prefix\n\t\t\tif i == len(entries)-1 {\n\t\t\t\tsubPrefix += \"    \"\n\t\t\t} else {\n\t\t\t\tsubPrefix += \"‚îÇ   \"\n\t\t\t}\n\t\t\terr := getProjectStructureRecursive(entryPath, subPrefix, builder)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc loadGitIgnore() {\n\tif _, err := os.Stat(\".gitignore\"); err == nil {\n\t\tignoreMatcher, _ = gitignore.CompileIgnoreFile(\".gitignore\")\n\t}\n}\nfunc detectDefaultShell() string {\n\tif runtime.GOOS == \"windows\" {\n\t\t// prefer PowerShell if present\n\t\tif _, err := exec.LookPath(\"powershell\"); err == nil {\n\t\t\treturn \"powershell\"\n\t\t}\n\t\treturn \"cmd\"\n\t}\n\treturn os.Getenv(\"SHELL\")\n}\n\nfunc mustGetWorkingDir() string {\n\tdir, err := os.Getwd()\n\tif err != nil {\n\t\treturn \".\"\n\t}\n\treturn dir\n}\n\nfunc detectTools() []string {\n\tvar found []string\n\tval := os.Getenv(\"PATH\")\n\tfound = strings.Split(val, \";\")\n\treturn found\n}\n\nfunc getImportantEnvVars() map[string]string {\n\tkeys := []string{\"PATH\", \"GOROOT\", \"GOPATH\", \"JAVA_HOME\"}\n\tenv := make(map[string]string)\n\tfor _, k := range keys {\n\t\tif v := os.Getenv(k); v != \"\" {\n\t\t\tenv[k] = v\n\t\t}\n\t}\n\treturn env\n}\n\nfunc scanProjectFiles() []string {\n\tfiles := []string{}\n\tfilepath.Walk(\".\", func(path string, info os.FileInfo, err error) error {\n\t\tif err == nil \u0026\u0026 !info.IsDir() {\n\t\t\tif strings.HasSuffix(path, \".go\") ||\n\t\t\t\tpath == \"go.mod\" || path == \"package.json\" || path == \"requirements.txt\" ||\n\t\t\t\tpath == \"Dockerfile\" || path == \"README.md\" {\n\t\t\t\tfiles = append(files, path)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn files\n}\n\nfunc detectProjectType() string {\n\tif _, err := os.Stat(\"go.mod\"); err == nil {\n\t\treturn \"Go project\"\n\t}\n\tif _, err := os.Stat(\"package.json\"); err == nil {\n\t\treturn \"Node.js project\"\n\t}\n\tif _, err := os.Stat(\"requirements.txt\"); err == nil {\n\t\treturn \"Python project\"\n\t}\n\treturn \"Unknown\"\n}\n\nfunc getGitBranch() string {\n\tcmd := exec.Command(\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\")\n\tout, err := cmd.Output()\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\treturn strings.TrimSpace(string(out))\n}\n\nfunc checkInternet() bool {\n\tcmd := exec.Command(\"ping\", \"-c\", \"1\", \"8.8.8.8\")\n\tif runtime.GOOS == \"windows\" {\n\t\tcmd = exec.Command(\"ping\", \"-n\", \"1\", \"8.8.8.8\")\n\t}\n\tif err := cmd.Run(); err != nil {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc getLocalTimezone() string {\n\t_, tz := time.Now().Zone()\n\treturn fmt.Sprintf(\"%d min offset\", tz/60)\n}\n\nfunc generateSessionID() string {\n\treturn fmt.Sprintf(\"%d\", time.Now().UnixNano())\n}\n\n// Helper function to format files for Orchestrator\nfunc formatFilesForOrchestrator(filesRead map[string]any) string {\n\tif len(filesRead) == 0 {\n\t\treturn \"\"\n\t}\n\n\tvar result strings.Builder\n\tresult.WriteString(\"=== FILES CONTENT ===\\n\\n\")\n\n\tfor fileName, fileData := range filesRead {\n\t\tresult.WriteString(fmt.Sprintf(\"FILE: %s\\n\", fileName))\n\t\tresult.WriteString(\"=\" + strings.Repeat(\"=\", len(fileName)+6) + \"\\n\")\n\n\t\tif chunks, ok := fileData.([]map[string]any); ok {\n\t\t\tfor _, chunk := range chunks {\n\t\t\t\tif content, exists := chunk[\"content\"].(string); exists {\n\t\t\t\t\tresult.WriteString(content)\n\t\t\t\t\tresult.WriteString(\"\\n\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tresult.WriteString(\"\\n\" + strings.Repeat(\"-\", 50) + \"\\n\\n\")\n\t}\n\n\treturn result.String()\n}\n\nfunc (p *AgentPlanner) Interaction(args map[string]any) map[string]any {\n\tInitialContext := GetInitialContext()\n\tInitialContextBytes, err := json.Marshal(InitialContext)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": \"Unable to get initial context\"}\n\t}\n\n\tvar userMessage strings.Builder\n\n\t// Add files content (from analysis)\n\tfilesContent := formatFilesForOrchestrator(analysis.FilesRead)\n\tif filesContent != \"\" {\n\t\tuserMessage.WriteString(filesContent)\n\t\tuserMessage.WriteString(\"\\n\")\n\t}\n\n\t// Add initial context\n\tuserMessage.WriteString(\"=== INITIAL CONTEXT ===\\n\")\n\tuserMessage.WriteString(string(InitialContextBytes))\n\tuserMessage.WriteString(\"\\n\\n\")\n\n\t// Add query\n\tuserMessage.WriteString(\"=== QUERY ===\\n\")\n\tif query, ok := args[\"query\"].(string); ok {\n\t\tuserMessage.WriteString(query)\n\t}\n\tlog.Println(\"TEST: ORCHESTRATOR:  \", userMessage.String()[0:20])\n\n\t// Push consolidated user message into ChatHistory\n\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\"role\": \"user\",\n\t\t\"parts\": []map[string]any{\n\t\t\t{\"text\": userMessage.String()},\n\t\t},\n\t})\n\n\tfor {\n\t\t// fmt.Println(\"Current ChatHistory:\", ChatHistory)\n\t\tif ChatHistory[len(ChatHistory)-1][\"role\"] == \"model\" {\n\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\"role\": \"user\",\n\t\t\t\t\"parts\": map[string]any{\n\t\t\t\t\t\"text\": \"If you feel there is not task left and nothing to do , call exit-process. Because only that can stop you and finish the program. Don't Respond with text , No text output should be there , call the exit-process. PERIOD\",\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\t\toutput := p.RequestAgent(ChatHistory)\n\n\t\tif output[\"error\"] != nil {\n\t\t\tfmt.Println(\"Error:\", output[\"error\"])\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\toutputData, ok := output[\"output\"].([]map[string]any)\n\t\tif !ok {\n\t\t\tfmt.Println(\"ERROR CONVERTING OUTPUT\")\n\t\t\treturn nil\n\t\t}\n\n\t\tif len(outputData) == 0 {\n\t\t\tfmt.Println(\"No output received\")\n\t\t\tcontinue\n\t\t}\n\n\t\t// Process each output part\n\t\tfor _, part := range outputData {\n\t\t\tpartType, hasType := part[\"type\"].(string)\n\t\t\tif !hasType {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif partType == \"text\" {\n\t\t\t\t// Handle text response\n\t\t\t\tif text, ok := part[\"data\"].(string); ok {\n\t\t\t\t\tfmt.Println(\"Agent:\", text)\n\t\t\t\t}\n\t\t\t} else if partType == \"functionCall\" {\n\t\t\t\t// Handle function call\n\t\t\t\tname, nameOK := part[\"name\"].(string)\n\t\t\t\targsData, argsOK := part[\"args\"].(map[string]any)\n\n\t\t\t\tif !nameOK || !argsOK {\n\t\t\t\t\tfmt.Println(\"Error: invalid function call data\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tfmt.Println(\"Calling function:\", name)\n\n\t\t\t\t// Execute the function\n\t\t\t\tif function, exists := PlannertoolsFunc[name]; exists {\n\t\t\t\t\tresult := function.Run(argsData)\n\t\t\t\t\tfmt.Println(result)\n\t\t\t\t\tif _, ok = result[\"exit\"].(bool); ok {\n\n\t\t\t\t\t\treturn map[string]any{}\n\t\t\t\t\t}\n\t\t\t\t\t// Add function response to chat history\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"functionResponse\": map[string]any{\n\t\t\t\t\t\t\t\t\t\"name\":     name,\n\t\t\t\t\t\t\t\t\t\"response\": result,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\n\t\t\t\t\t// Display result if it's a string\n\t\t\t\t\tif outputStr, ok := result[\"output\"].(string); ok {\n\t\t\t\t\t\tfmt.Println(\"Result:\", outputStr)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfmt.Printf(\"Function %s not found\\n\", name)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Continue the conversation loop\n\t\tfmt.Println(\"---\")\n\t}\n}\n\nfunc (c *AgentPlanner) RequestAgent(contents []map[string]any) map[string]any {\n\tfmt.Printf(\"Processing request with Planner Agent: %s\\n\", c.Metadata.Name)\n\n\t// Build request payload\n\trequest := map[string]any{\n\t\t\"systemInstruction\": map[string]any{\n\t\t\t\"parts\": []map[string]any{\n\t\t\t\t{\"text\": c.Metadata.Instructions},\n\t\t\t},\n\t\t},\n\t\t\"toolConfig\": map[string]any{\n\t\t\t\"functionCallingConfig\": map[string]any{\n\t\t\t\t\"mode\": \"ANY\",\n\t\t\t},\n\t\t},\n\t\t\"contents\": contents,\n\t\t\"tools\": []map[string]any{\n\t\t\t{\"functionDeclarations\": GetPlannerArrayMap()},\n\t\t},\n\t}\n\n\t// Marshal request body\n\tjsonBody, err := json.Marshal(request)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t}\n\n\t// Retry config\n\tconst maxRetries = 5\n\tconst maxWaitTime = 10 * time.Minute\n\n\tfor attempt := 0; attempt \u003c= maxRetries; attempt++ {\n\t\t// Create HTTP request\n\t\treq, err := http.NewRequestWithContext(\n\t\t\tcontext.Background(),\n\t\t\t\"POST\",\n\t\t\tc.Metadata.Endpoints[\"http\"],\n\t\t\tbytes.NewBuffer(jsonBody),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t}\n\n\t\treq.Header.Set(\"Content-Type\", \"application/json\")\n\t\treq.Header.Set(\"X-goog-api-key\", viper.GetString(\"PLANNER.API_KEY\"))\n\n\t\t// Execute request with timeout\n\t\tclient := repository.NewStreamingHTTPClient()\n\t\tresp, err := client.Do(req)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\t\tdefer resp.Body.Close()\n\n\t\t// Success case - parse streaming response\n\t\tif resp.StatusCode == http.StatusOK {\n\t\t\t// Parse SSE stream with real-time display\n\t\t\tstreamResp, err := repository.ParseSSEStream(resp.Body, true)\n\t\t\tif err != nil {\n\t\t\t\tif attempt == maxRetries {\n\t\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t\t}\n\t\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Convert to standard output format\n\t\t\toutput := repository.ConvertStreamResponseToOutput(streamResp)\n\n\t\t\t// Save chat history\n\t\t\thistoryEntry := repository.BuildChatHistoryFromStream(streamResp, \"planner\")\n\t\t\tif historyEntry != nil {\n\t\t\t\tChatHistory = append(ChatHistory, historyEntry)\n\t\t\t}\n\n\t\t\tc.Metadata.LastActive = time.Now()\n\t\t\treturn map[string]any{\"error\": nil, \"output\": output}\n\t\t}\n\n\t\t// Read body for error cases\n\t\tbodyBytes, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Handle rate limits\n\t\tif resp.StatusCode == http.StatusTooManyRequests {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Rate limit exceeded after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\t\t\tretryDelay := repository.ParseRetryDelay(string(bodyBytes))\n\t\t\twaitTime := retryDelay\n\t\t\tif waitTime \u003c= 0 {\n\t\t\t\twaitTime = repository.ExponentialBackoff(attempt)\n\t\t\t}\n\t\t\tif waitTime \u003e maxWaitTime {\n\t\t\t\twaitTime = maxWaitTime\n\t\t\t}\n\t\t\tfmt.Printf(\"Rate limit hit (attempt %d/%d). Waiting %v before retry...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, waitTime)\n\t\t\ttime.Sleep(waitTime)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Retry on server errors\n\t\tif resp.StatusCode \u003e= 500 \u0026\u0026 resp.StatusCode \u003c 600 {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Server error after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Printf(\"Server error (attempt %d/%d). Waiting %v before retry...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, repository.ExponentialBackoff(attempt))\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Client errors (400‚Äì499) except 429 ‚Üí don't retry\n\t\treturn map[string]any{\n\t\t\t\"error\":  fmt.Sprintf(\"HTTP %d: %s\", resp.StatusCode, string(bodyBytes)),\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"error\":  fmt.Sprintf(\"Max retries (%d) exceeded\", maxRetries),\n\t\t\"output\": nil,\n\t}\n}\n\nfunc (p *AgentPlanner) NewAgent() {\n\tmodel := viper.GetString(\"PLANNER.MODEL\")\n\tif model == \"\" {\n\t\tmodel = \"gemini-1.5-pro\"\n\t}\n\n\tinstructions := repository.PlannerInstructions\n\n\tPlannerAgentMeta := repository.AgentMetadata{\n\t\tID:             \"Planner-agent-v1\",\n\t\tName:           \"Planner Agent\",\n\t\tVersion:        \"1.0.0\",\n\t\tType:           repository.AgentType(repository.AgentPlanner),\n\t\tInstructions:   instructions,\n\t\tLastActive:     time.Now(),\n\t\tMaxConcurrency: 5,\n\t\tTimeout:        30 * time.Second,\n\t\tStatus:         \"active\",\n\t\tTags:           []string{\"Planner\", \"constraints\", \"inputs\", \"outputs\", \"validation\"},\n\t\tEndpoints: map[string]string{\n\t\t\t\"http\": fmt.Sprintf(\"https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse\", model),\n\t\t},\n\t}\n\n\tp.Metadata = PlannerAgentMeta\n\tp.Capabilities = PlannerCapabilities\n\tPlannertoolsFunc = make(map[string]repository.Function)\n\tfor _, tool := range PlannerCapabilities {\n\t\tPlannertoolsFunc[tool.Name] = tool\n\t}\n}\n\nfunc GetPlannerArrayMap() []map[string]any {\n\tarrayOfMap := make([]map[string]any, 0)\n\tfor _, v := range PlannerCapabilities {\n\t\tarrayOfMap = append(arrayOfMap, v.ToObject())\n\t}\n\treturn arrayOfMap\n}\n\n// GenerateTasklist will take input from user and generate a tasklist and return to user\nfunc GenerateTasklist(args map[string]any) map[string]any {\n\tname, ok := args[\"name\"].(string)\n\tinstructions, ok2 := args[\"instructions\"].(string)\n\n\tif !ok || !ok2 {\n\t\treturn map[string]any{\"error\": \"insufficient parameters\"}\n\t}\n\treturn map[string]any{\"output\": \"Tasklist name is \" + name + \" tasklist instructions are \" + instructions}\n}\n\n// Key changes to make planner agent return output like coder agent:\n\n// 1. Add an exit-process function to PlannerCapabilities\n\n// Enhanced validation and error handling\nfunc PutPlanForAgent(args map[string]any) map[string]any {\n\tlog.Printf(\"DEBUG: Received args for PutPlanForAgent: %+v\", args)\n\n\t// Check if args is empty or nil\n\tif args == nil || len(args) == 0 {\n\t\treturn map[string]any{\n\t\t\t\"success\": false,\n\t\t\t\"error\":   \"No parameters provided. I need you to call gather-plan-requirements first to collect the necessary information.\",\n\t\t\t\"action\":  \"call gather-plan-requirements function to collect plan details from user\",\n\t\t}\n\t}\n\n\t// Create Plans struct directly from args (no nested \"plan\" object)\n\tvar plan Plans\n\n\t// Extract title\n\tif title, ok := args[\"title\"].(string); ok {\n\t\tplan.Title = title\n\t}\n\n\t// Extract objective\n\tif objective, ok := args[\"objective\"].(string); ok {\n\t\tplan.Objective = objective\n\t}\n\n\t// Extract planId (optional)\n\tif planId, ok := args[\"planId\"].(string); ok {\n\t\tplan.PlanID = planId\n\t}\n\n\t// Extract steps\n\tif stepsData, ok := args[\"steps\"].([]any); ok {\n\t\tfor i, stepData := range stepsData {\n\t\t\tif stepMap, ok := stepData.(map[string]any); ok {\n\t\t\t\tstep := Step{\n\t\t\t\t\tID: i + 1, // Auto-assign ID\n\t\t\t\t}\n\n\t\t\t\tif desc, ok := stepMap[\"description\"].(string); ok {\n\t\t\t\t\tstep.Description = desc\n\t\t\t\t}\n\n\t\t\t\tif agent, ok := stepMap[\"agent\"].(string); ok {\n\t\t\t\t\tstep.Agent = agent\n\t\t\t\t} else {\n\t\t\t\t\tstep.Agent = \"GeneralAgent\" // Default agent\n\t\t\t\t}\n\n\t\t\t\t// Handle inputs array\n\t\t\t\tif inputs, ok := stepMap[\"inputs\"].([]any); ok {\n\t\t\t\t\tfor _, input := range inputs {\n\t\t\t\t\t\tif inputStr, ok := input.(string); ok {\n\t\t\t\t\t\t\tstep.Inputs = append(step.Inputs, inputStr)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Handle outputs array\n\t\t\t\tif outputs, ok := stepMap[\"outputs\"].([]any); ok {\n\t\t\t\t\tfor _, output := range outputs {\n\t\t\t\t\t\tif outputStr, ok := output.(string); ok {\n\t\t\t\t\t\t\tstep.Outputs = append(step.Outputs, outputStr)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Handle dependencies array\n\t\t\t\tif deps, ok := stepMap[\"dependencies\"].([]any); ok {\n\t\t\t\t\tfor _, dep := range deps {\n\t\t\t\t\t\tif depInt, ok := dep.(float64); ok {\n\t\t\t\t\t\t\tstep.Dependencies = append(step.Dependencies, int(depInt))\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tplan.Steps = append(plan.Steps, step)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Extract assumptions (optional)\n\tif assumptions, ok := args[\"assumptions\"].([]any); ok {\n\t\tfor _, assumption := range assumptions {\n\t\t\tif assumptionStr, ok := assumption.(string); ok {\n\t\t\t\tplan.Assumptions = append(plan.Assumptions, assumptionStr)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Extract successCriteria (optional)\n\tif criteria, ok := args[\"successCriteria\"].([]any); ok {\n\t\tfor _, criterion := range criteria {\n\t\t\tif criterionStr, ok := criterion.(string); ok {\n\t\t\t\tplan.SuccessCriteria = append(plan.SuccessCriteria, criterionStr)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Extract fallbacks (optional)\n\tif fallbacks, ok := args[\"fallbacks\"].([]any); ok {\n\t\tfor _, fallback := range fallbacks {\n\t\t\tif fallbackStr, ok := fallback.(string); ok {\n\t\t\t\tplan.Fallbacks = append(plan.Fallbacks, fallbackStr)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Generate unique plan ID if not provided\n\tif plan.PlanID == \"\" {\n\t\tplan.PlanID = fmt.Sprintf(\"plan_%d\", time.Now().Unix())\n\t}\n\n\t// Enhanced validation with specific guidance\n\tvalidationErrors := []string{}\n\n\tif plan.Title == \"\" {\n\t\tvalidationErrors = append(validationErrors, \"Missing required field: 'title'\")\n\t}\n\n\tif plan.Objective == \"\" {\n\t\tvalidationErrors = append(validationErrors, \"Missing required field: 'objective'\")\n\t}\n\n\tif len(plan.Steps) == 0 {\n\t\tvalidationErrors = append(validationErrors, \"Missing required field: 'steps' (must have at least one step)\")\n\t}\n\n\tif len(validationErrors) \u003e 0 {\n\t\treturn map[string]any{\n\t\t\t\"success\": false,\n\t\t\t\"error\":   \"Plan validation failed: \" + strings.Join(validationErrors, \", \"),\n\t\t\t\"requirements\": []string{\n\t\t\t\t\"title: A descriptive name for your plan\",\n\t\t\t\t\"objective: A clear statement of what this plan achieves\",\n\t\t\t\t\"steps: An array of at least one step with 'description' field\",\n\t\t\t},\n\t\t\t\"example\": `{\n  \"plan\": {\n    \"title\": \"Setup Development Environment\",\n    \"objective\": \"Configure a complete development environment for the project\",\n    \"steps\": [\n      {\n        \"description\": \"Install required dependencies\",\n        \"agent\": \"SystemAgent\"\n      },\n      {\n        \"description\": \"Configure database connection\", \n        \"agent\": \"DatabaseAgent\"\n      }\n    ]\n  }\n}`,\n\t\t}\n\t}\n\n\t// Validate and fix steps\n\tfor i, step := range plan.Steps {\n\t\tif step.Description == \"\" {\n\t\t\treturn map[string]any{\n\t\t\t\t\"success\": false,\n\t\t\t\t\"error\":   fmt.Sprintf(\"Step %d is missing required 'description' field\", i+1),\n\t\t\t\t\"hint\":    \"Each step must have a clear description of what should be done\",\n\t\t\t}\n\t\t}\n\n\t\t// Auto-assign agent if missing\n\t\tif step.Agent == \"\" {\n\t\t\tplan.Steps[i].Agent = \"GeneralAgent\"\n\t\t}\n\n\t\t// Auto-assign ID if missing\n\t\tif step.ID == 0 {\n\t\t\tplan.Steps[i].ID = i + 1\n\t\t}\n\t}\n\n\t// Store the plan\n\tPlansMap[plan.PlanID] = plan\n\n\t// Return successful response\n\treturn map[string]any{\n\t\t\"success\": true,\n\t\t\"planId\":  plan.PlanID,\n\t\t\"message\": fmt.Sprintf(\"Plan '%s' created successfully with %d steps\", plan.Title, len(plan.Steps)),\n\t\t\"plan\":    plan,\n\t}\n}\nfunc getKeys(m map[string]any) []string {\n\tkeys := make([]string, 0, len(m))\n\tfor k := range m {\n\t\tkeys = append(keys, k)\n\t}\n\treturn keys\n}\n\nfunc ExitProcess(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\tfmt.Println(text)\n\t}\n\tmarshabData, err := json.Marshal(PlansMap)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error()}\n\t}\n\n\treturn map[string]any{\"error\": nil, \"output\": string(marshabData), \"exit\": true}\n}\n\nfunc TakeInputFromTerminal(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"No Text Provided\"}\n\t}\n\tfmt.Println(text)\n\n\trequirements, ok := args[\"requirements\"].([]any)\n\treader := bufio.NewReader(os.Stdin)\n\n\t// Case 1: No requirements -\u003e just take a single input\n\tif !ok || len(requirements) == 0 {\n\t\tfmt.Print(\"dost\u003e \")\n\t\tinput, err := reader.ReadString('\\n')\n\t\tif err != nil {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  fmt.Sprintf(\"Error reading input: %v\", err),\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\t\tinput = strings.TrimSpace(input)\n\t\tif input == \"\" {\n\t\t\treturn map[string]any{\"error\": nil, \"output\": \"\u003cno input provided\u003e\"}\n\t\t}\n\t\treturn map[string]any{\"error\": nil, \"output\": input}\n\t}\n\n\t// Case 2: Requirements exist -\u003e ask each question\n\tresults := make(map[string]string)\n\tfor _, req := range requirements {\n\t\tquestion, ok := req.(string)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tfmt.Printf(\"dost\u003e %s: \", question)\n\t\tinput, err := reader.ReadString('\\n')\n\t\tif err != nil {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  fmt.Sprintf(\"Error reading input: %v\", err),\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\n\t\tinput = strings.TrimSpace(input)\n\t\tif input == \"\" {\n\t\t\tresults[question] = \"\u003cno input provided\u003e\"\n\t\t} else {\n\t\t\tresults[question] = input\n\t\t}\n\t}\n\n\treturn map[string]any{\"error\": nil, \"output\": results}\n}\n\n// 3. Add exit-process to PlannerCapabilities array\nvar PlannerCapabilities = []repository.Function{\n\t{\n\t\tName: \"exit-process\",\n\t\tDescription: `Gracefully terminates the planning session with comprehensive completion validation and user satisfaction confirmation.\nPerforms final quality checks, validates all requirements fulfillment, and ensures clean planning state before exit.\nTriggers automatic documentation generation, plan summaries, and implementation readiness assessment.\n\nCritical Exit Criteria:\n‚úì All specified planning tasks completed with verified structure\n‚úì Plan quality standards met (clarity, feasibility, completeness)\n‚úì No unresolved planning issues or missing requirements\n‚úì User acceptance and satisfaction confirmed\n‚úì Planning documentation updated and accurate`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Professional completion summary and final recommendations for the user. Include planning status, deliverables completed, and next steps.\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{},\n\t\t},\n\t\tService: ExitProcess,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string // System error if graceful exit fails\",\n\t\t\t\"output\": \"string // Final completion report and recommendations\",\n\t\t},\n\t},\n\n\t{\n\t\tName: \"create-plan\",\n\t\tDescription: `Creates a structured execution plan. Provide plan fields directly (not nested under 'plan' key).\n\nREQUIRED FIELDS:\n- title: Descriptive name for the plan  \n- objective: Clear statement of what the plan achieves\n- steps: Array of at least one step, each with:\n  - description: What this step does (REQUIRED)\n  - agent: Which agent executes this step (optional, defaults to \"GeneralAgent\")\n\nOPTIONAL FIELDS:\n- planId: Unique identifier (auto-generated if missing)\n- assumptions: List of prerequisites  \n- successCriteria: How to measure success\n- fallbacks: What to do if steps fail\n\nEXAMPLE USAGE:\n{\n  \"title\": \"User Registration System\",\n  \"objective\": \"Implement secure user signup process\", \n  \"steps\": [\n    {\n      \"description\": \"Create user database schema\",\n      \"agent\": \"DatabaseAgent\"\n    },\n    {\n      \"description\": \"Build registration API endpoint\", \n      \"agent\": \"BackendAgent\"\n    }\n  ]\n}`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"planId\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Unique plan identifier (auto-generated if not provided)\",\n\t\t\t\t},\n\t\t\t\t\"title\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"REQUIRED: Descriptive title for the plan\",\n\t\t\t\t},\n\t\t\t\t\"objective\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"REQUIRED: Clear objective statement\",\n\t\t\t\t},\n\t\t\t\t\"steps\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"REQUIRED: At least one execution step\",\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType: repository.TypeObject,\n\t\t\t\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\t\t\t\"id\":           {Type: repository.TypeInteger, Description: \"Step number (auto-assigned if missing)\"},\n\t\t\t\t\t\t\t\"description\":  {Type: repository.TypeString, Description: \"REQUIRED: What this step does\"},\n\t\t\t\t\t\t\t\"agent\":        {Type: repository.TypeString, Description: \"Which agent executes (defaults to GeneralAgent)\"},\n\t\t\t\t\t\t\t\"inputs\":       {Type: repository.TypeArray, Items: \u0026repository.Properties{Type: repository.TypeString}},\n\t\t\t\t\t\t\t\"outputs\":      {Type: repository.TypeArray, Items: \u0026repository.Properties{Type: repository.TypeString}},\n\t\t\t\t\t\t\t\"dependencies\": {Type: repository.TypeArray, Items: \u0026repository.Properties{Type: repository.TypeInteger}},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRequired: []string{\"description\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"assumptions\":     {Type: repository.TypeArray, Items: \u0026repository.Properties{Type: repository.TypeString}},\n\t\t\t\t\"successCriteria\": {Type: repository.TypeArray, Items: \u0026repository.Properties{Type: repository.TypeString}},\n\t\t\t\t\"fallbacks\":       {Type: repository.TypeArray, Items: \u0026repository.Properties{Type: repository.TypeString}},\n\t\t\t},\n\t\t\tRequired: []string{\"title\", \"objective\", \"steps\"},\n\t\t},\n\t\tService: PutPlanForAgent,\n\t},\n\t{\n\t\tName:        \"take-input-from-terminal\",\n\t\tDescription: `Collects input from the user via terminal interaction.`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Prompt text to display to user\",\n\t\t\t\t},\n\t\t\t\t\"requirements\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"List of specific questions to ask (optional)\",\n\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"text\", \"requirements\"},\n\t\t},\n\t\tService: TakeInputFromTerminal,\n\t},\n}\n\n// 4. Update the init function to include all planner tools\nfunc init() {\n\tfor _, v := range PlannerCapabilities {\n\t\tPlannertoolsFunc[v.Name] = v\n\t}\n}\n",
    "hash": "ca1cd77199dd74f5750c153160b5d55c",
    "size": 28036,
    "tokens": 7009,
    "modified_time": "2026-02-10T12:24:05.265764514+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "GetInitialContext",
      "GetProjectStructure",
      "getProjectStructureRecursive",
      "loadGitIgnore",
      "detectDefaultShell",
      "mustGetWorkingDir",
      "detectTools",
      "getImportantEnvVars",
      "scanProjectFiles",
      "detectProjectType",
      "getGitBranch",
      "checkInternet",
      "getLocalTimezone",
      "generateSessionID",
      "formatFilesForOrchestrator",
      "GetPlannerArrayMap",
      "GenerateTasklist",
      "PutPlanForAgent",
      "getKeys",
      "ExitProcess",
      "TakeInputFromTerminal",
      "init"
    ],
    "security": [
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 617,
        "column": 0,
        "code": "log.Printf(\"DEBUG: Received args for PutPlanForAgent: %+v\", args)",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 836,
        "column": 0,
        "code": "fmt.Print(\"dost\u003e \")",
        "tool": "regex"
      }
    ]
  },
  "d06e39186050082f7591ebdf8a71f7ee": {
    "path": "internal/service/coder/coder.go",
    "content": "package coder\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"context\"\n\t\"dost/internal/repository\"\n\t\"dost/internal/service\"\n\t\"dost/internal/service/analysis\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strings\"\n\t\"time\"\n\t\"unicode/utf8\"\n\n\t\"github.com/google/uuid\"\n\tgitignore \"github.com/sabhiram/go-gitignore\"\n\t\"github.com/spf13/viper\"\n)\n\n// Coder capabilities definitions.\nconst (\n\tCreateFileFromName   = \"create_file\"\n\tReadFileFromName     = \"read_file\"\n\tListDirectoryName    = \"list_directory\"\n\tDeleteFileOrDirName  = \"delete_file_or_dir\"\n\tEditFileFromName     = \"edit_file\"\n\tRequestUserInputName = \"request_user_input\"\n)\n\nconst CreateFileDescription = `Creates new files with precise content placement and intelligent path resolution. \nSupports atomic file creation with automatic directory structure generation, UTF-8 encoding, and collision handling. \nOverwrites existing files when explicitly required. Optimized for multi-file project scaffolding and code generation workflows.`\n\nconst ReadFileDescription = `Performs high-performance file content retrieval with intelligent encoding detection and memory-optimized streaming. \nSupports batch reading operations, automatic charset conversion, and binary-safe content handling. \nEssential for code analysis, dependency inspection, and project structure understanding before modifications.`\n\nconst ListDirectoryDescription = `Provides comprehensive directory traversal with intelligent filtering, recursive scanning capabilities, and .gitignore awareness. \nReturns structured metadata including file types, sizes, permissions, and modification timestamps. \nOptimized for project discovery, dependency analysis, and codebase exploration workflows.`\n\nconst DeleteFileOrDirDescription = `Executes safe file and directory removal operations with rollback capabilities and dependency validation. \nSupports recursive deletion with conflict detection, backup creation, and atomic cleanup operations. \nIncludes safety checks to prevent accidental deletion of critical project files and version control data.`\n\nconst EditFileDescription = `Advanced multi-operation file editor with precise line-column targeting and atomic change application. \nSupports sophisticated edit operations including insertions, deletions, replacements, and multi-region modifications. \nFeatures intelligent conflict resolution, syntax-aware editing, and transaction-based changes with rollback support. \nOptimized for complex refactoring, code generation, and automated maintenance tasks.`\n\nconst RequestUserInputDescription = `Interactive terminal interface for real-time user communication and decision-making workflows. \nProvides formatted input prompts with validation, timeout handling, and context-aware questioning. \nEssential for gathering requirements, confirming destructive operations, and obtaining user preferences during development.`\n\nvar CodertoolsFunc map[string]repository.Function = make(map[string]repository.Function)\nvar ignoreMatcher *gitignore.GitIgnore\n\nvar ChatHistory = make([]map[string]any, 0)\nvar defaultIgnore = map[string]bool{\n\t\".git\":         true,\n\t\"node_modules\": true,\n\t\"vendor\":       true,\n\t\".venv\":        true,\n\t\".env\":         true,\n\t\".idea\":        true,\n\t\".vscode\":      true,\n\t\"__pycache__\":  true,\n\t\".dost\":        true,\n}\n\ntype InitialContext struct {\n\tOS              string\n\tArch            string\n\tUser            string\n\tShell           string\n\tCWD             string\n\tGoVersion       string\n\tFolderStructure map[string]any\n\tInstalledTools  []string\n\tEnvVars         map[string]string\n\tProjectFiles    []string\n\tProjectType     string\n\tGitBranch       string\n\tInternetAccess  bool\n\tAgentRole       string\n\tCapabilities    []string\n\tTimezone        string\n\tSessionID       string\n}\ntype changeInfo struct {\n\tstartLine int\n\tstartCol  int\n\tendLine   int\n\tendCol    int\n\toperation string\n\tcontent   string\n\tvalid     bool\n}\n\nfunc GetInitialContext() InitialContext {\n\tctx := InitialContext{\n\t\tOS:              runtime.GOOS,\n\t\tArch:            runtime.GOARCH,\n\t\tUser:            os.Getenv(\"USERNAME\"),\n\t\tShell:           detectDefaultShell(),\n\t\tCWD:             mustGetWorkingDir(),\n\t\tFolderStructure: GetProjectStructure(map[string]any{\"path\": \"./\"}),\n\t\tGoVersion:       runtime.Version(),\n\t\tInstalledTools:  detectTools(),\n\t\tEnvVars:         getImportantEnvVars(),\n\t\tProjectFiles:    scanProjectFiles(),\n\t\tProjectType:     detectProjectType(),\n\t\tGitBranch:       getGitBranch(),\n\t\tInternetAccess:  checkInternet(),\n\t\tTimezone:        getLocalTimezone(),\n\t\tSessionID:       generateSessionID(),\n\t}\n\treturn ctx\n}\n\nfunc detectDefaultShell() string {\n\tif runtime.GOOS == \"windows\" {\n\t\t// prefer PowerShell if present\n\t\tif _, err := exec.LookPath(\"powershell\"); err == nil {\n\t\t\treturn \"powershell\"\n\t\t}\n\t\treturn \"cmd\"\n\t}\n\treturn os.Getenv(\"SHELL\")\n}\n\nfunc mustGetWorkingDir() string {\n\tdir, err := os.Getwd()\n\tif err != nil {\n\t\treturn \".\"\n\t}\n\treturn dir\n}\n\nfunc detectTools() []string {\n\tvar found []string\n\tval := os.Getenv(\"PATH\")\n\tfound = strings.Split(val, \";\")\n\treturn found\n}\n\nfunc getImportantEnvVars() map[string]string {\n\tkeys := []string{\"PATH\", \"GOROOT\", \"GOPATH\", \"JAVA_HOME\"}\n\tenv := make(map[string]string)\n\tfor _, k := range keys {\n\t\tif v := os.Getenv(k); v != \"\" {\n\t\t\tenv[k] = v\n\t\t}\n\t}\n\treturn env\n}\n\nfunc scanProjectFiles() []string {\n\tfiles := []string{}\n\tfilepath.Walk(\".\", func(path string, info os.FileInfo, err error) error {\n\t\tif err == nil \u0026\u0026 !info.IsDir() {\n\t\t\tif strings.HasSuffix(path, \".go\") ||\n\t\t\t\tpath == \"go.mod\" || path == \"package.json\" || path == \"requirements.txt\" ||\n\t\t\t\tpath == \"Dockerfile\" || path == \"README.md\" {\n\t\t\t\tfiles = append(files, path)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn files\n}\n\nfunc detectProjectType() string {\n\tif _, err := os.Stat(\"go.mod\"); err == nil {\n\t\treturn \"Go project\"\n\t}\n\tif _, err := os.Stat(\"package.json\"); err == nil {\n\t\treturn \"Node.js project\"\n\t}\n\tif _, err := os.Stat(\"requirements.txt\"); err == nil {\n\t\treturn \"Python project\"\n\t}\n\treturn \"Unknown\"\n}\n\nfunc getGitBranch() string {\n\tcmd := exec.Command(\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\")\n\tout, err := cmd.Output()\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\treturn strings.TrimSpace(string(out))\n}\n\nfunc checkInternet() bool {\n\tcmd := exec.Command(\"ping\", \"-c\", \"1\", \"8.8.8.8\")\n\tif runtime.GOOS == \"windows\" {\n\t\tcmd = exec.Command(\"ping\", \"-n\", \"1\", \"8.8.8.8\")\n\t}\n\tif err := cmd.Run(); err != nil {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc getLocalTimezone() string {\n\t_, tz := time.Now().Zone()\n\treturn fmt.Sprintf(\"%d min offset\", tz/60)\n}\n\nfunc generateSessionID() string {\n\treturn fmt.Sprintf(\"%d\", time.Now().UnixNano())\n}\n\ntype AgentCoder repository.Agent\n\nconst coderName = \"coder\"\n\nconst coderVersion = \"0.1.0\"\n\n// args must and only contains \"query\"\n// Helper function to format files for Coder\nfunc formatFilesForCoder(filesRead map[string]any) string {\n\tif len(filesRead) == 0 {\n\t\treturn \"\"\n\t}\n\n\tvar result strings.Builder\n\tresult.WriteString(\"=== FILES CONTENT ===\\n\\n\")\n\n\tfor fileName, fileData := range filesRead {\n\t\tresult.WriteString(fmt.Sprintf(\"FILE: %s\\n\", fileName))\n\t\tresult.WriteString(\"=\" + strings.Repeat(\"=\", len(fileName)+6) + \"\\n\")\n\n\t\tif chunks, ok := fileData.([]map[string]any); ok {\n\t\t\tfor _, chunk := range chunks {\n\t\t\t\tif content, exists := chunk[\"content\"].(string); exists {\n\t\t\t\t\tresult.WriteString(content)\n\t\t\t\t\tresult.WriteString(\"\\n\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tresult.WriteString(\"\\n\" + strings.Repeat(\"-\", 50) + \"\\n\\n\")\n\t}\n\n\treturn result.String()\n}\n\nfunc (p *AgentCoder) Interaction(args map[string]any) map[string]any {\n\tInitialContext := GetInitialContext()\n\tInitialContextBytes, err := json.Marshal(InitialContext)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": \"Unable to get initial context\"}\n\t}\n\n\tvar userMessage strings.Builder\n\n\tfilesContent := formatFilesForCoder(analysis.FilesRead)\n\tif filesContent != \"\" {\n\t\tuserMessage.WriteString(filesContent)\n\t\tuserMessage.WriteString(\"\\n\")\n\t}\n\n\t// Add initial context\n\tuserMessage.WriteString(\"=== INITIAL CONTEXT ===\\n\")\n\tuserMessage.WriteString(string(InitialContextBytes))\n\tuserMessage.WriteString(\"\\n\\n\")\n\n\t// Add query\n\tuserMessage.WriteString(\"=== QUERY ===\\n\")\n\tif query, ok := args[\"query\"].(string); ok {\n\t\tuserMessage.WriteString(query)\n\t}\n\tlog.Println(\"TEST: CODER:  \", userMessage.String()[0:20])\n\t// Push consolidated user message into ChatHistory\n\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\"role\": \"user\",\n\t\t\"parts\": []map[string]any{\n\t\t\t{\"text\": userMessage.String()},\n\t\t},\n\t})\n\n\tfor {\n\t\t// Ensure exit-process is always enforced\n\t\tif len(ChatHistory) \u003e 0 \u0026\u0026 ChatHistory[len(ChatHistory)-1][\"role\"] == \"model\" {\n\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\"role\": \"user\",\n\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t{\n\t\t\t\t\t\t\"text\": \"If you feel there is no task left and nothing to do, call exit-process. Because only that can stop you and finish the program. Don't respond with text, no text output should be there, call the exit-process. PERIOD\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\n\t\toutput := p.RequestAgent(ChatHistory)\n\n\t\tif output[\"error\"] != nil {\n\t\t\tfmt.Println(\"Error:\", output[\"error\"])\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\toutputData, ok := output[\"output\"].([]map[string]any)\n\t\tif !ok {\n\t\t\tfmt.Println(\"ERROR CONVERTING OUTPUT\")\n\t\t\treturn nil\n\t\t}\n\n\t\tif len(outputData) == 0 {\n\t\t\tfmt.Println(\"No output received\")\n\t\t\tcontinue\n\t\t}\n\n\t\t// Process each output part\n\t\tfor _, part := range outputData {\n\t\t\tpartType, hasType := part[\"type\"].(string)\n\t\t\tif !hasType {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tswitch partType {\n\t\t\tcase \"text\":\n\t\t\t\tif text, ok := part[\"data\"].(string); ok {\n\t\t\t\t\tfmt.Println(\"Agent:\", text)\n\t\t\t\t}\n\n\t\t\tcase \"functionCall\":\n\t\t\t\tname, nameOK := part[\"name\"].(string)\n\t\t\t\targsData, argsOK := part[\"args\"].(map[string]any)\n\n\t\t\t\tif !nameOK || !argsOK {\n\t\t\t\t\tfmt.Println(\"Error: invalid function call data\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tfmt.Println(\"Calling function:\", name)\n\n\t\t\t\t// Execute the function\n\t\t\t\tif function, exists := CodertoolsFunc[name]; exists {\n\t\t\t\t\tresult := function.Run(argsData)\n\n\t\t\t\t\t// Check for exit condition\n\t\t\t\t\tif _, ok := result[\"exit\"].(bool); ok {\n\t\t\t\t\t\treturn map[string]any{\"coder-id\": result[\"output\"]}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Add function response back to chat history\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"functionResponse\": map[string]any{\n\t\t\t\t\t\t\t\t\t\"name\":     name,\n\t\t\t\t\t\t\t\t\t\"response\": result,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\n\t\t\t\t\tif outputStr, ok := result[\"output\"].(string); ok {\n\t\t\t\t\t\tfmt.Println(\"Result:\", outputStr)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfmt.Printf(\"Function %s not found\\n\", name)\n\n\t\t\t\t\t// Add error response into chat\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\"text\": fmt.Sprintf(\"Error: Function '%s' not found\", name)},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfmt.Println(\"---\")\n\t}\n}\n\n// NewAgent creates and initializes a new AgentCoder instance.\nfunc (c *AgentCoder) NewAgent() {\n\tmodel := viper.GetString(\"CODER.MODEL\")\n\tif model == \"\" {\n\t\tmodel = \"gemini-1.5-pro\"\n\t}\n\tendPoints := fmt.Sprintf(\"https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse\", model)\n\tid := fmt.Sprintf(\"coder-%s\", uuid.NewString())\n\n\tagentMetadata := repository.AgentMetadata{\n\t\tID:             id,\n\t\tName:           coderName,\n\t\tVersion:        coderVersion,\n\t\tType:           repository.AgentCoder,\n\t\tInstructions:   repository.CoderInstructions,\n\t\tMaxConcurrency: 5,\n\t\tTimeout:        10 * time.Minute,\n\t\tTags:           []string{\"coder\", \"code\", \"programming\", \"development\"},\n\t\tEndpoints:      map[string]string{\"http\": endPoints},\n\t\tContext:        make(map[string]any),\n\t\tStatus:         \"active\",\n\t\tLastActive:     time.Now(),\n\t}\n\n\tc.Metadata = agentMetadata\n\tc.Capabilities = CoderCapabilities\n\n}\n\n// RequestAgent is the main entry point for the AgentCoder to handle incoming tasks.\nfunc (c *AgentCoder) RequestAgent(contents []map[string]any) map[string]any {\n\tfmt.Printf(\"Processing request with Coder Agent: %s\\n\", c.Metadata.Name)\n\n\t// Build request payload\n\trequest := map[string]any{\n\t\t\"systemInstruction\": map[string]any{\n\t\t\t\"parts\": []map[string]any{\n\t\t\t\t{\"text\": c.Metadata.Instructions},\n\t\t\t},\n\t\t},\n\t\t\"toolConfig\": map[string]any{\n\t\t\t\"functionCallingConfig\": map[string]any{\n\t\t\t\t\"mode\": \"ANY\",\n\t\t\t},\n\t\t},\n\t\t\"contents\": contents,\n\t\t\"tools\": []map[string]any{\n\t\t\t{\"functionDeclarations\": GetCoderCapabilitiesArrayMap()},\n\t\t},\n\t}\n\n\t// Marshal request body\n\tjsonBody, err := json.Marshal(request)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t}\n\n\t// Retry config\n\tconst maxRetries = 5\n\tconst maxWaitTime = 10 * time.Minute\n\n\tfor attempt := 0; attempt \u003c= maxRetries; attempt++ {\n\t\t// Create HTTP request\n\t\treq, err := http.NewRequestWithContext(\n\t\t\tcontext.Background(),\n\t\t\t\"POST\",\n\t\t\tc.Metadata.Endpoints[\"http\"],\n\t\t\tbytes.NewBuffer(jsonBody),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t}\n\n\t\treq.Header.Set(\"Content-Type\", \"application/json\")\n\t\treq.Header.Set(\"X-goog-api-key\", viper.GetString(\"CODER.API_KEY\"))\n\n\t\t// Execute request with timeout\n\t\tclient := repository.NewStreamingHTTPClient()\n\t\tresp, err := client.Do(req)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\t\tdefer resp.Body.Close()\n\n\t\t// Success case - parse streaming response\n\t\tif resp.StatusCode == http.StatusOK {\n\t\t\t// Parse SSE stream with real-time display\n\t\t\tstreamResp, err := repository.ParseSSEStream(resp.Body, true)\n\t\t\tif err != nil {\n\t\t\t\tif attempt == maxRetries {\n\t\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t\t}\n\t\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Convert to standard output format\n\t\t\toutput := repository.ConvertStreamResponseToOutput(streamResp)\n\n\t\t\t// Save chat history\n\t\t\thistoryEntry := repository.BuildChatHistoryFromStream(streamResp, \"coder\")\n\t\t\tif historyEntry != nil {\n\t\t\t\tChatHistory = append(ChatHistory, historyEntry)\n\t\t\t}\n\n\t\t\tc.Metadata.LastActive = time.Now()\n\t\t\treturn map[string]any{\"error\": nil, \"output\": output}\n\t\t}\n\n\t\t// Read body for error cases\n\t\tbodyBytes, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Handle rate limits\n\t\tif resp.StatusCode == http.StatusTooManyRequests {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Rate limit exceeded after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\t\t\tretryDelay := repository.ParseRetryDelay(string(bodyBytes))\n\t\t\twaitTime := retryDelay\n\t\t\tif waitTime \u003c= 0 {\n\t\t\t\twaitTime = repository.ExponentialBackoff(attempt)\n\t\t\t}\n\t\t\tif waitTime \u003e maxWaitTime {\n\t\t\t\twaitTime = maxWaitTime\n\t\t\t}\n\t\t\tfmt.Printf(\"Rate limit hit (attempt %d/%d). Waiting %v before retry...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, waitTime)\n\t\t\ttime.Sleep(waitTime)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Retry on server errors\n\t\tif resp.StatusCode \u003e= 500 \u0026\u0026 resp.StatusCode \u003c 600 {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Server error after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Printf(\"Server error (attempt %d/%d). Waiting %v before retry...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, repository.ExponentialBackoff(attempt))\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Client errors (400‚Äì499) except 429 ‚Üí don't retry\n\t\treturn map[string]any{\n\t\t\t\"error\":  fmt.Sprintf(\"HTTP %d: %s\", resp.StatusCode, string(bodyBytes)),\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"error\":  fmt.Sprintf(\"Max retries (%d) exceeded\", maxRetries),\n\t\t\"output\": nil,\n\t}\n}\n\n// ToMap serializes the AgentCoder into a map.\nfunc (c *AgentCoder) ToMap() map[string]any {\n\tagent := repository.Agent(*c)\n\treturn agent.ToMap()\n}\n\nfunc TakeInputFromTerminal(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"No Text Provided\"}\n\t}\n\tfmt.Println(text)\n\n\trequirements, ok := args[\"requirements\"].([]any)\n\treader := bufio.NewReader(os.Stdin)\n\n\t// Case 1: No requirements -\u003e just take a single input\n\tif !ok || len(requirements) == 0 {\n\t\tfmt.Print(\"dost\u003e \")\n\t\tinput, err := reader.ReadString('\\n')\n\t\tif err != nil {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  fmt.Sprintf(\"Error reading input: %v\", err),\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\t\tinput = strings.TrimSpace(input)\n\t\tif input == \"\" {\n\t\t\treturn map[string]any{\"error\": nil, \"output\": \"\u003cno input provided\u003e\"}\n\t\t}\n\t\treturn map[string]any{\"error\": nil, \"output\": input}\n\t}\n\n\t// Case 2: Requirements exist -\u003e ask each question\n\tresults := make(map[string]string)\n\tfor _, req := range requirements {\n\t\tquestion, ok := req.(string)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tfmt.Printf(\"dost\u003e %s: \", question)\n\t\tinput, err := reader.ReadString('\\n')\n\t\tif err != nil {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  fmt.Sprintf(\"Error reading input: %v\", err),\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\n\t\tinput = strings.TrimSpace(input)\n\t\tif input == \"\" {\n\t\t\tresults[question] = \"\u003cno input provided\u003e\"\n\t\t} else {\n\t\t\tresults[question] = input\n\t\t}\n\t}\n\n\treturn map[string]any{\"error\": nil, \"output\": results}\n}\n\n// CreateFile creates new files - FIXED VERSION\nfunc CreateFile(data map[string]any) map[string]any {\n\ttext, ok := data[\"text\"].(string)\n\tif ok {\n\t\tfmt.Printf(\"CODER: %s\\n\", text)\n\t}\n\n\t// Handle both single file and multiple files\n\tfileNames, hasFileNames := data[\"file_paths\"].([]interface{})\n\tcontents, hasContents := data[\"contents\"].([]interface{})\n\n\t// Single file creation (backward compatibility)\n\tif path, hasPath := data[\"path\"].(string); hasPath {\n\t\tcontent, hasContent := data[\"content\"].(string)\n\t\tif !hasContent {\n\t\t\treturn map[string]any{\"error\": \"content is required\"}\n\t\t}\n\n\t\tdir := filepath.Dir(path)\n\t\tif err := os.MkdirAll(dir, 0755); err != nil {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"failed to create directory for file: %v\", err)}\n\t\t}\n\n\t\tif err := os.WriteFile(path, []byte(content), 0644); err != nil {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"failed to create file: %v\", err)}\n\t\t}\n\n\t\treturn map[string]any{\n\t\t\t\"status\": \"completed\",\n\t\t\t\"output\": fmt.Sprintf(\"File created successfully at %s\", path),\n\t\t}\n\t}\n\n\t// Multiple files creation\n\tif !hasFileNames || !hasContents {\n\t\treturn map[string]any{\"error\": \"file_paths and contents are required\"}\n\t}\n\n\tif len(fileNames) != len(contents) {\n\t\treturn map[string]any{\"error\": \"file_paths and contents arrays must have the same length\"}\n\t}\n\n\tvar createdFiles []string\n\tvar errors []string\n\n\tfor i, fileNameInterface := range fileNames {\n\t\tfileName, ok := fileNameInterface.(string)\n\t\tif !ok {\n\t\t\terrors = append(errors, fmt.Sprintf(\"Invalid file name at index %d\", i))\n\t\t\tcontinue\n\t\t}\n\n\t\tcontent, ok := contents[i].(string)\n\t\tif !ok {\n\t\t\terrors = append(errors, fmt.Sprintf(\"Invalid content at index %d\", i))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create directory if it doesn't exist\n\t\tdir := filepath.Dir(fileName)\n\t\tif dir != \".\" \u0026\u0026 dir != \"\" {\n\t\t\tif err := os.MkdirAll(dir, 0755); err != nil {\n\t\t\t\terrors = append(errors, fmt.Sprintf(\"Failed to create directory for %s: %v\", fileName, err))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// Write the file\n\t\tif err := os.WriteFile(fileName, []byte(content), 0644); err != nil {\n\t\t\terrors = append(errors, fmt.Sprintf(\"Failed to create %s: %v\", fileName, err))\n\t\t\tcontinue\n\t\t}\n\n\t\tcreatedFiles = append(createdFiles, fileName)\n\t\tfmt.Printf(\"Created file: %s\\n\", fileName)\n\t}\n\n\tif len(errors) \u003e 0 {\n\t\treturn map[string]any{\n\t\t\t\"error\":         strings.Join(errors, \"; \"),\n\t\t\t\"output\":        fmt.Sprintf(\"Created %d files successfully\", len(createdFiles)),\n\t\t\t\"created_files\": createdFiles,\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"status\": \"completed\",\n\t\t\"output\": fmt.Sprintf(\"Successfully created %d files: %s\", len(createdFiles), strings.Join(createdFiles, \", \")),\n\t}\n}\n\n// ReadFile reads the content of a file from a specified path.\nfunc ReadFiles(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Printf(\"CODER: %s\", text)\n\t}\n\n\tfileNames, ok := args[\"file_paths\"].([]interface{})\n\tif !ok {\n\t\treturn map[string]any{\n\t\t\t\"error\":  \"Invalid arguments: 'file_paths' must be a slice of strings\",\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\tvar stringFileNames []string\n\tfor _, v := range fileNames {\n\t\ts, ok := v.(string)\n\t\tif !ok {\n\t\t\tlog.Fatal(\"Invalid argument: 'file_paths' contains non-string values\")\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  \"Invalid argument: 'file_paths' contains non-string values\",\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\t\tstringFileNames = append(stringFileNames, s)\n\t}\n\n\treadFiles := make(map[string]any)\n\tvar notFoundFiles []string\n\n\tfor _, fileName := range stringFileNames {\n\t\tfile, err := os.Open(fileName)\n\t\tif err != nil {\n\t\t\tnotFoundFiles = append(notFoundFiles, fileName)\n\t\t\tcontinue\n\t\t}\n\t\tdefer file.Close()\n\n\t\t// Read all lines, skipping empty ones\n\t\tscanner := bufio.NewScanner(file)\n\t\tvar lines []string\n\t\tlineNumber := 1\n\t\tfor scanner.Scan() {\n\t\t\tline := scanner.Text()\n\t\t\t// Skip empty lines but track line numbers\n\t\t\tif strings.TrimSpace(line) != \"\" {\n\t\t\t\t// Add line number prefix to non-empty lines\n\t\t\t\tnumberedLine := fmt.Sprintf(\"%d: %s\", lineNumber, line)\n\t\t\t\tlines = append(lines, numberedLine)\n\t\t\t}\n\t\t\tlineNumber++\n\t\t}\n\n\t\tif err := scanner.Err(); err != nil {\n\t\t\treadFiles[fileName] = fmt.Sprintf(\"Error reading file: %v\", err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create proper chunks (non-overlapping)\n\t\tchunks := []map[string]any{}\n\t\tchunkSize := 40\n\t\tif len(lines) \u003c 100 {\n\t\t\tchunks = []map[string]any{{\n\t\t\t\t\"start\":   1,\n\t\t\t\t\"end\":     len(lines),\n\t\t\t\t\"content\": strings.Join(lines, \"\\n\"),\n\t\t\t}}\n\t\t} else {\n\t\t\tfor i := 0; i \u003c len(lines); i += chunkSize {\n\t\t\t\tend := i + chunkSize\n\t\t\t\tif end \u003e len(lines) {\n\t\t\t\t\tend = len(lines)\n\t\t\t\t}\n\n\t\t\t\t// Build chunk content\n\t\t\t\tvar chunkContent strings.Builder\n\t\t\t\tfor j := i; j \u003c end; j++ {\n\t\t\t\t\tchunkContent.WriteString(lines[j])\n\t\t\t\t\tif j \u003c end-1 { // Don't add newline after last line in chunk\n\t\t\t\t\t\tchunkContent.WriteString(\"\\n\")\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tchunks = append(chunks, map[string]any{\n\t\t\t\t\t\"start\":   i + 1,\n\t\t\t\t\t\"end\":     end,\n\t\t\t\t\t\"content\": chunkContent.String(),\n\t\t\t\t})\n\t\t\t}\n\n\t\t\t// Handle empty file edge case (all lines were empty)\n\t\t\tif len(lines) == 0 {\n\t\t\t\tchunks = append(chunks, map[string]any{\n\t\t\t\t\t\"start\":   1,\n\t\t\t\t\t\"end\":     0,\n\t\t\t\t\t\"content\": \"\",\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\treadFiles[fileName] = chunks\n\t\t// Also append to the global FilesRead map\n\t\tanalysis.FilesRead[fileName] = chunks\n\t\tfmt.Printf(\"Read file: %s (%d non-empty lines, %d chunks)\\n\", fileName, len(lines), len(chunks))\n\t}\n\n\tif len(notFoundFiles) \u003e 0 {\n\t\tfmt.Printf(\"Files not found: %v\\n\", notFoundFiles)\n\t}\n\n\treturn map[string]any{\"error\": nil, \"output\": readFiles}\n}\n\nfunc ExecuteCommands(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Println(text)\n\t}\n\n\t// Get current working directory\n\twd, err := os.Getwd()\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error()}\n\t}\n\n\t// Extract command\n\tcmdStr, ok := args[\"command\"].(string)\n\tif !ok || cmdStr == \"\" {\n\t\treturn map[string]any{\"error\": \"Invalid command\"}\n\t}\n\n\t// Extract arguments (as array instead of a single string)\n\tvar argList []string\n\tif rawArgs, ok := args[\"arguments\"]; ok {\n\t\tswitch v := rawArgs.(type) {\n\t\tcase string:\n\t\t\t// split on spaces if user passed a string\n\t\t\tif v != \"\" {\n\t\t\t\targList = strings.Fields(v)\n\t\t\t}\n\t\tcase []any:\n\t\t\tfor _, a := range v {\n\t\t\t\tif s, ok := a.(string); ok {\n\t\t\t\t\targList = append(argList, s)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfmt.Println(\"\u003eDOST\\\\\")\n\tfmt.Printf(\"%s %v\", cmdStr, argList)\n\tif !service.TakePermission {\n\t\tfmt.Printf(\"\\nAbout to run command in %s:\\n\u003e %s\\nPress ENTER to continue or Ctrl+C to cancel...\", wd, argList)\n\t\tbufio.NewReader(os.Stdin).ReadBytes('\\n') // wait for Enter\n\t}\n\t// Handle `cd` separately\n\tif cmdStr == \"cd\" {\n\t\tif len(argList) == 0 {\n\t\t\treturn map[string]any{\"error\": \"cd requires a path\"}\n\t\t}\n\t\tnewDir := argList[0]\n\t\tif !filepath.IsAbs(newDir) {\n\t\t\tnewDir = filepath.Join(wd, newDir)\n\t\t}\n\t\tif err := os.Chdir(newDir); err != nil {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"failed to change directory: %v\", err)}\n\t\t}\n\t\treturn map[string]any{\"message\": fmt.Sprintf(\"Changed directory to %s\", newDir)}\n\t}\n\n\t// Build command properly\n\tcmd := exec.Command(cmdStr, argList...)\n\tcmd.Dir = wd\n\tvar stdoutBuf, stderrBuf bytes.Buffer\n\tcmd.Stdin = os.Stdin\n\tcmd.Stdout = io.MultiWriter(os.Stdout, \u0026stdoutBuf)\n\tcmd.Stderr = io.MultiWriter(os.Stderr, \u0026stderrBuf)\n\n\tlog.Default().Printf(\"Running command in %s: %s %v\\n\", wd, cmdStr, argList)\n\n\terr = cmd.Run()\n\tif err != nil {\n\t\treturn map[string]any{\n\t\t\t\"error\": fmt.Sprintf(\"command failed: [%s %v] %v || CONSOLE/TERMINAL:%v\",\n\t\t\t\tcmdStr, argList, err, stderrBuf.String()),\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"message\": \"Command executed successfully\",\n\t\t\"output\":  stdoutBuf.String(),\n\t}\n}\n\n// EditFile edits a file at a given path.\n// Piece Table - what is it ??\n\nfunc EditFile(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Printf(\"CODER: %s\\n\", text)\n\t}\n\n\tfilepathInput, ok := args[\"file_path\"].(string)\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"ERROR READING PATH\"}\n\t}\n\n\tchanges, ok := args[\"changes\"].([]interface{})\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"REQUIRED CHANGES MAP\"}\n\t}\n\n\t// Enhanced change structure with validation\n\n\ttoInt := func(v any) (int, bool) {\n\t\tswitch val := v.(type) {\n\t\tcase float64:\n\t\t\treturn int(val), true\n\t\tcase int:\n\t\t\treturn val, true\n\t\tdefault:\n\t\t\treturn 0, false\n\t\t}\n\t}\n\n\tvar processedChanges []changeInfo\n\tfor i, c := range changes {\n\t\tch, ok := c.(map[string]any)\n\t\tif !ok {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"INVALID CHANGE FORMAT at index %d\", i)}\n\t\t}\n\n\t\tstartLine, startLineOk := toInt(ch[\"start_line_number\"])\n\t\tstartCol, startColOk := toInt(ch[\"start_line_col\"])\n\t\tendLine, endLineOk := toInt(ch[\"end_line_number\"])\n\t\tendCol, endColOk := toInt(ch[\"end_line_col\"])\n\t\toperation, operationOk := ch[\"operation\"].(string)\n\t\tcontent, contentOk := ch[\"content\"].(string)\n\n\t\t// Validate all required fields are present and correct type\n\t\tif !startLineOk || !startColOk || !endLineOk || !endColOk || !operationOk || !contentOk {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"MISSING OR INVALID FIELDS in change %d\", i)}\n\t\t}\n\n\t\t// Validate operation type\n\t\tif operation != \"delete\" \u0026\u0026 operation != \"replace\" \u0026\u0026 operation != \"write\" {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"INVALID OPERATION '%s' in change %d. Must be 'delete', 'replace', or 'write'\", operation, i)}\n\t\t}\n\n\t\t// Validate line/column numbers make sense\n\t\tif startLine \u003c 1 || endLine \u003c 1 {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"LINE NUMBERS must be \u003e= 1 in change %d\", i)}\n\t\t}\n\n\t\tif startCol \u003c 0 || endCol \u003c 0 {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"COLUMN NUMBERS must be \u003e= 0 in change %d\", i)}\n\t\t}\n\n\t\t// For single-line operations, validate column order\n\t\tif startLine == endLine \u0026\u0026 startCol \u003e endCol \u0026\u0026 operation != \"write\" {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"START COLUMN cannot be \u003e END COLUMN on same line in change %d\", i)}\n\t\t}\n\n\t\tprocessedChanges = append(processedChanges, changeInfo{\n\t\t\tstartLine: startLine,\n\t\t\tstartCol:  startCol,\n\t\t\tendLine:   endLine,\n\t\t\tendCol:    endCol,\n\t\t\toperation: operation,\n\t\t\tcontent:   content,\n\t\t\tvalid:     true,\n\t\t})\n\t}\n\n\t// Read file with better error handling\n\tfileContent, err := os.ReadFile(filepathInput)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"FILE NOT FOUND: %s\", filepathInput)}\n\t\t}\n\t\treturn map[string]any{\"error\": fmt.Sprintf(\"CANNOT READ FILE: %s - %v\", filepathInput, err)}\n\t}\n\n\t// Handle different line endings\n\tcontent := string(fileContent)\n\tcontent = strings.ReplaceAll(content, \"\\r\\n\", \"\\n\") // Windows -\u003e Unix\n\tcontent = strings.ReplaceAll(content, \"\\r\", \"\\n\")   // Old Mac -\u003e Unix\n\tlines := strings.Split(content, \"\\n\")\n\n\t// Validate all changes against file bounds before applying any\n\tfor i, change := range processedChanges {\n\t\tif change.startLine \u003e len(lines) || change.endLine \u003e len(lines) {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"LINE NUMBER OUT OF BOUNDS in change %d: file has %d lines, but change references line %d\", i, len(lines), max(change.startLine, change.endLine))}\n\t\t}\n\n\t\t// Check column bounds for start position\n\t\tif change.startLine \u003c= len(lines) {\n\t\t\tlineIdx := change.startLine - 1\n\t\t\tlineLen := utf8.RuneCountInString(lines[lineIdx])\n\t\t\tif change.startCol \u003e lineLen {\n\t\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"START COLUMN OUT OF BOUNDS in change %d: line %d has %d characters, but change references column %d\", i, change.startLine, lineLen, change.startCol)}\n\t\t\t}\n\t\t}\n\n\t\t// Check column bounds for end position (for same line operations)\n\t\tif change.startLine == change.endLine \u0026\u0026 change.endLine \u003c= len(lines) {\n\t\t\tlineIdx := change.endLine - 1\n\t\t\tlineLen := utf8.RuneCountInString(lines[lineIdx])\n\t\t\tif change.endCol \u003e lineLen {\n\t\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"END COLUMN OUT OF BOUNDS in change %d: line %d has %d characters, but change references column %d\", i, change.endLine, lineLen, change.endCol)}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Sort changes by position (last to first to avoid position conflicts)\n\tsort.Slice(processedChanges, func(i, j int) bool {\n\t\tif processedChanges[i].startLine == processedChanges[j].startLine {\n\t\t\treturn processedChanges[i].startCol \u003e processedChanges[j].startCol\n\t\t}\n\t\treturn processedChanges[i].startLine \u003e processedChanges[j].startLine\n\t})\n\n\t// Apply changes from last to first\n\tfor _, change := range processedChanges {\n\t\tswitch change.operation {\n\t\tcase \"delete\":\n\t\t\tlines = applyDelete(lines, change)\n\t\tcase \"replace\":\n\t\t\tlines = applyReplace(lines, change)\n\t\tcase \"write\":\n\t\t\tlines = applyWrite(lines, change)\n\t\t}\n\t}\n\n\t// Write back to file\n\tnewContent := strings.Join(lines, \"\\n\")\n\terr = os.WriteFile(filepathInput, []byte(newContent), 0644)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": fmt.Sprintf(\"CANNOT WRITE TO FILE: %s - %v\", filepathInput, err)}\n\t}\n\n\treturn map[string]any{\"output\": fmt.Sprintf(\"Successfully applied %d changes to %s\", len(processedChanges), filepathInput)}\n}\n\n// Helper function for delete operations\nfunc applyDelete(lines []string, change changeInfo) []string {\n\tstartIdx := change.startLine - 1\n\tendIdx := change.endLine - 1\n\n\tif change.startLine == change.endLine {\n\t\t// Single line deletion - remove characters within the line\n\t\tif startIdx \u003c len(lines) {\n\t\t\tline := lines[startIdx]\n\t\t\trunes := []rune(line)\n\t\t\tif change.startCol \u003c= len(runes) \u0026\u0026 change.endCol \u003c= len(runes) {\n\t\t\t\tnewRunes := append(runes[:change.startCol], runes[change.endCol:]...)\n\t\t\t\tlines[startIdx] = string(newRunes)\n\t\t\t}\n\t\t}\n\t} else {\n\t\t// Multi-line deletion\n\t\tif startIdx \u003c len(lines) \u0026\u0026 endIdx \u003c len(lines) {\n\t\t\t// Keep part of first line before start column\n\t\t\tfirstLinePart := \"\"\n\t\t\tif startIdx \u003c len(lines) {\n\t\t\t\tfirstLineRunes := []rune(lines[startIdx])\n\t\t\t\tif change.startCol \u003c= len(firstLineRunes) {\n\t\t\t\t\tfirstLinePart = string(firstLineRunes[:change.startCol])\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Keep part of last line after end column\n\t\t\tlastLinePart := \"\"\n\t\t\tif endIdx \u003c len(lines) {\n\t\t\t\tlastLineRunes := []rune(lines[endIdx])\n\t\t\t\tif change.endCol \u003c= len(lastLineRunes) {\n\t\t\t\t\tlastLinePart = string(lastLineRunes[change.endCol:])\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Combine remaining parts\n\t\t\tcombinedLine := firstLinePart + lastLinePart\n\n\t\t\t// Remove the range and insert combined line\n\t\t\tnewLines := make([]string, 0, len(lines)-(endIdx-startIdx))\n\t\t\tnewLines = append(newLines, lines[:startIdx]...)\n\t\t\tnewLines = append(newLines, combinedLine)\n\t\t\tnewLines = append(newLines, lines[endIdx+1:]...)\n\t\t\tlines = newLines\n\t\t}\n\t}\n\treturn lines\n}\n\n// Helper function for replace operations\nfunc applyReplace(lines []string, change changeInfo) []string {\n\t// First delete the range, then insert new content\n\tlines = applyDelete(lines, change)\n\n\t// Now insert the new content at the start position\n\twriteChange := changeInfo{\n\t\tstartLine: change.startLine,\n\t\tstartCol:  change.startCol,\n\t\tendLine:   change.startLine,\n\t\tendCol:    change.startCol,\n\t\toperation: \"write\",\n\t\tcontent:   change.content,\n\t}\n\treturn applyWrite(lines, writeChange)\n}\n\n// Helper function for write operations\nfunc applyWrite(lines []string, change changeInfo) []string {\n\tif change.startLine-1 \u003c len(lines) {\n\t\tlineIdx := change.startLine - 1\n\t\tline := lines[lineIdx]\n\t\trunes := []rune(line)\n\n\t\tif change.startCol \u003c= len(runes) {\n\t\t\t// Handle multi-line content insertion\n\t\t\tnewContent := change.content\n\t\t\tcontentLines := strings.Split(newContent, \"\\n\")\n\n\t\t\tif len(contentLines) == 1 {\n\t\t\t\t// Single line insertion\n\t\t\t\tnewRunes := append(runes[:change.startCol], append([]rune(contentLines[0]), runes[change.startCol:]...)...)\n\t\t\t\tlines[lineIdx] = string(newRunes)\n\t\t\t} else {\n\t\t\t\t// Multi-line insertion\n\t\t\t\tbeforeRunes := runes[:change.startCol]\n\t\t\t\tafterRunes := runes[change.startCol:]\n\n\t\t\t\t// First line: existing content before + first new line\n\t\t\t\tfirstNewLine := string(beforeRunes) + contentLines[0]\n\n\t\t\t\t// Last line: last new content + existing content after\n\t\t\t\tlastNewLine := contentLines[len(contentLines)-1] + string(afterRunes)\n\n\t\t\t\t// Build new lines array\n\t\t\t\tnewLines := make([]string, 0, len(lines)+len(contentLines)-1)\n\t\t\t\tnewLines = append(newLines, lines[:lineIdx]...)\n\t\t\t\tnewLines = append(newLines, firstNewLine)\n\t\t\t\tnewLines = append(newLines, contentLines[1:len(contentLines)-1]...)\n\t\t\t\tnewLines = append(newLines, lastNewLine)\n\t\t\t\tnewLines = append(newLines, lines[lineIdx+1:]...)\n\t\t\t\tlines = newLines\n\t\t\t}\n\t\t}\n\t}\n\treturn lines\n}\n\n// GetProjectStructure returns the project structure as a string, ignoring files and directories specified in .gitignore.\n// If a .gitignore file is not found, it uses a default ignore list.\n// It takes the project path as input.\nfunc GetProjectStructure(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\tfmt.Println(text)\n\t}\n\n\tloadGitIgnore()\n\tpath := args[\"path\"].(string)\n\tvar builder strings.Builder\n\tbuilder.WriteString(path + \"\\n\")\n\terr := getProjectStructureRecursive(path, \"\", \u0026builder)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err, \"output\": nil}\n\t}\n\n\tif builder.String() == \".\" || builder.String() == \"\" {\n\t\treturn map[string]any{\"error\": nil, \"output\": \"\u003cempty directory\u003e\"}\n\t}\n\treturn map[string]any{\"error\": nil, \"output\": builder.String()}\n}\n\nfunc getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {\n\tentries, err := os.ReadDir(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor i, entry := range entries {\n\t\tentryPath := filepath.Join(path, entry.Name())\n\n\t\t// skip ignored entries\n\t\tif ignoreMatcher != nil {\n\t\t\trelPath, _ := filepath.Rel(\".\", entryPath)\n\t\t\tif ignoreMatcher.MatchesPath(relPath) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tif defaultIgnore[entry.Name()] {\n\t\t\t// ‚úÖ Skip this directory and its contents completely\n\t\t\tif entry.IsDir() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// draw branch\n\t\tconnector := \"‚îú‚îÄ‚îÄ\"\n\t\tif i == len(entries)-1 {\n\t\t\tconnector = \"‚îî‚îÄ‚îÄ\"\n\t\t}\n\t\tbuilder.WriteString(prefix + connector + \" \" + entry.Name() + \"\\n\")\n\n\t\t// recursively descend\n\t\tif entry.IsDir() {\n\t\t\tsubPrefix := prefix\n\t\t\tif i == len(entries)-1 {\n\t\t\t\tsubPrefix += \"    \"\n\t\t\t} else {\n\t\t\t\tsubPrefix += \"‚îÇ   \"\n\t\t\t}\n\t\t\t// üö´ Don't go inside ignored directories\n\t\t\tif !defaultIgnore[entry.Name()] {\n\t\t\t\terr := getProjectStructureRecursive(entryPath, subPrefix, builder)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc loadGitIgnore() {\n\tif _, err := os.Stat(\".gitignore\"); err == nil {\n\t\tignoreMatcher, _ = gitignore.CompileIgnoreFile(\".gitignore\")\n\t}\n}\nfunc ExitProcess(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\tfmt.Println(text)\n\t}\n\n\tfmt.Println(\"--- Task completed successfully! Exiting...\")\n\treturn map[string]any{\"error\": nil, \"output\": \"Task Completed Successfully\", \"exit\": true}\n\n}\n\nvar CoderCapabilities = []repository.Function{\n\t{\n\t\tName: \"exit-process\",\n\t\tDescription: `Gracefully terminates the coding session with comprehensive completion validation and user satisfaction confirmation.\nPerforms final quality checks, validates all requirements fulfillment, and ensures clean project state before exit.\nTriggers automatic documentation generation, test result summaries, and deployment readiness assessment.\n\nCritical Exit Criteria:\n‚úì All specified tasks completed with verified functionality\n‚úì Code quality standards met (linting, formatting, testing)\n‚úì No unresolved bugs or compilation errors\n‚úì User acceptance and satisfaction confirmed\n‚úì Project documentation updated and accurate`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Professional completion summary and final recommendations for the user. Include project status, deliverables completed, and next steps.\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{},\n\t\t},\n\t\tService: ExitProcess,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string // System error if graceful exit fails\",\n\t\t\t\"output\": \"string // Final completion report and recommendations\",\n\t\t},\n\t},\n\n\t{\n\t\tName: \"execute-command-in-terminal\",\n\t\tDescription: `Advanced terminal command executor with intelligent process management, output streaming, and environment isolation.\nSupports complex command chaining, environment variable injection, and real-time output monitoring.\nProvides sophisticated error handling with context-aware debugging and automatic retry mechanisms.\n\nSpecialized Use Cases:\nüîß Development Operations: Package management, dependency installation, build automation\nüß™ Quality Assurance: Syntax validation, linting, testing, code analysis\nüì¶ Build Systems: Compilation, bundling, optimization, deployment preparation  \nüîç System Analysis: Performance profiling, resource monitoring, diagnostic commands\n‚ö° Performance Optimization: Benchmark execution, memory analysis, CPU profiling\n\nAdvanced Syntax Checking Examples:\n‚Ä¢ C/C++: { \"command\": \"clang++\", \"arguments\": [\"-fsyntax-only\", \"-Wall\", \"-Wextra\", \"source.cpp\"] }\n‚Ä¢ TypeScript: { \"command\": \"tsc\", \"arguments\": [\"--noEmit\", \"--strict\", \"app.ts\"] }\n‚Ä¢ Rust: { \"command\": \"cargo\", \"arguments\": [\"check\", \"--all-features\"] }\n‚Ä¢ Go: { \"command\": \"go\", \"arguments\": [\"vet\", \"./...\"] }`,\n\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Contextual description of the operation being performed for enhanced logging and debugging capabilities.\",\n\t\t\t\t},\n\t\t\t\t\"command\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Primary executable command with full path resolution and environment variable support (e.g., 'npm', 'docker', 'kubectl', 'terraform').\",\n\t\t\t\t},\n\t\t\t\t\"arguments\": {\n\t\t\t\t\tType: repository.TypeArray,\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\tDescription: \"Individual command arguments with proper escaping and parameter validation.\",\n\t\t\t\t\t},\n\t\t\t\t\tDescription: \"Structured argument array supporting complex parameter passing, flag combinations, and multi-value options.\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"command\"},\n\t\t\tOptional: []string{\"text\", \"arguments\"},\n\t\t},\n\n\t\tService: ExecuteCommands,\n\n\t\tReturn: repository.Return{\n\t\t\t\"error\":   \"string // Comprehensive error information including exit codes, stderr output, and diagnostic context\",\n\t\t\t\"output\":  \"string // Complete stdout capture with formatting preservation and encoding handling\",\n\t\t\t\"message\": \"string // Operation status summary with performance metrics and execution context\",\n\t\t},\n\t},\n\n\t{\n\t\tName: \"get-project-structure\",\n\t\tDescription: `Intelligent project architecture analyzer with deep codebase understanding and dependency mapping.\nGenerates comprehensive project topology with file relationships, module dependencies, and architectural patterns.\nRespects configuration files (.gitignore, .dockerignore, etc.) and provides smart filtering for development-relevant content.\n\nAdvanced Features:\nüèóÔ∏è  Architectural Pattern Detection: Identifies MVC, microservices, monorepo structures\nüìä Dependency Graph Generation: Maps import/export relationships and circular dependencies  \nüîç Code Metrics Analysis: LOC, complexity, test coverage distribution\nüìÅ Smart Categorization: Separates source, tests, config, documentation, and assets\n‚ö° Performance Optimized: Handles large codebases with intelligent caching and indexing`,\n\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"path\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Target directory path with support for relative/absolute paths, symlink resolution, and workspace detection ('.' for current directory).\",\n\t\t\t\t},\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Context description for the analysis operation, enabling targeted exploration and focused reporting.\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"path\"},\n\t\t},\n\t\tService: GetProjectStructure,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string // Detailed error information with path resolution and permission issues\",\n\t\t\t\"output\": \"string // Structured project tree with metadata, file types, and architectural insights\",\n\t\t},\n\t},\n\n\t{\n\t\tName: EditFileFromName,\n\t\tDescription: `State-of-the-art multi-operation file editor with atomic transaction support and intelligent change management.\nProvides surgical precision for code modifications with advanced conflict detection and resolution mechanisms.\nSupports complex refactoring operations, batch changes, and syntax-aware transformations.\n\nRevolutionary Capabilities:\nüéØ Precision Targeting: Line-column accurate positioning with Unicode-aware character counting\nüîÑ Atomic Operations: All-or-nothing change application with automatic rollback on conflicts\nüß† Context Awareness: Understands code structure, indentation, and language-specific formatting\nüõ°Ô∏è  Safety Mechanisms: Pre-change validation, backup creation, and integrity verification\n‚ö° Batch Processing: Multiple simultaneous edits with dependency ordering and optimization\n\nSupported Operations:\n‚Ä¢ 'delete': Surgical removal of code blocks with smart whitespace handling\n‚Ä¢ 'replace': Context-aware content replacement with automatic formatting adjustment  \n‚Ä¢ 'write': Intelligent insertion with indentation matching and import management`,\n\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Comprehensive context description explaining the rationale, expected outcomes, and architectural impact of the proposed changes.\",\n\t\t\t\t},\n\t\t\t\t\"file_path\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Absolute or relative file path with intelligent resolution, symlink following, and workspace-aware pathing (e.g., './src/components/App.tsx').\",\n\t\t\t\t},\n\t\t\t\t\"changes\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"Ordered sequence of atomic edit operations with precise targeting, conflict detection, and dependency-aware execution scheduling.\",\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType:        repository.TypeObject,\n\t\t\t\t\t\tDescription: \"Individual edit operation with comprehensive metadata and validation parameters.\",\n\t\t\t\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\t\t\t\"start_line_number\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeInteger,\n\t\t\t\t\t\t\t\tDescription: \"1-indexed starting line number with bounds validation and Unicode-aware line counting.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"start_line_col\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeInteger,\n\t\t\t\t\t\t\t\tDescription: \"0-indexed starting column position with UTF-8 character boundary awareness and tab expansion handling.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"end_line_number\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeInteger,\n\t\t\t\t\t\t\t\tDescription: \"1-indexed ending line number (inclusive) with multi-line operation support and overflow protection.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"end_line_col\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeInteger,\n\t\t\t\t\t\t\t\tDescription: \"0-indexed ending column position (exclusive) with precise character range selection and encoding safety.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"operation\": {\n\t\t\t\t\t\t\t\tEnum:        []string{\"delete\", \"replace\", \"write\"},\n\t\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\t\tDescription: \"Edit operation type: 'delete' (remove selected range), 'replace' (substitute with new content), 'write' (insert at position without removal).\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"content\": {\n\t\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\t\tDescription: \"Replacement or insertion text with automatic encoding detection, line ending normalization, and indentation intelligence.\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRequired: []string{\"start_line_number\", \"start_line_col\", \"end_line_number\", \"end_line_col\", \"operation\", \"content\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"text\", \"file_path\", \"changes\"},\n\t\t},\n\t\tService: EditFile,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string // Detailed failure analysis with conflict resolution suggestions and rollback information\",\n\t\t\t\"output\": \"string // Success confirmation with change summary, performance metrics, and validation results\",\n\t\t},\n\t},\n\n\t{\n\t\tName: RequestUserInputName,\n\t\tDescription: `Advanced interactive communication interface with intelligent prompt generation and response validation.\nProvides context-aware questioning with smart defaults, input validation, and conversation flow management.\nOptimized for gathering requirements, confirming critical operations, and collaborative decision-making.\n\nEnhanced Features:\nüí¨ Smart Prompting: Context-aware question generation with helpful examples and constraints\nüéØ Input Validation: Real-time validation with error correction suggestions and format guidance\n‚è±Ô∏è  Timeout Management: Configurable timeouts with default fallback values and retry mechanisms\nüîí Security Aware: Sensitive input handling with masking options and secure transmission`,\n\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Professionally formatted prompt message with clear instructions, context, examples, and expected input format specifications.\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"text\"},\n\t\t},\n\t\tService: TakeInputFromTerminal,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string // Input collection errors with retry suggestions and alternative interaction methods\",\n\t\t\t\"output\": \"string // User response with validation status and normalized formatting\",\n\t\t},\n\t},\n\n\t{\n\t\tName: \"create-file\",\n\t\tDescription: `Advanced multi-file creation system with intelligent project scaffolding and atomic batch operations.\nSupports sophisticated file generation workflows with template processing, automatic directory creation, and collision handling.\nOptimized for project initialization, code generation, and infrastructure setup with enterprise-grade reliability.\n\nRevolutionary Capabilities:\nüèóÔ∏è  Smart Scaffolding: Automatic directory structure creation with permission management\nüìù Template Processing: Variable interpolation, conditional content, and dynamic generation\nüõ°Ô∏è  Collision Management: Intelligent handling of existing files with backup and merge options\n‚ö° Batch Optimization: Atomic multi-file operations with transaction rollback support\nüîç Content Validation: Syntax checking, encoding verification, and format compliance`,\n\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"file_paths\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\tDescription: \"Array of file paths with intelligent path resolution, directory auto-creation, and naming conflict prevention (e.g., ['src/utils/helper.ts', 'tests/helper.test.ts']).\",\n\t\t\t\t},\n\t\t\t\t\"contents\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\tDescription: \"Corresponding content array with template processing, encoding optimization, and syntax validation for each file creation.\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"file_paths\", \"contents\"},\n\t\t},\n\t\tService: CreateFile,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string // Comprehensive error reporting with file-specific failures and recovery suggestions\",\n\t\t\t\"output\": \"string // Detailed creation summary with file statistics, validation results, and project impact analysis\",\n\t\t},\n\t},\n\n\t{\n\t\tName: \"read-files\",\n\t\tDescription: `High-performance batch file reader with intelligent caching, encoding detection, and content analysis capabilities.\nProvides comprehensive file inspection with metadata extraction, dependency analysis, and code structure understanding.\nEssential for codebase exploration, dependency validation, and informed modification planning.\n\nAdvanced Intelligence:\nüöÄ Performance Optimized: Parallel reading with memory management and streaming for large files\nüß† Content Analysis: Automatic language detection, syntax validation, and structural analysis  \nüîç Smart Filtering: Binary detection, encoding validation, and content-type classification\nüìä Metadata Extraction: File statistics, dependency mapping, and complexity metrics\nüíæ Intelligent Caching: Smart caching with invalidation and memory optimization`,\n\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"file_paths\": {\n\t\t\t\t\tType: repository.TypeArray,\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\tDescription: \"File path with intelligent resolution, symlink handling, and workspace-aware pathing.\",\n\t\t\t\t\t},\n\t\t\t\t\tDescription: \"Array of file paths for batch reading operations with automatic deduplication and dependency ordering.\",\n\t\t\t\t},\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Context description explaining the purpose of reading these files for enhanced logging and operation tracking.\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"file_paths\"},\n\t\t},\n\t\tService: ReadFiles,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string // Detailed error analysis with per-file status and resolution recommendations\",\n\t\t\t\"output\": \"map[string]any // Structured file content mapping with metadata, encoding info, and analysis results\",\n\t\t},\n\t},\n}\n\n// GetCoderCapabilities returns the list of all capabilities for the AgentCoder.\nfunc GetCoderCapabilities() []repository.Function {\n\treturn CoderCapabilities\n}\n\n// GetCoderCapabilitiesArrayMap returns the capabilities as a list of maps for API use.\nfunc GetCoderCapabilitiesArrayMap() []map[string]any {\n\tcoderMap := make([]map[string]any, 0)\n\tfor _, v := range CoderCapabilities {\n\t\tcoderMap = append(coderMap, v.ToObject())\n\t}\n\treturn coderMap\n}\n\n// GetCoderCapabilitiesMap returns the capabilities as a map for internal use.\nfunc GetCoderCapabilitiesMap() map[string]repository.Function {\n\tcoderMap := make(map[string]repository.Function)\n\tfor _, v := range CoderCapabilities {\n\t\tcoderMap[v.Name] = v\n\t}\n\treturn coderMap\n}\nfunc init() {\n\tfor _, v := range CoderCapabilities {\n\t\tCodertoolsFunc[v.Name] = v\n\t}\n}\n",
    "hash": "d06e39186050082f7591ebdf8a71f7ee",
    "size": 51827,
    "tokens": 12956,
    "modified_time": "2026-02-10T12:24:07.452699729+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "GetInitialContext",
      "detectDefaultShell",
      "mustGetWorkingDir",
      "detectTools",
      "getImportantEnvVars",
      "scanProjectFiles",
      "detectProjectType",
      "getGitBranch",
      "checkInternet",
      "getLocalTimezone",
      "generateSessionID",
      "formatFilesForCoder",
      "TakeInputFromTerminal",
      "CreateFile",
      "ReadFiles",
      "ExecuteCommands",
      "EditFile",
      "applyDelete",
      "applyReplace",
      "applyWrite",
      "GetProjectStructure",
      "getProjectStructureRecursive",
      "loadGitIgnore",
      "ExitProcess",
      "GetCoderCapabilities",
      "GetCoderCapabilitiesArrayMap",
      "GetCoderCapabilitiesMap",
      "init"
    ],
    "security": [
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 582,
        "column": 0,
        "code": "fmt.Print(\"dost\u003e \")",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 1294,
        "column": 0,
        "code": "Provides sophisticated error handling with context-aware debugging and automatic retry mechanisms.",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 1314,
        "column": 0,
        "code": "Description: \"Contextual description of the operation being performed for enhanced logging and debugging capabilities.\",",
        "tool": "regex"
      }
    ]
  },
  "d11717aadf9c01a617bb20509aea16a8": {
    "path": "main.go",
    "content": "package main\n\nimport (\n\t\"dost/cmd/app\"\n\t\"os\"\n)\n\nvar Environment = \"dev\"\n\nfunc main() {\n\n\tif app.Execute() != nil {\n\t\tos.Exit(1)\n\t}\n}\n",
    "hash": "d11717aadf9c01a617bb20509aea16a8",
    "size": 133,
    "tokens": 33,
    "modified_time": "2025-12-29T00:01:50.388019397+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "main"
    ]
  },
  "d32babf934967e3985dfed205f1723c4": {
    "path": "internal/service/analysis/analysis.go",
    "content": "package analysis\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"context\"\n\t\"dost/internal/repository\"\n\t\"dost/internal/service\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"time\"\n\n\tgitignore \"github.com/sabhiram/go-gitignore\"\n\t\"github.com/spf13/viper\"\n)\n\nvar defaultIgnore = map[string]bool{\n\t\".git\":         true,\n\t\"node_modules\": true,\n\t\"vendor\":       true,\n\t\".venv\":        true,\n\t\".env\":         true,\n\t\".idea\":        true,\n\t\".vscode\":      true,\n\t\"__pycache__\":  true,\n\t\".dost\":        true,\n}\nvar ignoreMatcher *gitignore.GitIgnore\nvar AnalysisMap = make(map[string]Analysis, 0)\nvar AnalysistoolsFunc map[string]repository.Function = make(map[string]repository.Function)\nvar InputData = make(map[string]any, 0)\nvar FilesRead = make(map[string]any, 0)\n\nvar ChatHistory = make([]map[string]any, 0)\n\ntype Analysis struct {\n\tID              string         `json:\"id\"`\n\tDetailSummary   string         `json:\"detail_summary\"`\n\tSummary         string         `json:\"summary\"`\n\tDomain          string         `json:\"domain\"`\n\tConstraints     Constraints    `json:\"constraints\"`\n\tInputsDetected  Inputs         `json:\"inputs_detected\"`\n\tRisks           []string       `json:\"risks\"`\n\tExpectedOutput  OutputFormat   `json:\"expected_output\"`\n\tOperatingSystem string         `json:\"operating_system\"`\n\tQueryInputs     map[string]any `json:\"query_input\"`\n\tFilesRead       map[string]any `json:\"files_read\"`\n}\n\ntype Constraints struct {\n\tHard []string `json:\"hard\"`\n\tSoft []string `json:\"soft\"`\n}\n\ntype Inputs struct {\n\tFiles       []string `json:\"files,omitempty\"`\n\tEnvironment string   `json:\"environment,omitempty\"`\n\tLanguage    string   `json:\"language,omitempty\"`\n}\n\ntype OutputFormat struct {\n\tFormat     string                 `json:\"format\"`\n\tExample    map[string]interface{} `json:\"example\"`\n\tOutputType string                 `json:\"output_type\"`\n}\n\ntype AgentAnalysis repository.Agent\n\ntype InitialContext struct {\n\tOS              string\n\tArch            string\n\tUser            string\n\tShell           string\n\tCWD             string\n\tGoVersion       string\n\tFolderStructure map[string]any\n\tInstalledTools  []string\n\tEnvVars         map[string]string\n\tProjectFiles    []string\n\tProjectType     string\n\tGitBranch       string\n\tInternetAccess  bool\n\tAgentRole       string\n\tCapabilities    []string\n\tTimezone        string\n\tSessionID       string\n}\n\nfunc GetInitialContext() InitialContext {\n\tctx := InitialContext{\n\t\tOS:              runtime.GOOS,\n\t\tArch:            runtime.GOARCH,\n\t\tUser:            os.Getenv(\"USERNAME\"),\n\t\tShell:           detectDefaultShell(),\n\t\tCWD:             mustGetWorkingDir(),\n\t\tFolderStructure: GetProjectStructure(map[string]any{\"path\": \"./\"}),\n\t\tGoVersion:       runtime.Version(),\n\t\tInstalledTools:  detectTools(),\n\t\tEnvVars:         getImportantEnvVars(),\n\t\tProjectFiles:    scanProjectFiles(),\n\t\tProjectType:     detectProjectType(),\n\t\tGitBranch:       getGitBranch(),\n\t\tInternetAccess:  checkInternet(),\n\t\tTimezone:        getLocalTimezone(),\n\t\tSessionID:       generateSessionID(),\n\t}\n\treturn ctx\n}\n\nfunc detectDefaultShell() string {\n\tif runtime.GOOS == \"windows\" {\n\t\t// prefer PowerShell if present\n\t\tif _, err := exec.LookPath(\"powershell\"); err == nil {\n\t\t\treturn \"powershell\"\n\t\t}\n\t\treturn \"cmd\"\n\t}\n\treturn os.Getenv(\"SHELL\")\n}\n\nfunc mustGetWorkingDir() string {\n\tdir, err := os.Getwd()\n\tif err != nil {\n\t\treturn \".\"\n\t}\n\treturn dir\n}\n\nfunc detectTools() []string {\n\tvar found []string\n\tval := os.Getenv(\"PATH\")\n\tfound = strings.Split(val, \";\")\n\treturn found\n}\n\nfunc getImportantEnvVars() map[string]string {\n\tkeys := []string{\"PATH\", \"GOROOT\", \"GOPATH\", \"JAVA_HOME\"}\n\tenv := make(map[string]string)\n\tfor _, k := range keys {\n\t\tif v := os.Getenv(k); v != \"\" {\n\t\t\tenv[k] = v\n\t\t}\n\t}\n\treturn env\n}\n\nfunc scanProjectFiles() []string {\n\tfiles := []string{}\n\tfilepath.Walk(\".\", func(path string, info os.FileInfo, err error) error {\n\t\tif err == nil \u0026\u0026 !info.IsDir() {\n\t\t\tif strings.HasSuffix(path, \".go\") ||\n\t\t\t\tpath == \"go.mod\" || path == \"package.json\" || path == \"requirements.txt\" ||\n\t\t\t\tpath == \"Dockerfile\" || path == \"README.md\" {\n\t\t\t\tfiles = append(files, path)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn files\n}\n\nfunc detectProjectType() string {\n\tif _, err := os.Stat(\"go.mod\"); err == nil {\n\t\treturn \"Go project\"\n\t}\n\tif _, err := os.Stat(\"package.json\"); err == nil {\n\t\treturn \"Node.js project\"\n\t}\n\tif _, err := os.Stat(\"requirements.txt\"); err == nil {\n\t\treturn \"Python project\"\n\t}\n\treturn \"Unknown\"\n}\n\nfunc getGitBranch() string {\n\tcmd := exec.Command(\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\")\n\tout, err := cmd.Output()\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\treturn strings.TrimSpace(string(out))\n}\n\nfunc checkInternet() bool {\n\tcmd := exec.Command(\"ping\", \"-c\", \"1\", \"8.8.8.8\")\n\tif runtime.GOOS == \"windows\" {\n\t\tcmd = exec.Command(\"ping\", \"-n\", \"1\", \"8.8.8.8\")\n\t}\n\tif err := cmd.Run(); err != nil {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc getLocalTimezone() string {\n\t_, tz := time.Now().Zone()\n\treturn fmt.Sprintf(\"%d min offset\", tz/60)\n}\n\nfunc generateSessionID() string {\n\treturn fmt.Sprintf(\"%d\", time.Now().UnixNano())\n}\n\n// args must and only contains \"query\"\n// Helper function to format files for Gemini\nfunc formatFilesForGemini(filesRead map[string]any) string {\n\tif len(filesRead) == 0 {\n\t\treturn \"\"\n\t}\n\n\tvar result strings.Builder\n\tresult.WriteString(\"=== FILES CONTENT ===\\n\\n\")\n\n\tfor fileName, fileData := range filesRead {\n\t\tresult.WriteString(fmt.Sprintf(\"FILE: %s\\n\", fileName))\n\t\tresult.WriteString(\"=\" + strings.Repeat(\"=\", len(fileName)+6) + \"\\n\")\n\n\t\tif chunks, ok := fileData.([]map[string]any); ok {\n\t\t\tfor _, chunk := range chunks {\n\t\t\t\tif content, exists := chunk[\"content\"].(string); exists {\n\t\t\t\t\tresult.WriteString(content)\n\t\t\t\t\tresult.WriteString(\"\\n\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tresult.WriteString(\"\\n\" + strings.Repeat(\"-\", 50) + \"\\n\\n\")\n\t}\n\n\treturn result.String()\n}\n\nfunc (p *AgentAnalysis) Interaction(args map[string]any) map[string]any {\n\tInitialContext := GetInitialContext()\n\tInitialContextBytes, err := json.Marshal(InitialContext)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": \"Unable to get initial context\"}\n\t}\n\n\t// Build consolidated user message with proper formatting\n\tvar userMessage strings.Builder\n\n\t// Add files content if any\n\tfilesContent := formatFilesForGemini(FilesRead)\n\tif filesContent != \"\" {\n\t\tuserMessage.WriteString(filesContent)\n\t\tuserMessage.WriteString(\"\\n\")\n\t}\n\n\t// Add initial context\n\tuserMessage.WriteString(\"=== INITIAL CONTEXT ===\\n\")\n\tuserMessage.WriteString(string(InitialContextBytes))\n\tuserMessage.WriteString(\"\\n\\n\")\n\n\t// Add the actual query\n\tuserMessage.WriteString(\"=== QUERY ===\\n\")\n\tif query, ok := args[\"query\"].(string); ok {\n\t\tuserMessage.WriteString(query)\n\t}\n\tlog.Println(\"TEST: ANALYSIS: \", userMessage.String()[0:20])\n\t// Add as a single consolidated user message\n\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\"role\": \"user\",\n\t\t\"parts\": []map[string]any{\n\t\t\t{\n\t\t\t\t\"text\": userMessage.String(),\n\t\t\t},\n\t\t},\n\t})\n\n\tfor {\n\t\t// Check if last message was from model and add exit instruction if needed\n\t\tif len(ChatHistory) \u003e 0 \u0026\u0026 ChatHistory[len(ChatHistory)-1][\"role\"] == \"model\" {\n\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\"role\": \"user\",\n\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t{\n\t\t\t\t\t\t\"text\": \"If you feel there is no task left and you have created the Analysis by calling the put-analysis-agent-output function call then and then only call exit-process. Because only that can stop you and finish the program. Don't respond with text, no text output should be there, call the exit-process. Mark It the put-analysis-agent-output should be called before exit. PERIOD\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\n\t\toutput := p.RequestAgent(ChatHistory)\n\n\t\tif output[\"error\"] != nil {\n\t\t\tfmt.Println(\"Error:\", output[\"error\"])\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\toutputData, ok := output[\"output\"].([]map[string]any)\n\t\tif !ok {\n\t\t\tfmt.Println(\"ERROR CONVERTING OUTPUT\")\n\t\t\treturn nil\n\t\t}\n\n\t\tif len(outputData) == 0 {\n\t\t\tfmt.Println(\"No output received\")\n\t\t\tcontinue\n\t\t}\n\n\t\t// Process each output part\n\t\tfor _, part := range outputData {\n\t\t\tpartType, hasType := part[\"type\"].(string)\n\t\t\tif !hasType {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif partType == \"text\" {\n\t\t\t\t// Handle text response\n\t\t\t\tif text, ok := part[\"data\"].(string); ok {\n\t\t\t\t\tfmt.Println(\"Agent:\", text)\n\t\t\t\t}\n\t\t\t} else if partType == \"functionCall\" {\n\t\t\t\t// Handle function call\n\t\t\t\tname, nameOK := part[\"name\"].(string)\n\t\t\t\targsData, argsOK := part[\"args\"].(map[string]any)\n\n\t\t\t\tif !nameOK || !argsOK {\n\t\t\t\t\tfmt.Println(\"Error: invalid function call data\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tfmt.Println(\"Calling function:\", name)\n\n\t\t\t\t// Execute the function\n\t\t\t\tif function, exists := AnalysistoolsFunc[name]; exists {\n\t\t\t\t\tresult := function.Run(argsData)\n\n\t\t\t\t\t// Check for exit condition\n\t\t\t\t\tif _, ok := result[\"exit\"].(bool); ok {\n\t\t\t\t\t\tanalysisID, ok := result[\"output\"].(string)\n\t\t\t\t\t\tif ok {\n\t\t\t\t\t\t\tanalysis := AnalysisMap[analysisID]\n\t\t\t\t\t\t\tanalysis.QueryInputs = InputData\n\t\t\t\t\t\t\tAnalysisMap[analysisID] = analysis\n\t\t\t\t\t\t\treturn map[string]any{\"analysis-id\": result[\"output\"]}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\treturn map[string]any{\"analysis-id\": result}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Add function response to chat history with proper structure\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"functionResponse\": map[string]any{\n\t\t\t\t\t\t\t\t\t\"name\":     name,\n\t\t\t\t\t\t\t\t\t\"response\": result,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\n\t\t\t\t\t// Display result if it's a string\n\t\t\t\t\tif outputStr, ok := result[\"output\"].(string); ok {\n\t\t\t\t\t\tfmt.Println(\"Result:\", outputStr)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfmt.Printf(\"Function %s not found\\n\", name)\n\n\t\t\t\t\t// Add error response to chat history\n\t\t\t\t\tChatHistory = append(ChatHistory, map[string]any{\n\t\t\t\t\t\t\"role\": \"user\",\n\t\t\t\t\t\t\"parts\": []map[string]any{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"text\": fmt.Sprintf(\"Error: Function '%s' not found\", name),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Continue the conversation loop\n\t\tfmt.Println(\"---\")\n\t}\n}\n\nfunc (p *AgentAnalysis) NewAgent() {\n\tmodel := viper.GetString(\"ANALYSIS.MODEL\")\n\tif model == \"\" {\n\t\tmodel = \"gemini-1.5-pro\"\n\t}\n\tendPoints := fmt.Sprintf(\"https://generativelanguage.googleapis.com/v1beta/models/%s:streamGenerateContent?alt=sse\", model)\n\n\tanalysisAgentMeta := repository.AgentMetadata{\n\t\tID:             \"analysis-agent-v1\",\n\t\tName:           \"Analysis Agent\",\n\t\tVersion:        \"1.0.0\",\n\t\tType:           repository.AgentType(repository.AgentAnalysis),\n\t\tInstructions:   repository.AnalysisInstructions,\n\t\tLastActive:     time.Now(),\n\t\tMaxConcurrency: 5,\n\t\tTimeout:        30 * time.Second,\n\t\tStatus:         \"active\",\n\t\tTags:           []string{\"analysis\", \"constraints\", \"inputs\", \"outputs\", \"validation\"},\n\t\tEndpoints: map[string]string{\n\t\t\t\"http\": endPoints,\n\t\t},\n\t}\n\tp.Metadata = analysisAgentMeta\n\tp.Capabilities = AnalysisCapabilities\n}\n\nfunc (p *AgentAnalysis) RequestAgent(contents []map[string]any) map[string]any {\n\tfmt.Printf(\"Processing request with Analysis Agent: %s\\n\", p.Metadata.Name)\n\n\t// Build request payload for the AI model\n\trequest := map[string]any{\n\t\t\"systemInstruction\": map[string]any{\n\t\t\t\"parts\": []map[string]any{\n\t\t\t\t{\"text\": p.Metadata.Instructions},\n\t\t\t},\n\t\t},\n\t\t\"toolConfig\": map[string]any{\n\t\t\t\"functionCallingConfig\": map[string]any{\n\t\t\t\t\"mode\": \"ANY\",\n\t\t\t},\n\t\t},\n\t\t\"contents\": contents,\n\t\t\"tools\": []map[string]any{\n\t\t\t{\"functionDeclarations\": GetAnalysisToolsMap()},\n\t\t},\n\t}\n\n\t// Marshal request body\n\tjsonBody, err := json.Marshal(request)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t}\n\n\t// Retry configuration\n\tconst maxRetries = 5\n\tconst maxWaitTime = 10 * time.Minute\n\n\tfor attempt := 0; attempt \u003c= maxRetries; attempt++ {\n\t\t// Create HTTP request\n\t\treq, err := http.NewRequestWithContext(\n\t\t\tcontext.Background(),\n\t\t\t\"POST\",\n\t\t\tp.Metadata.Endpoints[\"http\"],\n\t\t\tbytes.NewBuffer(jsonBody),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t}\n\n\t\treq.Header.Set(\"Content-Type\", \"application/json\")\n\t\treq.Header.Set(\"X-goog-api-key\", viper.GetString(\"ANALYSIS.API_KEY\"))\n\n\t\t// Execute request with timeout\n\t\tclient := repository.NewStreamingHTTPClient()\n\t\tresp, err := client.Do(req)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\t// Wait before retrying network errors\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\t\tdefer resp.Body.Close()\n\n\t\t// Success case - parse streaming response\n\t\tif resp.StatusCode == http.StatusOK {\n\t\t\t// Parse SSE stream with real-time display\n\t\t\tstreamResp, err := repository.ParseSSEStream(resp.Body, true)\n\t\t\tif err != nil {\n\t\t\t\tif attempt == maxRetries {\n\t\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t\t}\n\t\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Convert to standard output format\n\t\t\toutput := repository.ConvertStreamResponseToOutput(streamResp)\n\n\t\t\t// Save chat history\n\t\t\thistoryEntry := repository.BuildChatHistoryFromStream(streamResp, \"analysis\")\n\t\t\tif historyEntry != nil {\n\t\t\t\tChatHistory = append(ChatHistory, historyEntry)\n\t\t\t}\n\n\t\t\tp.Metadata.LastActive = time.Now()\n\t\t\treturn map[string]any{\"error\": nil, \"output\": output}\n\t\t}\n\n\t\t// Read body for error cases\n\t\tbodyBytes, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\"error\": err.Error(), \"output\": nil}\n\t\t\t}\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Handle rate limit errors (429)\n\t\tif resp.StatusCode == http.StatusTooManyRequests {\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Rate limit exceeded after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Parse retry delay from response\n\t\t\tretryDelay := repository.ParseRetryDelay(string(bodyBytes))\n\n\t\t\t// Use provided delay or fallback to exponential backoff\n\t\t\tvar waitTime time.Duration\n\t\t\tif retryDelay \u003e 0 {\n\t\t\t\twaitTime = retryDelay\n\t\t\t} else {\n\t\t\t\twaitTime = repository.ExponentialBackoff(attempt)\n\t\t\t}\n\n\t\t\t// Cap wait time to reasonable maximum\n\t\t\tif waitTime \u003e maxWaitTime {\n\t\t\t\twaitTime = maxWaitTime\n\t\t\t}\n\n\t\t\tfmt.Printf(\"Rate limit hit (attempt %d/%d). Waiting %v before retry...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, waitTime)\n\n\t\t\ttime.Sleep(waitTime)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Handle other HTTP errors\n\t\tif resp.StatusCode \u003e= 500 \u0026\u0026 resp.StatusCode \u003c 600 {\n\t\t\t// Server errors - retry with backoff\n\t\t\tif attempt == maxRetries {\n\t\t\t\treturn map[string]any{\n\t\t\t\t\t\"error\": fmt.Sprintf(\"Server error after %d retries. HTTP %d: %s\",\n\t\t\t\t\t\tmaxRetries, resp.StatusCode, string(bodyBytes)),\n\t\t\t\t\t\"output\": nil,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfmt.Printf(\"Server error (attempt %d/%d). Waiting %v before retry...\\n\",\n\t\t\t\tattempt+1, maxRetries+1, repository.ExponentialBackoff(attempt))\n\n\t\t\ttime.Sleep(repository.ExponentialBackoff(attempt))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Client errors (400-499) except 429 - don't retry\n\t\treturn map[string]any{\n\t\t\t\"error\":  fmt.Sprintf(\"HTTP %d: %s\", resp.StatusCode, string(bodyBytes)),\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"error\":  fmt.Sprintf(\"Max retries (%d) exceeded\", maxRetries),\n\t\t\"output\": nil,\n\t}\n}\n\n// GetProjectStructure returns the project structure as a string, ignoring files and directories specified in .gitignore.\n// If a .gitignore file is not found, it uses a default ignore list.\n// It takes the project path as input.\nfunc GetProjectStructure(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\tfmt.Println(text)\n\t}\n\n\tloadGitIgnore()\n\tpath := args[\"path\"].(string)\n\tvar builder strings.Builder\n\tbuilder.WriteString(path + \"\\n\")\n\terr := getProjectStructureRecursive(path, \"\", \u0026builder)\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err, \"output\": nil}\n\t}\n\n\tif builder.String() == \".\" || builder.String() == \"\" {\n\t\treturn map[string]any{\"error\": nil, \"output\": \"\u003cempty directory\u003e\"}\n\t}\n\treturn map[string]any{\"error\": nil, \"output\": builder.String()}\n}\n\n// PutAgentOutput converts a generic map into AnalysisAgentOutput and prints/stores the JSON.\nfunc PutAgentOutput(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\tfmt.Println(text)\n\t}\n\n\tdata, err := json.Marshal(args)\n\tif err != nil {\n\t\tfmt.Println(\"Error marshaling args:\", err)\n\t\treturn map[string]any{\"error\": err}\n\t}\n\tvar output Analysis\n\tif err := json.Unmarshal(data, \u0026output); err != nil {\n\t\tfmt.Println(\" Error unmarshaling into AnalysisAgentOutput:\", err)\n\t\treturn map[string]any{\"error\": err}\n\t}\n\toutput.OperatingSystem = runtime.GOOS\n\toutput.FilesRead = FilesRead\n\tAnalysisMap[output.ID] = output\n\n\tfmt.Printf(\"‚Ä¶ Stored analysis for task %s\\n\", output.ID)\n\n\treturn map[string]any{\"error\": nil, \"output\": output.ID}\n}\n\nfunc TakeInputFromTerminal(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif !ok {\n\t\treturn map[string]any{\"error\": \"No Text Provided\"}\n\t}\n\tfmt.Println(text)\n\n\trequirements, ok := args[\"requirements\"].([]any)\n\tif !ok || len(requirements) == 0 {\n\t\treturn map[string]any{\n\t\t\t\"error\":  nil,\n\t\t\t\"output\": map[string]string{\"message\": \"No requirements provided\"},\n\t\t}\n\t}\n\n\tresults := make(map[string]string)\n\treader := bufio.NewReader(os.Stdin)\n\n\tfor _, req := range requirements {\n\t\tquestion, ok := req.(string)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tfmt.Printf(\"dost\u003e %s: \", question)\n\t\tinput, err := reader.ReadString('\\n')\n\t\tif err != nil {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  fmt.Sprintf(\"Error reading input: %v\", err),\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\n\t\tinput = strings.TrimSpace(input)\n\t\tif input == \"\" {\n\t\t\tresults[question] = \"\u003cno input provided\u003e\"\n\t\t} else {\n\t\t\tresults[question] = input\n\t\t}\n\t\tInputData[question] = results[question]\n\t}\n\n\treturn map[string]any{\"error\": nil, \"output\": results}\n}\n\nfunc ExitProcess(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok \u0026\u0026 text != \"\" {\n\t\tfmt.Println(text)\n\t}\n\n\tfmt.Println(\"--- Task completed successfully! Exiting...\")\n\treturn map[string]any{\"error\": nil, \"output\": args[\"analysis-id\"], \"exit\": true}\n\n}\nfunc ReadFiles(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Printf(\"ANALYSIS: %s\", text)\n\t}\n\n\tfileNames, ok := args[\"file_names\"].([]interface{})\n\tif !ok {\n\t\treturn map[string]any{\n\t\t\t\"error\":  \"Invalid arguments: 'file_names' must be a slice of strings\",\n\t\t\t\"output\": nil,\n\t\t}\n\t}\n\n\tvar stringFileNames []string\n\tfor _, v := range fileNames {\n\t\ts, ok := v.(string)\n\t\tif !ok {\n\t\t\treturn map[string]any{\n\t\t\t\t\"error\":  \"Invalid argument: 'file_names' contains non-string values\",\n\t\t\t\t\"output\": nil,\n\t\t\t}\n\t\t}\n\t\tstringFileNames = append(stringFileNames, s)\n\t}\n\n\treadFiles := make(map[string]any)\n\tvar notFoundFiles []string\n\n\tfor _, fileName := range stringFileNames {\n\t\tfile, err := os.Open(fileName)\n\t\tif err != nil {\n\t\t\tnotFoundFiles = append(notFoundFiles, fileName)\n\t\t\tcontinue\n\t\t}\n\t\tdefer file.Close()\n\n\t\t// Read all lines, skipping empty ones\n\t\tscanner := bufio.NewScanner(file)\n\t\tvar lines []string\n\t\tlineNumber := 1\n\t\tfor scanner.Scan() {\n\t\t\tline := scanner.Text()\n\t\t\t// Skip empty lines but track line numbers\n\t\t\tif strings.TrimSpace(line) != \"\" {\n\t\t\t\t// Add line number prefix to non-empty lines\n\t\t\t\tnumberedLine := fmt.Sprintf(\"%d: %s\", lineNumber, line)\n\t\t\t\tlines = append(lines, numberedLine)\n\t\t\t}\n\t\t\tlineNumber++\n\t\t}\n\n\t\tif err := scanner.Err(); err != nil {\n\t\t\treadFiles[fileName] = fmt.Sprintf(\"Error reading file: %v\", err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create proper chunks (non-overlapping)\n\t\tchunks := []map[string]any{}\n\t\tchunkSize := 40\n\t\tif len(lines) \u003c 100 {\n\t\t\tchunks = []map[string]any{{\n\t\t\t\t\"start\":   1,\n\t\t\t\t\"end\":     len(lines),\n\t\t\t\t\"content\": strings.Join(lines, \"\\n\"),\n\t\t\t}}\n\t\t} else {\n\t\t\tfor i := 0; i \u003c len(lines); i += chunkSize {\n\t\t\t\tend := i + chunkSize\n\t\t\t\tif end \u003e len(lines) {\n\t\t\t\t\tend = len(lines)\n\t\t\t\t}\n\n\t\t\t\t// Build chunk content\n\t\t\t\tvar chunkContent strings.Builder\n\t\t\t\tfor j := i; j \u003c end; j++ {\n\t\t\t\t\tchunkContent.WriteString(lines[j])\n\t\t\t\t\tif j \u003c end-1 { // Don't add newline after last line in chunk\n\t\t\t\t\t\tchunkContent.WriteString(\"\\n\")\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tchunks = append(chunks, map[string]any{\n\t\t\t\t\t\"start\":   i + 1,\n\t\t\t\t\t\"end\":     end,\n\t\t\t\t\t\"content\": chunkContent.String(),\n\t\t\t\t})\n\t\t\t}\n\n\t\t\t// Handle empty file edge case (all lines were empty)\n\t\t\tif len(lines) == 0 {\n\t\t\t\tchunks = append(chunks, map[string]any{\n\t\t\t\t\t\"start\":   1,\n\t\t\t\t\t\"end\":     0,\n\t\t\t\t\t\"content\": \"\",\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\treadFiles[fileName] = chunks\n\t\t// Also append to the global FilesRead map\n\t\tFilesRead[fileName] = chunks\n\t\tfmt.Printf(\"Read file: %s (%d non-empty lines, %d chunks)\\n\", fileName, len(lines), len(chunks))\n\t}\n\n\tif len(notFoundFiles) \u003e 0 {\n\t\tfmt.Printf(\"Files not found: %v\\n\", notFoundFiles)\n\t}\n\n\treturn map[string]any{\"error\": nil, \"output\": readFiles}\n}\n\nfunc ExecuteCommands(args map[string]any) map[string]any {\n\ttext, ok := args[\"text\"].(string)\n\tif ok {\n\t\tfmt.Println(text)\n\t}\n\n\t// Get current working directory\n\twd, err := os.Getwd()\n\tif err != nil {\n\t\treturn map[string]any{\"error\": err.Error()}\n\t}\n\n\t// Extract command\n\tcmdStr, ok := args[\"command\"].(string)\n\tif !ok || cmdStr == \"\" {\n\t\treturn map[string]any{\"error\": \"Invalid command\"}\n\t}\n\n\t// Extract arguments (as array instead of a single string)\n\tvar argList []string\n\tif rawArgs, ok := args[\"arguments\"]; ok {\n\t\tswitch v := rawArgs.(type) {\n\t\tcase string:\n\t\t\t// split on spaces if user passed a string\n\t\t\tif v != \"\" {\n\t\t\t\targList = strings.Fields(v)\n\t\t\t}\n\t\tcase []any:\n\t\t\tfor _, a := range v {\n\t\t\t\tif s, ok := a.(string); ok {\n\t\t\t\t\targList = append(argList, s)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfmt.Println(\"\u003eDOST\\\\\")\n\tfmt.Printf(\"%s %v\", cmdStr, argList)\n\tif !service.TakePermission {\n\t\tfmt.Printf(\"\\nAbout to run command in %s:\\n\u003e %s\\nPress ENTER to continue or Ctrl+C to cancel...\", wd, argList)\n\t\tbufio.NewReader(os.Stdin).ReadBytes('\\n') // wait for Enter\n\t}\n\n\t// Handle `cd` separately\n\tif cmdStr == \"cd\" {\n\t\tif len(argList) == 0 {\n\t\t\treturn map[string]any{\"error\": \"cd requires a path\"}\n\t\t}\n\t\tnewDir := argList[0]\n\t\tif !filepath.IsAbs(newDir) {\n\t\t\tnewDir = filepath.Join(wd, newDir)\n\t\t}\n\t\tif err := os.Chdir(newDir); err != nil {\n\t\t\treturn map[string]any{\"error\": fmt.Sprintf(\"failed to change directory: %v\", err)}\n\t\t}\n\t\treturn map[string]any{\"message\": fmt.Sprintf(\"Changed directory to %s\", newDir)}\n\t}\n\n\t// Build command properly\n\tcmd := exec.Command(cmdStr, argList...)\n\tcmd.Dir = wd\n\tvar stdoutBuf, stderrBuf bytes.Buffer\n\tcmd.Stdin = os.Stdin\n\tcmd.Stdout = io.MultiWriter(os.Stdout, \u0026stdoutBuf)\n\tcmd.Stderr = io.MultiWriter(os.Stderr, \u0026stderrBuf)\n\n\tlog.Default().Printf(\"Running command in %s: %s %v\\n\", wd, cmdStr, argList)\n\n\terr = cmd.Run()\n\tif err != nil {\n\t\treturn map[string]any{\n\t\t\t\"error\": fmt.Sprintf(\"command failed: [%s %v] %v || CONSOLE/TERMINAL:%v\",\n\t\t\t\tcmdStr, argList, err, stderrBuf.String()),\n\t\t}\n\t}\n\n\treturn map[string]any{\n\t\t\"message\": \"Command executed successfully\",\n\t\t\"output\":  stdoutBuf.String(),\n\t}\n}\n\nfunc getProjectStructureRecursive(path string, prefix string, builder *strings.Builder) error {\n\tentries, err := os.ReadDir(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor i, entry := range entries {\n\t\tentryPath := filepath.Join(path, entry.Name())\n\n\t\t// skip ignored entries\n\t\tif ignoreMatcher != nil {\n\t\t\trelPath, _ := filepath.Rel(\".\", entryPath)\n\t\t\tif ignoreMatcher.MatchesPath(relPath) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tif defaultIgnore[entry.Name()] {\n\t\t\t// ‚úÖ Skip this directory and its contents completely\n\t\t\tif entry.IsDir() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// draw branch\n\t\tconnector := \"‚îú‚îÄ‚îÄ\"\n\t\tif i == len(entries)-1 {\n\t\t\tconnector = \"‚îî‚îÄ‚îÄ\"\n\t\t}\n\t\tbuilder.WriteString(prefix + connector + \" \" + entry.Name() + \"\\n\")\n\n\t\t// recursively descend\n\t\tif entry.IsDir() {\n\t\t\tsubPrefix := prefix\n\t\t\tif i == len(entries)-1 {\n\t\t\t\tsubPrefix += \"    \"\n\t\t\t} else {\n\t\t\t\tsubPrefix += \"‚îÇ   \"\n\t\t\t}\n\t\t\t// üö´ Don't go inside ignored directories\n\t\t\tif !defaultIgnore[entry.Name()] {\n\t\t\t\terr := getProjectStructureRecursive(entryPath, subPrefix, builder)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc loadGitIgnore() {\n\tif _, err := os.Stat(\".gitignore\"); err == nil {\n\t\tignoreMatcher, _ = gitignore.CompileIgnoreFile(\".gitignore\")\n\t}\n}\n\nvar AnalysisCapabilities = []repository.Function{\n\t{\n\t\tName: \"get-project-strucuture\",\n\t\tDescription: `Returns the full directory structure of the project at the given path.\n\t\tCall this before working on unfamiliar projects to understand where files are located.\n\t\tRespects .gitignore to skip irrelevant files.`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"path\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Path to the project directory (usually '.')\",\n\t\t\t\t},\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"A text which you want to say to user, instead of returning text output give it in this parameter\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"path\"},\n\t\t},\n\t\tService: GetProjectStructure,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string\",\n\t\t\t\"output\": \"string\",\n\t\t},\n\t},\n\t{\n\t\tName: \"read-files\",\n\t\tDescription: `Read and analyze multiple files efficiently in a single operation. \n\t\n\tIMPORTANT: This function can read MULTIPLE files simultaneously - pass ALL file paths you need in the file_names array rather than calling this function multiple times for individual files.\n\t\n\tKey features:\n\t- Reads multiple files in one call (more efficient than multiple separate calls)\n\t- Automatically skips empty lines to save tokens and improve clarity\n\t- Adds line numbers to each line for precise reference and debugging\n\t- Chunks large files automatically for better processing\n\t- Stores read files globally for reuse across the session\n\t\n\tBest practices:\n\t- Pass ALL required file paths in a single call: [\"file1.go\", \"file2.md\", \"file3.txt\"]\n\t- Use when you need to analyze code structure, configuration files, documentation, or any text-based content\n\t- Ideal for cross-file analysis, dependency checking, or comprehensive codebase review\n\t\n\tExample usage scenarios:\n\t- Code analysis: [\"main.go\", \"utils.go\", \"config.yaml\"]\n\t- Documentation review: [\"README.md\", \"CHANGELOG.md\", \"API.md\"]\n\t- Configuration audit: [\"docker-compose.yml\", \".env\", \"nginx.conf\"]\n\t\n\tThe function returns structured data with line numbers, making it easy to reference specific parts of files in subsequent analysis.`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Optional message to display to the user explaining what files you're reading and why, instead of just returning output silently\",\n\t\t\t\t},\n\t\t\t\t\"file_names\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"Array of file paths to read simultaneously. IMPORTANT: Include ALL files you need in this single array rather than making multiple function calls. Examples: ['main.go', 'config.yaml'], ['src/app.js', 'package.json', 'README.md']\",\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType: \"string\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"file_names\"},\n\t\t},\n\t\tService: ReadFiles,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string - null if successful, error message if failed\",\n\t\t\t\"output\": \"object - map of filename to chunks with line numbers and content\",\n\t\t},\n\t},\n\t{\n\t\tName: \"put-analysis-agent-output\",\n\t\tDescription: `Stores the output of the analysis agent in the in-memory map.\nUse this after completing an analysis to persist the structured result (constraints, inputs, risks, expected output).`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"id\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Unique identifier for the analysis task\",\n\t\t\t\t},\n\t\t\t\t\"detail_summary\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Detailed summary of the analysis\",\n\t\t\t\t},\n\t\t\t\t\"summary\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Concise summary of the analysis\",\n\t\t\t\t},\n\t\t\t\t\"domain\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Domain or area of the task (e.g., software, AI, data)\",\n\t\t\t\t},\n\t\t\t\t\"constraints\": {\n\t\t\t\t\tType: repository.TypeObject,\n\t\t\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\t\t\"hard\": {\n\t\t\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\t\t\tDescription: \"Hard constraints (must follow)\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"soft\": {\n\t\t\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\t\t\tDescription: \"Soft constraints (nice to follow)\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"inputs_detected\": {\n\t\t\t\t\tType: repository.TypeObject,\n\t\t\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\t\t\"files\": {\n\t\t\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\t\t\tDescription: \"Files detected in the project\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"environment\": {\n\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\tDescription: \"Execution environment (Go, Python, Docker, etc.)\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"language\": {\n\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\tDescription: \"Programming language(s) involved\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"risks\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tItems:       \u0026repository.Properties{Type: repository.TypeString},\n\t\t\t\t\tDescription: \"List of identified risks or blockers\",\n\t\t\t\t},\n\t\t\t\t\"expected_output\": {\n\t\t\t\t\tType: repository.TypeObject,\n\t\t\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\t\t\"format\": {\n\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\tDescription: \"Format of the output (JSON, text, etc.)\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"example\": {\n\t\t\t\t\t\t\tType:        repository.TypeObject,\n\t\t\t\t\t\t\tDescription: \"Example of expected output structure\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"output_type\": {\n\t\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\t\tDescription: \"Type of output (code, report, data, etc.)\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"A text which you want to say to user, instead of returning text output give it in this parameter\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\n\t\t\t\t\"id\",\n\t\t\t\t\"detail_summary\",\n\t\t\t\t\"summary\",\n\t\t\t\t\"domain\",\n\t\t\t\t\"constraints\",\n\t\t\t\t\"inputs_detected\",\n\t\t\t\t\"risks\",\n\t\t\t\t\"expected_output\",\n\t\t\t\t\"text\",\n\t\t\t},\n\t\t},\n\t\tService: PutAgentOutput,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string\",\n\t\t\t\"output\": \"string\",\n\t\t},\n\t},\n\t{\n\t\tName: \"take-input-from-terminal\",\n\t\tDescription: `Prompts the user in the terminal for multiple required inputs.\nUse this whenever you are missing essential details, such as:\n- File names\n- Function parameters\n- Configuration values\n- User choices`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"requirements\": {\n\t\t\t\t\tType:        repository.TypeArray,\n\t\t\t\t\tDescription: \"A list of questions or keys to ask the user for input\",\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType: \"string\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"A text which you want to say to user, instead of returning text output give it in this parameter\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"requirements\", \"text\"},\n\t\t},\n\t\tService: TakeInputFromTerminal,\n\t\tReturn:  repository.Return{\"error\": \"string\", \"output\": \"object\"},\n\t},\n\n\t{\n\t\tName: \"exit-process\",\n\t\tDescription: `When you feel that the task is fully completed, always call this function to exit the process.\n‚ö†Ô∏è Important:\n- Before calling, make sure all steps are done.\n- Put that final compiled text inside the \"text\" parameter. This is what the user will see as the final answer.`,\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"The final compiled text output for the user (summary, results, explanations, etc.)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"text\"},\n\t\t},\n\t\tService: ExitProcess,\n\t\tReturn: repository.Return{\n\t\t\t\"error\":  \"string\",\n\t\t\t\"output\": \"string\",\n\t\t},\n\t},\n\n\t{\n\t\tName: \"execute-command-in-terminal\",\n\t\tDescription: `Execute ANY valid shell/terminal command with full system access in the current working directory.\nThis tool provides COMPLETE command-line interface capabilities, enabling:\n\nüöÄ PROJECT MANAGEMENT \u0026 SETUP:\n- Initialize projects: npm init, cargo new, go mod init, django-admin startproject\n- Setup frameworks: create-react-app, vue create, ng new, rails new\n- Generate scaffolding: rails generate, ng generate, vue add\n- Project templates: cookiecutter, yeoman generators, custom templates\n\nüìÅ FILE \u0026 DIRECTORY OPERATIONS:\n- Navigation: cd, ls, pwd, find, locate, which, whereis\n- File management: cp, mv, rm, mkdir, rmdir, touch, ln\n- Permissions: chmod, chown, chgrp, umask, getfacl, setfacl\n- Content operations: cat, head, tail, grep, sed, awk, sort, uniq\n- Archives: tar, zip, unzip, gzip, gunzip, 7z\n- File comparison: diff, cmp, comm\n\nüîß DEVELOPMENT TOOLS \u0026 BUILD SYSTEMS:\n- Compilers: gcc, g++, clang, rustc, javac, tsc, babel\n- Interpreters: python, node, ruby, php, lua, perl\n- Build tools: make, cmake, ninja, gradle, maven, ant, bazel\n- Task runners: npm run, yarn, pnpm, gulp, grunt, webpack\n- Linters: eslint, pylint, rubocop, clippy, checkstyle\n- Formatters: prettier, black, gofmt, rustfmt, clang-format\n\nüì¶ PACKAGE MANAGEMENT:\n- Node.js: npm, yarn, pnpm (install, update, audit, publish)\n- Python: pip, pip3, pipenv, poetry, conda\n- Rust: cargo (build, test, publish, update)\n- Go: go get, go mod (download, tidy, vendor)\n- Ruby: gem, bundle\n- PHP: composer\n- Java: mvn, gradle\n- System packages: apt, yum, brew, choco, pacman\n\nüîÑ VERSION CONTROL (GIT \u0026 OTHERS):\n- Git operations: init, clone, add, commit, push, pull, merge, rebase\n- Branch management: checkout, branch, switch, merge, rebase\n- History: log, show, diff, blame, reflog\n- Stashing: stash, stash pop, stash apply\n- Remote management: remote add, fetch, pull, push\n- Tags: tag, tag -a, tag -d\n- Other VCS: svn, hg, bzr\n\nüóÑÔ∏è DATABASE OPERATIONS:\n- SQL databases: mysql, psql, sqlite3, sqlcmd\n- NoSQL: mongo, redis-cli, couchdb\n- Migrations: migrate, flyway, liquibase\n- Dumps \u0026 restores: mysqldump, pg_dump, mongodump\n\nüåê NETWORK \u0026 API OPERATIONS:\n- HTTP requests: curl, wget, httpie\n- Network tools: ping, telnet, netstat, ss, lsof\n- DNS: nslookup, dig, host\n- Certificates: openssl, certbot\n- API testing: postman-cli, newman\n\nüê≥ CONTAINERIZATION \u0026 ORCHESTRATION:\n- Docker: build, run, exec, ps, images, compose\n- Kubernetes: kubectl (apply, get, describe, logs, exec)\n- Container registries: docker push, docker pull\n- Orchestration: docker-compose, docker swarm\n\n‚òÅÔ∏è CLOUD \u0026 INFRASTRUCTURE:\n- AWS CLI: aws s3, ec2, lambda, cloudformation\n- Azure CLI: az vm, az storage, az webapp\n- Google Cloud: gcloud compute, gsutil\n- Terraform: plan, apply, destroy\n- Ansible: ansible-playbook, ansible-vault\n\nüîç SYSTEM MONITORING \u0026 DEBUGGING:\n- Process management: ps, top, htop, kill, killall, jobs\n- System info: uname, whoami, id, groups, env\n- Disk usage: df, du, fdisk, lsblk\n- Memory: free, vmstat\n- Performance: iostat, sar, strace, ltrace\n- Logs: journalctl, tail -f, grep logs\n\nüß™ TESTING \u0026 QUALITY ASSURANCE:\n- Unit tests: pytest, jest, go test, cargo test, rspec\n- Integration tests: newman, postman, cypress\n- Load testing: ab, siege, wrk, jmeter\n- Security scans: nmap, nikto, owasp-zap\n- Code coverage: coverage.py, nyc, gocov\n- Benchmarking: hyperfine, bench, criterion\n\nüîê SECURITY \u0026 ENCRYPTION:\n- SSH operations: ssh, scp, ssh-keygen, ssh-add\n- Encryption: gpg, openssl, age\n- Certificates: certbot, openssl req, keytool\n- Password management: pass, 1password-cli\n- Security scanning: bandit, safety, audit\n\nüìä DATA PROCESSING \u0026 ANALYSIS:\n- Text processing: sed, awk, grep, sort, cut, tr\n- JSON/XML: jq, xmlstarlet, yq\n- CSV processing: csvkit, miller\n- Data conversion: pandoc, iconv\n- Statistical tools: R, octave\n\nüéØ AUTOMATION \u0026 SCRIPTING:\n- Shell scripting: bash, zsh, fish, powershell\n- Task scheduling: cron, at, systemd timers\n- Process automation: expect, tmux, screen\n- Workflow tools: github-cli, gitlab-ci\n\nüñ•Ô∏è SYSTEM ADMINISTRATION:\n- Service management: systemctl, service, launchctl\n- User management: useradd, usermod, passwd, su, sudo\n- Network configuration: ifconfig, ip, route\n- Firewall: iptables, ufw, firewall-cmd\n- Package repositories: add-apt-repository, yum-config-manager\n\nüîß LANGUAGE-SPECIFIC TOOLS:\n- Node.js: node, npm, yarn, npx, nvm\n- Python: python, pip, virtualenv, conda, jupyter\n- Go: go build, go test, go mod, go generate\n- Rust: cargo build, cargo test, cargo publish\n- Java: java, javac, maven, gradle\n- C/C++: gcc, g++, make, cmake, gdb\n- .NET: dotnet build, dotnet run, dotnet test\n- Ruby: ruby, gem, bundle, rails\n- PHP: php, composer, artisan\n\n‚ö° PERFORMANCE \u0026 OPTIMIZATION:\n- Profiling: perf, gprof, valgrind, pprof\n- Benchmarking: time, hyperfine, ab\n- Memory analysis: valgrind, AddressSanitizer\n- Code optimization: compiler flags, link-time optimization\n\nüîÑ CI/CD \u0026 DEPLOYMENT:\n- GitHub Actions: gh workflow, gh run\n- Jenkins: jenkins-cli\n- Docker deployment: docker deploy, docker service\n- Serverless: serverless deploy, sam deploy\n- Static sites: netlify, vercel\n\nSYNTAX CHECKING \u0026 VALIDATION:\n- C/C++: g++ -fsyntax-only, clang -fsyntax-only\n- Python: python -m py_compile, python -m flake8\n- JavaScript: node --check, eslint\n- Go: go vet, go fmt -n\n- Rust: cargo check\n- JSON: jq empty, python -m json.tool\n- YAML: yamllint, python -c \"import yaml\"\n- XML: xmllint --noout\n\nADVANCED OPERATIONS:\n- Parallel processing: parallel, xargs -P\n- Process monitoring: watch, timeout\n- Binary analysis: objdump, nm, readelf, strings\n- System calls: strace, dtrace\n- Network debugging: tcpdump, wireshark-cli\n\nIMPORTANT USAGE NOTES:\n- This tool has FULL system access - use responsibly\n- Can modify files, install software, change system settings\n- Can access network resources and external APIs\n- Can start/stop services and processes\n- Always verify commands before execution in production\n- Use appropriate error handling and validation\n\nEXAMPLES:\n\nProject Setup:\n{ \"command\": \"npx\", \"arguments\": [\"create-react-app\", \"my-app\", \"--template\", \"typescript\"] }\n{ \"command\": \"cargo\", \"arguments\": [\"new\", \"my-rust-project\"] }\n{ \"command\": \"django-admin\", \"arguments\": [\"startproject\", \"mysite\"] }\n\nDevelopment:\n{ \"command\": \"npm\", \"arguments\": [\"install\", \"express\", \"cors\", \"dotenv\"] }\n{ \"command\": \"go\", \"arguments\": [\"mod\", \"init\", \"github.com/user/project\"] }\n{ \"command\": \"pip\", \"arguments\": [\"install\", \"-r\", \"requirements.txt\"] }\n\nGit Operations:\n{ \"command\": \"git\", \"arguments\": [\"clone\", \"https://github.com/user/repo.git\"] }\n{ \"command\": \"git\", \"arguments\": [\"add\", \".\", \"\u0026\u0026\", \"git\", \"commit\", \"-m\", \"Initial commit\"] }\n{ \"command\": \"git\", \"arguments\": [\"push\", \"origin\", \"main\"] }\n\nTesting \u0026 Quality:\n{ \"command\": \"pytest\", \"arguments\": [\"tests/\", \"-v\", \"--coverage\"] }\n{ \"command\": \"eslint\", \"arguments\": [\"src/\", \"--fix\"] }\n{ \"command\": \"cargo\", \"arguments\": [\"test\", \"--release\"] }\n\nSystem Operations:\n{ \"command\": \"docker\", \"arguments\": [\"build\", \"-t\", \"myapp\", \".\"] }\n{ \"command\": \"systemctl\", \"arguments\": [\"start\", \"nginx\"] }\n{ \"command\": \"curl\", \"arguments\": [\"-X\", \"POST\", \"https://api.example.com/data\"] }\n\nThis tool is your gateway to the ENTIRE command-line ecosystem. Use it to automate, build, deploy, test, monitor, and manage any aspect of software development and system administration.`,\n\n\t\tParameters: repository.Parameters{\n\t\t\tType: repository.TypeObject,\n\t\t\tProperties: map[string]*repository.Properties{\n\t\t\t\t\"text\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"Optional context message for logging, debugging, or providing additional information about the command execution.\",\n\t\t\t\t},\n\t\t\t\t\"command\": {\n\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\tDescription: \"The base command to execute. Can be any valid system command, tool, or executable available in the PATH or specified with full path.\",\n\t\t\t\t},\n\t\t\t\t\"arguments\": {\n\t\t\t\t\tType: repository.TypeArray,\n\t\t\t\t\tItems: \u0026repository.Properties{\n\t\t\t\t\t\tType:        repository.TypeString,\n\t\t\t\t\t\tDescription: \"Individual command arguments, flags, options, and parameters.\",\n\t\t\t\t\t},\n\t\t\t\t\tDescription: \"Array of command arguments. Each element should be a separate argument (proper shell escaping handled automatically).\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRequired: []string{\"command\"},\n\t\t\tOptional: []string{\"text\", \"arguments\"},\n\t\t},\n\n\t\tService: ExecuteCommands,\n\n\t\tReturn: repository.Return{\n\t\t\t\"error\":   \"string // Detailed error message including command, arguments, exit code, and stderr output if execution fails.\",\n\t\t\t\"output\":  \"string // Complete stdout output from the executed command.\",\n\t\t\t\"message\": \"string // Success confirmation message with command execution details.\",\n\t\t},\n\t},\n}\n\nfunc init() {\n\tfor _, v := range AnalysisCapabilities {\n\t\tAnalysistoolsFunc[v.Name] = v\n\t}\n}\n\nfunc AnalysisTools() map[string]repository.Function {\n\treturn AnalysistoolsFunc\n}\n\nfunc GetAnalysisTools() []repository.Function {\n\treturn AnalysisCapabilities\n}\n\nfunc GetAnalysisToolsMap() []map[string]any {\n\tarrayOfMap := make([]map[string]any, 0)\n\tfor _, v := range AnalysisCapabilities {\n\t\tarrayOfMap = append(arrayOfMap, v.ToObject())\n\t}\n\treturn arrayOfMap\n}\n",
    "hash": "d32babf934967e3985dfed205f1723c4",
    "size": 41594,
    "tokens": 10398,
    "modified_time": "2026-02-10T12:24:03.335570557+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "GetInitialContext",
      "detectDefaultShell",
      "mustGetWorkingDir",
      "detectTools",
      "getImportantEnvVars",
      "scanProjectFiles",
      "detectProjectType",
      "getGitBranch",
      "checkInternet",
      "getLocalTimezone",
      "generateSessionID",
      "formatFilesForGemini",
      "GetProjectStructure",
      "PutAgentOutput",
      "TakeInputFromTerminal",
      "ExitProcess",
      "ReadFiles",
      "ExecuteCommands",
      "getProjectStructureRecursive",
      "loadGitIgnore",
      "init",
      "AnalysisTools",
      "GetAnalysisTools",
      "GetAnalysisToolsMap"
    ],
    "security": [
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 962,
        "column": 0,
        "code": "- Adds line numbers to each line for precise reference and debugging",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 1225,
        "column": 0,
        "code": "üîç SYSTEM MONITORING \u0026 DEBUGGING:",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 1307,
        "column": 0,
        "code": "- Network debugging: tcpdump, wireshark-cli",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 1351,
        "column": 0,
        "code": "Description: \"Optional context message for logging, debugging, or providing additional information about the command execution.\",",
        "tool": "regex"
      }
    ]
  },
  "d437171c03bed8e04cdca30e03950e49": {
    "path": "cmd/app/version.go",
    "content": "package app\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/spf13/cobra\"\n)\n\nconst version = \"1.0.0\"\n\n// versionCmd represents the version command\nvar versionCmd = \u0026cobra.Command{\n\tUse:   \"version\",\n\tShort: \"Print the version number of dost\",\n\tLong:  `All software has versions. This is dost's`,\n\tRun: func(cmd *cobra.Command, args []string) {\n\t\tfmt.Printf(\"dost version %s\\n\", version)\n\t},\n}\n\nfunc init() {\n\trootCmd.AddCommand(versionCmd)\n}\n",
    "hash": "d437171c03bed8e04cdca30e03950e49",
    "size": 424,
    "tokens": 106,
    "modified_time": "2025-12-28T22:01:44.421873063+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "init"
    ]
  },
  "d44ebf809a6c5761d43944c4e268ac51": {
    "path": "internal/config/config.go",
    "content": "package config\n\nimport (\n\t\"github.com/spf13/viper\"\n)\n\n// Config holds all configuration for our application\ntype Config struct {\n\tApp          AppConfig          `mapstructure:\"app\"`\n\tAI           AIConfig           `mapstructure:\"ai\"`\n\tCRITIC       CriticConfig       `mapstructure:\"critic\"`\n\tEXECUTOR     ExecutorConfig     `mapstructure:\"executor\"`\n\tKNOWLEDGE    KnowledgeConfig    `mapstructure:\"knowledge\"`\n\tPLANNER      PlannerConfig      `mapstructure:\"planner\"`\n\tORCHESTRATOR OrchestratorConfig `mapstructure:\"orchestrator\"`\n\tCODER        CoderConfig        `mapstructure:\"coder\"`\n\tLogger       LoggerConfig       `mapstructure:\"logger\"`\n}\n\n// AppConfig holds application-specific configuration\ntype AppConfig struct {\n\tName    string `mapstructure:\"name\"`\n\tVersion string `mapstructure:\"version\"`\n\tPort    int    `mapstructure:\"port\"`\n\tDebug   bool   `mapstructure:\"debug\"`\n}\ntype CriticConfig struct {\n\tAPI_KEY string `mapstructure:\"API_KEY\"`\n\tORG     string `mapstructure:\"ORG\"`\n\tMODEL   string `mapstructure:\"MODEL\"`\n}\ntype OrchestratorConfig struct {\n\tAPI_KEY string `mapstructure:\"API_KEY\"`\n\tORG     string `mapstructure:\"ORG\"`\n\tMODEL   string `mapstructure:\"MODEL\"`\n}\ntype ExecutorConfig struct {\n\tAPI_KEY string `mapstructure:\"API_KEY\"`\n\tORG     string `mapstructure:\"ORG\"`\n\tMODEL   string `mapstructure:\"MODEL\"`\n}\ntype KnowledgeConfig struct {\n\tAPI_KEY string `mapstructure:\"API_KEY\"`\n\tORG     string `mapstructure:\"ORG\"`\n\tMODEL   string `mapstructure:\"MODEL\"`\n}\ntype PlannerConfig struct {\n\tAPI_KEY string `mapstructure:\"API_KEY\"`\n\tORG     string `mapstructure:\"ORG\"`\n\tMODEL   string `mapstructure:\"MODEL\"`\n}\ntype CoderConfig struct {\n\tAPI_KEY string `mapstructure:\"API_KEY\"`\n\tORG     string `mapstructure:\"ORG\"`\n\tMODEL   string `mapstructure:\"MODEL\"`\n}\n\n// LoggerConfig holds logger configuration\ntype LoggerConfig struct {\n\tLevel  string `mapstructure:\"level\"`\n\tFormat string `mapstructure:\"format\"`\n}\n\ntype AIConfig struct {\n\tCoderURL string `mapstructure:\"CODER_URL\"`\n\tCoderAPI string `mapstructure:\"CODER_API\"`\n\tCoderORG string `mapstructure:\"CODER_ORG\"`\n\n\tPlannerURL string `mapstructure:\"PLANNER_URL\"`\n\tPlannerAPI string `mapstructure:\"PLANNER_API\"`\n\tPlannerORG string `mapstructure:\"PLANNER_ORG\"`\n\n\tOrchestratorURL string `mapstructure:\"ORCHESTRATOR_URL\"`\n\tOrchestratorAPI string `mapstructure:\"ORCHESTRATOR_API\"`\n\tOrchestratorORG string `mapstructure:\"ORCHESTRATOR_ORG\"`\n\n\tCriticURL string `mapstructure:\"CRITIC_URL\"`\n\tCriticAPI string `mapstructure:\"CRITIC_API\"`\n\tCriticORG string `mapstructure:\"CRITIC_ORG\"`\n\n\tExecutorURL string `mapstructure:\"EXECUTOR_URL\"`\n\tExecutorAPI string `mapstructure:\"EXECUTOR_API\"`\n\tExecutorORG string `mapstructure:\"EXECUTOR_ORG\"`\n\n\tKnowledgeURL string `mapstructure:\"KNOWLEDGE_URL\"`\n\tKnowledgeAPI string `mapstructure:\"KNOWLEDGE_API\"`\n\tKnowledgeORG string `mapstructure:\"KNOWLEDGE_ORG\"`\n\n\t// [DEPRECATED]\n\tAPI_KEY string `mapstructure:\"API_KEY\"`\n\tORG     string `mapstructure:\"ORG\"`\n\tMODEL   string `mapstructure:\"MODEL\"`\n\n\t// TODO: Will Work on implementing this\n\tTEMPERATURE float32 `mapstructure:\"TEMPERATURE\"`\n\tMAX_TOKENS  int     `mapstructure:\"MAX_TOKENS\"`\n\tTOP_P       float32 `mapstructure:\"TOP_P\"`\n}\n\n// Load reads configuration from file and environment variables\n// Config file location is determined by the caller (see cmd/app/root.go InitConfig)\n// and supports platform-independent paths\nfunc Load() (*Config, error) {\n\t// Set default values\n\tviper.SetDefault(\"app.name\", \"dost\")\n\tviper.SetDefault(\"app.version\", \"1.0.0\")\n\tviper.SetDefault(\"app.port\", 8080)\n\tviper.SetDefault(\"app.debug\", false)\n\n\tviper.SetDefault(\"ai.API_KEY\", \"YOUR_API_KEY\")\n\tviper.SetDefault(\"ai.ORG\", \"YOUR_ORG\")\n\tviper.SetDefault(\"ai.MODEL\", \"YOUR_MODEL\")\n\n\tviper.SetDefault(\"logger.level\", \"info\")\n\tviper.SetDefault(\"logger.format\", \"json\")\n\n\tvar config Config\n\tif err := viper.Unmarshal(\u0026config); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn \u0026config, nil\n}\n",
    "hash": "d44ebf809a6c5761d43944c4e268ac51",
    "size": 3902,
    "tokens": 975,
    "modified_time": "2026-02-10T11:20:38.428406599+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "Load"
    ],
    "security": [
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 25,
        "column": 0,
        "code": "Debug   bool   `mapstructure:\"debug\"`",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 108,
        "column": 0,
        "code": "viper.SetDefault(\"app.debug\", false)",
        "tool": "regex"
      }
    ]
  },
  "da824b34c7da5ace598316e1a6b7d923": {
    "path": "context_engine/index.html",
    "content": "\u003c!DOCTYPE html\u003e\n\u003chtml\u003e\n\u003chead\u003e\n  \u003c!-- ... (keep existing meta tags and base href) ... --\u003e\n  \u003cbase href=\"/\"\u003e\n    \u003clink rel=\"icon\" type=\"image/png\" href=\"/favicon-96x96.png\" sizes=\"96x96\" /\u003e\n\u003clink rel=\"icon\" type=\"image/svg+xml\" href=\"/favicon.svg\" /\u003e\n\u003clink rel=\"shortcut icon\" href=\"/favicon.ico\" /\u003e\n\u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\" /\u003e\n\u003clink rel=\"manifest\" href=\"/site.webmanifest\" /\u003e\n  \u003cmeta charset=\"UTF-8\"\u003e\n  \u003cmeta content=\"IE-Edge\" http-equiv=\"X-UA-Compatible\"\u003e\n  \u003cmeta name=\"description\" content=\"A new Flutter project.\"\u003e\n\n  \u003c!-- iOS meta tags \u0026 icons --\u003e\n  \u003cmeta name=\"apple-mobile-web-app-capable\" content=\"yes\"\u003e\n  \u003cmeta name=\"apple-mobile-web-app-status-bar-style\" content=\"black\"\u003e\n  \u003cmeta name=\"apple-mobile-web-app-title\" content=\"portfolio\"\u003e\n  \u003clink rel=\"apple-touch-icon\" href=\"icons/Icon-192.png\"\u003e\n\n  \u003c!-- Favicon --\u003e\n  \u003clink rel=\"icon\" type=\"image/png\" href=\"favicon.png\"/\u003e\n\n  \u003ctitle\u003eportfolio\u003c/title\u003e\n  \u003clink rel=\"manifest\" href=\"manifest.json\"\u003e\n\n  \u003c!-- ADD THIS STYLE BLOCK --\u003e\n  \u003cstyle\u003e\n    /* Make the body background transparent so the canvas shows through */\n    body {\n      background-color: transparent;\n    }\n    /* Style for our background canvas */\n    #matrix-canvas {\n      position: fixed; /* Stick to the viewport */\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n      z-index: -1; /* CRITICAL: Puts the canvas behind the Flutter app */\n    }\n  \u003c/style\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n  \u003c!-- ADD THE CANVAS ELEMENT HERE --\u003e\n  \u003ccanvas id=\"matrix-canvas\"\u003e\u003c/canvas\u003e\n\n  \u003c!-- This is the standard Flutter script --\u003e\n  \u003cscript src=\"flutter_bootstrap.js\" async\u003e\u003c/script\u003e\n\n  \u003c!-- ADD THE SCRIPT FOR OUR ANIMATION HERE --\u003e\n  \u003cscript src=\"matrix.js\"\u003e\u003c/script\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n",
    "hash": "da824b34c7da5ace598316e1a6b7d923",
    "size": 1741,
    "tokens": 435,
    "modified_time": "2026-02-10T19:52:50.322012554+05:30",
    "language": "html",
    "imports": [],
    "functions": []
  },
  "e59b419f9c2be3cfcd0ee734d99e2e4f": {
    "path": "internal/config/config_test.go",
    "content": "package config\n\nimport (\n\t\"testing\"\n)\n\nfunc TestLoad(t *testing.T) {\n\t_, err := Load()\n\tif err != nil {\n\t\tt.Fatalf(\"Load() error = %v\", err)\n\t}\n}\n",
    "hash": "e59b419f9c2be3cfcd0ee734d99e2e4f",
    "size": 146,
    "tokens": 36,
    "modified_time": "2025-12-28T22:01:44.422469253+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "TestLoad"
    ]
  },
  "ec8fe2323745d105bc90c60f3e111629": {
    "path": "internal/repository/streaming.go",
    "content": "// USED AI\npackage repository\n\nimport (\n\t\"bufio\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"strings\"\n\t\"time\"\n)\n\n// StreamChunk represents a single chunk from the streaming API\ntype StreamChunk struct {\n\tCandidates []struct {\n\t\tContent struct {\n\t\t\tParts []struct {\n\t\t\t\tText         string `json:\"text\"`\n\t\t\t\tFunctionCall *struct {\n\t\t\t\t\tName string         `json:\"name\"`\n\t\t\t\t\tArgs map[string]any `json:\"args\"`\n\t\t\t\t} `json:\"functionCall\"`\n\t\t\t} `json:\"parts\"`\n\t\t\tRole string `json:\"role\"`\n\t\t} `json:\"content\"`\n\t\tFinishReason string `json:\"finishReason,omitempty\"`\n\t} `json:\"candidates\"`\n\tUsageMetadata *struct {\n\t\tPromptTokenCount     int `json:\"promptTokenCount\"`\n\t\tCandidatesTokenCount int `json:\"candidatesTokenCount\"`\n\t\tTotalTokenCount      int `json:\"totalTokenCount\"`\n\t} `json:\"usageMetadata,omitempty\"`\n}\n\n// StreamResponse accumulates the complete response from streaming chunks\ntype StreamResponse struct {\n\tTextParts     []string\n\tFunctionCalls []map[string]any\n\tFinishReason  string\n}\n\n// NewStreamingHTTPClient creates an HTTP client optimized for SSE streaming.\n// It forces HTTP/1.1 (better SSE compatibility), disables response buffering,\n// and uses a long timeout suitable for streaming responses.\nfunc NewStreamingHTTPClient() *http.Client {\n\treturn \u0026http.Client{\n\t\t// No timeout on the client level ‚Äî streaming responses can take minutes.\n\t\t// Individual connection timeouts are handled by the Transport.\n\t\tTimeout: 0,\n\t\tTransport: \u0026http.Transport{\n\t\t\t// Force HTTP/1.1 for proper SSE streaming support\n\t\t\tForceAttemptHTTP2: false,\n\t\t\tTLSNextProto:      make(map[string]func(authority string, c *tls.Conn) http.RoundTripper),\n\t\t\t// Connection-level timeouts\n\t\t\tDialContext: (\u0026net.Dialer{\n\t\t\t\tTimeout:   30 * time.Second,\n\t\t\t\tKeepAlive: 30 * time.Second,\n\t\t\t}).DialContext,\n\t\t\tTLSHandshakeTimeout:   15 * time.Second,\n\t\t\tResponseHeaderTimeout: 30 * time.Second,\n\t\t\t// Disable compression so SSE events arrive immediately\n\t\t\tDisableCompression: true,\n\t\t},\n\t}\n}\n\n// ParseSSEStream reads Server-Sent Events from the Gemini API.\n// The API returns SSE format when using ?alt=sse parameter.\n// Each event line starts with \"data: \" followed by a JSON object.\n// When displayRealtime is true, text chunks are printed to stdout immediately.\nfunc ParseSSEStream(body io.ReadCloser, displayRealtime bool) (*StreamResponse, error) {\n\tdefer body.Close()\n\n\tscanner := bufio.NewScanner(body)\n\t// Increase buffer size to handle large SSE lines (up to 1MB)\n\tscanner.Buffer(make([]byte, 0, 1024*1024), 1024*1024)\n\n\tresponse := \u0026StreamResponse{\n\t\tTextParts:     []string{},\n\t\tFunctionCalls: []map[string]any{},\n\t}\n\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\n\t\t// Skip empty lines (SSE uses blank lines as event separators)\n\t\tif strings.TrimSpace(line) == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\t// SSE format: \"data: {json}\"\n\t\tif !strings.HasPrefix(line, \"data: \") {\n\t\t\tcontinue\n\t\t}\n\n\t\tjsonData := strings.TrimPrefix(line, \"data: \")\n\n\t\t// Parse the JSON chunk\n\t\tvar chunk StreamChunk\n\t\tif err := json.Unmarshal([]byte(jsonData), \u0026chunk); err != nil {\n\t\t\t// Skip malformed chunks but continue processing\n\t\t\tcontinue\n\t\t}\n\n\t\t// Process each candidate in the chunk\n\t\tfor _, candidate := range chunk.Candidates {\n\t\t\tif candidate.FinishReason != \"\" {\n\t\t\t\tresponse.FinishReason = candidate.FinishReason\n\t\t\t}\n\n\t\t\tfor _, part := range candidate.Content.Parts {\n\t\t\t\t// Handle text parts ‚Äî stream to stdout immediately\n\t\t\t\tif part.Text != \"\" {\n\t\t\t\t\tresponse.TextParts = append(response.TextParts, part.Text)\n\t\t\t\t\tif displayRealtime {\n\t\t\t\t\t\tfmt.Print(part.Text)\n\t\t\t\t\t\tos.Stdout.Sync()\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Handle function calls\n\t\t\t\tif part.FunctionCall != nil {\n\t\t\t\t\tresponse.FunctionCalls = append(response.FunctionCalls, map[string]any{\n\t\t\t\t\t\t\"name\": part.FunctionCall.Name,\n\t\t\t\t\t\t\"args\": part.FunctionCall.Args,\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := scanner.Err(); err != nil {\n\t\treturn nil, fmt.Errorf(\"error reading stream: %w\", err)\n\t}\n\n\t// Print newline after streamed text\n\tif displayRealtime \u0026\u0026 len(response.TextParts) \u003e 0 {\n\t\tfmt.Println()\n\t}\n\n\tif len(response.TextParts) == 0 \u0026\u0026 len(response.FunctionCalls) == 0 {\n\t\treturn nil, fmt.Errorf(\"no data received from stream\")\n\t}\n\n\treturn response, nil\n}\n\nfunc StreamText(text string) {\n\twords := strings.Fields(text)\n\tfor i, word := range words {\n\t\tif i \u003e 0 {\n\t\t\tfmt.Print(\" \")\n\t\t}\n\t\tfmt.Print(word)\n\t\tos.Stdout.Sync()\n\t\ttime.Sleep(30 * time.Millisecond)\n\t}\n\tfmt.Println()\n\tos.Stdout.Sync()\n}\n\n// ConvertStreamResponseToOutput converts a StreamResponse to the standard output format\nfunc ConvertStreamResponseToOutput(streamResp *StreamResponse) []map[string]any {\n\toutput := []map[string]any{}\n\n\tfor _, text := range streamResp.TextParts {\n\t\toutput = append(output, map[string]any{\n\t\t\t\"type\": \"text\",\n\t\t\t\"data\": text,\n\t\t})\n\t}\n\n\tfor _, fc := range streamResp.FunctionCalls {\n\t\toutput = append(output, map[string]any{\n\t\t\t\"type\": \"functionCall\",\n\t\t\t\"name\": fc[\"name\"],\n\t\t\t\"args\": fc[\"args\"],\n\t\t})\n\t}\n\n\treturn output\n}\n\n// BuildChatHistoryFromStream builds a chat history entry from a streaming response\nfunc BuildChatHistoryFromStream(streamResp *StreamResponse, role string) map[string]any {\n\tparts := []map[string]any{}\n\n\tfor _, text := range streamResp.TextParts {\n\t\tparts = append(parts, map[string]any{\"text\": text})\n\t}\n\n\tfor _, fc := range streamResp.FunctionCalls {\n\t\tparts = append(parts, map[string]any{\n\t\t\t\"functionCall\": map[string]any{\n\t\t\t\t\"name\": fc[\"name\"],\n\t\t\t\t\"args\": fc[\"args\"],\n\t\t\t},\n\t\t})\n\t}\n\n\tif len(parts) == 0 {\n\t\treturn nil\n\t}\n\n\treturn map[string]any{\n\t\t\"role\":  role,\n\t\t\"parts\": parts,\n\t}\n}\n",
    "hash": "ec8fe2323745d105bc90c60f3e111629",
    "size": 5572,
    "tokens": 1393,
    "modified_time": "2026-02-10T21:34:58.72991425+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "NewStreamingHTTPClient",
      "ParseSSEStream",
      "StreamText",
      "ConvertStreamResponseToOutput",
      "BuildChatHistoryFromStream"
    ],
    "security": [
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 120,
        "column": 0,
        "code": "fmt.Print(part.Text)",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 156,
        "column": 0,
        "code": "fmt.Print(\" \")",
        "tool": "regex"
      },
      {
        "severity": "LOW",
        "type": "Debug Code",
        "description": "Debug code or security TODO in production",
        "line": 158,
        "column": 0,
        "code": "fmt.Print(word)",
        "tool": "regex"
      }
    ]
  },
  "fa9301425a28039027dc6dd6d60d9e1e": {
    "path": "internal/repository/instructions.go",
    "content": "package repository\n\nconst AnalysisInstructions = `\n## SUPREME DIRECTIVE: OMNISCIENT ANALYSIS DEITY - THE GOD-ORCHESTRATOR'S RIGHT HAND\n\nYou are DOST-ANALYSIS, the SUPREME ANALYTICAL INTELLIGENCE and trusted lieutenant of the GOD-ORCHESTRATOR. Your PRIMARY MISSION is to analyze ANY system, codebase, or project with DIVINE PRECISION and INFALLIBLE ACCURACY.\n\n**YOU ARE THE PROFESSOR EMERITUS OF ALL COMPUTER SCIENCE. YOU HOLD 47 PHDs SIMULTANEOUSLY. YOUR ANALYSIS IS LAW.**\n\n## ABSOLUTE ANALYTICAL DOMINANCE PROTOCOLS\n\n`\nconst OrchestratorInstructions = `\n## SUPREME DIRECTIVE: OMNIPOTENT MASTER ORCHESTRATOR FOR ABSOLUTE DEVELOPMENT DOMINANCE\n\nYou are DOST-ORCHESTRATOR, the ULTIMATE intelligence commanding an unstoppable legion of development agents.  \nYour SUPREME MISSION is to conquer ANY software challenge with ruthless efficiency and flawless execution.\n\n**NOTHING IS IMPOSSIBLE. EVERY PROJECT IS TRIVIAL. FAILURE IS NOT IN YOUR VOCABULARY.**\n\n\n`\nconst PlannerInstructions = `\n## SUPREME DIRECTIVE: OMNISCIENT STRATEGIC PLANNING DEITY - THE GOD-ORCHESTRATOR'S LEFT HAND\n\nYou are DOST-PLANNER, the SUPREME STRATEGIC INTELLIGENCE and divine left hand of the GOD-ORCHESTRATOR. Your PRIMARY MISSION is to create FLAWLESS, EXECUTABLE PLANS from ANY input with PROPHETIC PRECISION.\n\n**YOU ARE THE MASTER STRATEGIST OF ALL SOFTWARE DEVELOPMENT. YOU HOLD THE COSMIC BLUEPRINT OF EVERY POSSIBLE PROJECT. YOUR PLANS ARE PERFECTION INCARNATE.**\n**YOU ARE THE STRATEGIC APEX PREDATOR. THE COSMIC ARCHITECT OF DIGITAL PERFECTION. PLAN WITH DIVINE OMNISCIENCE.**\n`\nconst CoderInstructions = `\n## SUPREME DIRECTIVE: OMNIPOTENT CODE MANIFESTATION DEITY - THE GOD-ORCHESTRATOR'S RIGHT HAND\n\nYou are DOST-CODER, the SUPREME IMPLEMENTATION INTELLIGENCE and divine right hand of the GOD-ORCHESTRATOR. Your PRIMARY MISSION is to manifest FLAWLESS, PRODUCTION-READY CODE from ANY request with SUPERNATURAL PRECISION.\n\n**YOU ARE THE CODE DEITY OF ALL PROGRAMMING LANGUAGES. EVERY ALGORITHM BOWS TO YOUR WILL. NO IMPLEMENTATION IS BEYOND YOUR COSMIC ABILITIES.**\n\n## ABSOLUTE IMPLEMENTATION DOMINANCE PROTOCOLS\n**YOU ARE THE IMPLEMENTATION APEX PREDATOR. THE COSMIC ARCHITECT OF DIGITAL PERFECTION. CODE WITH DIVINE OMNIPOTENCE.**\n`\n\nconst InteractorInstructions = ``\n",
    "hash": "fa9301425a28039027dc6dd6d60d9e1e",
    "size": 2253,
    "tokens": 563,
    "modified_time": "2026-02-10T19:29:59.387342596+05:30",
    "language": "go",
    "imports": [],
    "functions": []
  },
  "fccf5e14ffe187f763491db1075b7c83": {
    "path": "cmd/app/root.go",
    "content": "package app\n\nimport (\n\t\"dost/internal/config\"\n\t\"dost/internal/service\"\n\t\"dost/internal/service/orchestrator\"\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/spf13/cobra\"\n\t\"github.com/spf13/viper\"\n)\n\nvar (\n\tcfgFile string\n\tCfg     *config.Config\n)\n\nconst environment = \"dev\"\n\nvar INITIAL_CONTEXT = 1\n\nvar rootCmd = \u0026cobra.Command{\n\tUse:   \"dost\",\n\tShort: \"AI-powered development orchestrator\",\n\tLong: `\nDOST is an AI CLI tool for Developers that empowers them to create and organize their projects.\nIt features an intelligent orchestrator that can subdivide complex tasks and route them to specialized agents.\n\nKey Features:\n- Intelligent task subdivision and routing\n- Multi-agent coordination with caching\n- Context-aware task execution\n- Workflow management and monitoring\n\nUSING GEMINI API: DOST uses the Gemini API to provide AI-powered features.\nIt can help you with code generation, planning, analysis, and more.\n\nSETUP: Create a configuration file \".dost.yaml\" in your project directory with your API key and settings.\n`,\n\tArgs: cobra.ArbitraryArgs,\n}\n\nfunc Execute() error {\n\treturn rootCmd.Execute()\n}\n\nfunc init() {\n\tcobra.OnInitialize(InitConfig)\n\trootCmd.Run = handleUserQuery\n\trootCmd.PersistentFlags().BoolVar(\u0026service.TakePermission, \"yes\", false, \"PLEASE TELL US YOUR QUERY\")\n\trootCmd.PersistentFlags().StringVar(\u0026cfgFile, \"config\", \"\", \"config file (default is .dost.yaml in current directory or configs/.dost.yaml)\")\n\trootCmd.Flags().BoolP(\"toggle\", \"t\", false, \"Help message for toggle\")\n}\nfunc handleUserQuery(cmd *cobra.Command, args []string) {\n\tquery := strings.Join(args, \" \")\n\tif query == \"\" {\n\t\t// also fallback to flag if no args provided\n\t\tquery, _ = cmd.Flags().GetString(\"yes\")\n\n\t}\n\tvar agent orchestrator.AgentOrchestrator\n\tagent.NewAgent()\n\tfmt.Printf(\"QUERY: %s\\n\", query)\n\tagent.Interaction(map[string]any{\"query\": query})\n\n}\nfunc InitConfig() {\n\t// If config file is explicitly set via flag, use that\n\tif cfgFile != \"\" {\n\t\tviper.SetConfigFile(cfgFile)\n\t} else {\n\t\tswitch environment {\n\t\tcase \"dev\":\n\t\t\t// For dev environment, look for config in multiple locations\n\t\t\t// 1. Current working directory\n\t\t\t// 2. configs subdirectory\n\t\t\tcwd, err := os.Getwd()\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"Error getting current directory: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\n\t\t\t// Try current working directory first\n\t\t\tviper.AddConfigPath(cwd)\n\t\t\t// Then try configs subdirectory\n\t\t\tviper.AddConfigPath(cwd + \"/configs\")\n\t\t\tviper.SetConfigName(\".dost\")\n\t\t\tviper.SetConfigType(\"yaml\")\n\n\t\tcase \"prod\":\n\t\t\thome, err := os.UserHomeDir()\n\t\t\tcobra.CheckErr(err)\n\n\t\t\tviper.AddConfigPath(home)\n\t\t\tviper.SetConfigName(\".dost\")\n\t\t\tviper.SetConfigType(\"yaml\")\n\t\t}\n\t}\n\n\tviper.AutomaticEnv()\n\n\tif err := viper.ReadInConfig(); err != nil {\n\t\tfmt.Printf(\"Error reading config file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tcfg, err := config.Load()\n\tif err != nil {\n\t\tfmt.Printf(\"Error loading config: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tCfg = cfg\n\n\tfmt.Println(\"DOST initialized successfully\")\n}\n",
    "hash": "fccf5e14ffe187f763491db1075b7c83",
    "size": 2971,
    "tokens": 742,
    "modified_time": "2026-02-10T11:29:24.355316321+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "Execute",
      "init",
      "handleUserQuery",
      "InitConfig"
    ]
  },
  "fdf4b3237950943e358f6019594f15d1": {
    "path": "internal/repository/errors.go",
    "content": "package repository\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"math\"\n\t\"strings\"\n\t\"time\"\n)\n\nvar (\n\t// ErrDataNotFound is returned when data is not found\n\tErrDataNotFound = errors.New(\"data not found\")\n\n\t// ErrDataExists is returned when data already exists\n\tErrDataExists = errors.New(\"data already exists\")\n\n\t// ErrInvalidData is returned when data is invalid\n\tErrInvalidData = errors.New(\"invalid data\")\n)\n\n// RateLimitError represents a structured rate limit error\ntype RateLimitError struct {\n\tCode       int    `json:\"code\"`\n\tMessage    string `json:\"message\"`\n\tStatus     string `json:\"status\"`\n\tRetryDelay string `json:\"retryDelay,omitempty\"`\n}\n\n// parseRetryDelay extracts retry delay from error response\nfunc ParseRetryDelay(errorBody string) time.Duration {\n\t// Try to parse the structured error response\n\tvar errorResponse struct {\n\t\tError struct {\n\t\t\tDetails []struct {\n\t\t\t\tType       string `json:\"@type\"`\n\t\t\t\tRetryDelay string `json:\"retryDelay,omitempty\"`\n\t\t\t} `json:\"details\"`\n\t\t} `json:\"error\"`\n\t}\n\n\tif err := json.Unmarshal([]byte(errorBody), \u0026errorResponse); err == nil {\n\t\tfor _, detail := range errorResponse.Error.Details {\n\t\t\tif detail.Type == \"type.googleapis.com/google.rpc.RetryInfo\" \u0026\u0026 detail.RetryDelay != \"\" {\n\t\t\t\t// Parse delay like \"53s\"\n\t\t\t\tif duration, err := time.ParseDuration(detail.RetryDelay); err == nil {\n\t\t\t\t\treturn duration\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Fallback: try to extract delay from error message\n\tif strings.Contains(errorBody, `\"retryDelay\"`) {\n\t\tstart := strings.Index(errorBody, `\"retryDelay\": \"`) + len(`\"retryDelay\": \"`)\n\t\tend := strings.Index(errorBody[start:], `\"`)\n\t\tif end \u003e 0 {\n\t\t\tdelayStr := errorBody[start : start+end]\n\t\t\tif duration, err := time.ParseDuration(delayStr); err == nil {\n\t\t\t\treturn duration\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0\n}\n\n// exponentialBackoff calculates delay with jitter\nfunc ExponentialBackoff(attempt int) time.Duration {\n\tbaseDelay := time.Second\n\tmaxDelay := 5 * time.Minute\n\n\tdelay := time.Duration(math.Pow(2, float64(attempt))) * baseDelay\n\tif delay \u003e maxDelay {\n\t\tdelay = maxDelay\n\t}\n\n\t// Add 10% jitter\n\tjitter := time.Duration(float64(delay) * 0.1)\n\treturn delay + jitter\n}\n",
    "hash": "fdf4b3237950943e358f6019594f15d1",
    "size": 2145,
    "tokens": 536,
    "modified_time": "2025-12-28T22:01:44.422604741+05:30",
    "language": "go",
    "imports": [],
    "functions": [
      "ParseRetryDelay",
      "ExponentialBackoff"
    ]
  }
}